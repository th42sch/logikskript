\documentclass[fontsize=11pt, twoside=false, numbers=autoenddot]{scrbook}
\usepackage{logik_tafelanschriebe}

\pagestyle{plain}
% \pagestyle{scrheadings}
% % \chead{\headmark}
% \chead{\partmark}
% \renewcommand{\sectionmark}[1]{\markright{\textsl{#1}}}
% \renewcommand{\chaptermark}[1]{\markright{\textsl{#1}}{}}
% \renewcommand{\partmark}[1]{\markright{\textsl{#1}}}
\parindent0pt
\parskip\smallskipamount
 
\title{Tafelmitschriften zur Vorlesung \glqq Logik\grqq\\ im Wintersemester 2019/20}
\author{%
  Dr.\ Jean Christoph Jung, Prof.\ Dr.\ Thomas Schneider\\[1pt]
  AG Theorie der Künstlichen Intelligenz \\[1pt]
  Fachbereich 3 \\
  \includegraphics[width=.4\linewidth]{logo_ub.jpg} \\[\baselineskip]~%
}
\date{Stand: \today}

\begin{document}

\maketitle
\tableofcontents

% ===================================================================
% ===================================================================
% ===================================================================
\part{Aussagenlogik}

% ===================================================================
\section*{T1.1~ Modellierung des Zeitplanungsproblems}

Wir verwenden die Variablen
\[
  x_{ij}^\alpha
  \quad\text{mit}\quad
  \alpha \in \{\textsf{M},\textsf{S},\textsf{K}\},~
  i \in \{\textsf{I},\textsf{II},\textsf{III}\},~
  j \in \{\textsf{a},\textsf{b}\}.
\]
Die Variable $x_{ij}^\alpha$ repräsentiert die Aussage
\begin{center}
  "`Lehrerin $\alpha$ unterrichtet in Stunde $i$ die Klasse $j$."'
\end{center}
Wir modellieren das Problem wie folgt:
\begin{itemize}
  \item
    Jede Stunde wird von einer passenden Lehrerin unterrichtet:
    \[
      \varphi_1 = 
      \bigwedge_{ij \,\in\, \{\textsf{Ia},\textsf{IIIa},\textsf{IIIb}\}} (x_{ij}^{\textsf{M}} \vee x_{ij}^{\textsf{K}})
      \quad\wedge\quad
      \bigwedge_{ij \,\in\, \{\textsf{Ib},\textsf{IIa},\textsf{IIb}\}} (x_{ij}^{\textsf{S}} \vee x_{ij}^{\textsf{K}})
    \]
    Die Konjunktion in der 1.\ Hälfte iteriert über alle Deutschstunden (also $\textsf{Ia},\textsf{IIIa},\textsf{IIIb}$)
    und besagt, dass diese nur von Lehrerinnen \textsf{M}üller oder \textsf{K}örner unterrichtet werden können.
    Analog für die 2.\ Hälfte.
  \item
    Jede Lehrerin unterrichtet $\geq 2$ Stunden:
    \[
      \varphi_2 =
      \bigwedge_{\alpha \,\in\, \{\textsf{M},\textsf{S},\textsf{K}\}}
      \quad
      \bigvee_{\substack{ij,\,i'\!j'\, \in\, \{\textsf{Ia},\textsf{Ib},\textsf{IIa},\textsf{IIb},\textsf{IIIa},\textsf{IIIb}\}\\ij\,\neq\,i'\!j'}} (x_{ij}^\alpha \wedge x_{i'\!j'}^\alpha)
    \]
    Diese Formel ist eine Konjunktion
    aus drei Teilen, einem pro Lehrerin $\alpha$.
    Jeder Teil ist wiederum eine Disjunktion,
    die besagt, dass es ein Paar von \emph{verschiedenen} Stunden ($ij$ und $i'\!j'$) gibt,
    das die jeweilige Lehrerin $\alpha$ unterrichtet.
  \item
    Keine Lehrerin unterrichtet zwei Klassen gleichzeitig:
    \[
      \varphi_3 =
      \bigwedge_{\alpha \,\in\, \{\textsf{M},\textsf{S},\textsf{K}\}}
      \quad
      \bigwedge_{i \,\in\, \{\textsf{I},\textsf{II},\textsf{III}\}} \neg(x_{i\textsf{a}}^\alpha \wedge x_{i\textsf{b}}^\alpha)
    \]
    Diese Formel ist eine Konjunktion über alle Kombinationen
    aus Lehrerin $\alpha$ und Stunde $i$;
    jeder Bestandteil dieser Konjunktion besagt, dass Lehrerin $\alpha$ in Stunde $i$ nicht gleichzeitig Klasse \textsf{a} und \textsf{b} unterrichten kann.
  \item
    In jeder Unterrichtsstunde wird jede Klasse von höchstens einer Lehrerin unterrichtet:
    \[
      \varphi_4 =
      \bigwedge_{i \,\in\, \{\textsf{I},\textsf{II},\textsf{III}\}}
      \quad
      \bigwedge_{j \,\in\, \{\textsf{a},\textsf{b}\}}
      \Big(
        \neg(x_{ij}^{\textsf{M}} \wedge x_{ij}^{\textsf{S}}) ~~\wedge~~
        \neg(x_{ij}^{\textsf{M}} \wedge x_{ij}^{\textsf{K}}) ~~\wedge~~
        \neg(x_{ij}^{\textsf{S}} \wedge x_{ij}^{\textsf{K}})
      \Big)
    \]
    Diese Formel ist eine Konjunktion über alle Kombinationen aus Stunde $i$ und Klasse $j$;
    jeder Bestandteil dieser Konjunktion besagt, dass keine zwei Lehrerinnen aus $\{\textsf{M},\textsf{S},\textsf{K}\}$
    in $ij$ unterrichten können.
\end{itemize}
Man sieht nun leicht, dass die Belegungen $V$ mit
\[
  V \models \varphi_1 \wedge \varphi_2 \wedge \varphi_3 \wedge \varphi_4
\]
genau den Lösungen des Zeitplanungsproblems entsprechen.

% ===================================================================
\section*{T1.2~ Beispiel fürs Ersetzungslemma}

Seien $\varphi = x \land y$ and $\psi = \lnot(\lnot x \lor \lnot y)$, \\
und sei $\vartheta = z \lor \lnot (\underbrace{x \land y}_{\varphi})$.

Dann ist $\vartheta' = z \lor \lnot \underbrace{\lnot(\lnot x \lor \lnot y)}_{\psi}$.

Wir wissen aus dem vorhergenden Beispiel, dass $\varphi \equiv \psi$.

Also liefert das Ersetzungslemma $\vartheta \equiv \vartheta'$.

% ===================================================================
\section*{T1.3~ Beweis des Ersetzungslemmas}

\textsfbf{Lemma 1.8~ (Ersetzungslemma).}~
% \par\noindent
Seien $\varphi$ and $\psi$ äquivalente Formeln,
$\vartheta$ eine Formel mit $\varphi \in \textsf{TF}(\vartheta)$
und $\vartheta'$ eine Formel, die sich aus $\vartheta$ ergibt,
indem ein beliebiges Vorkommen von $\varphi$ durch $\psi$ ersetzt wird.
Dann gilt $\vartheta \equiv \vartheta'$.

\par\medskip\noindent
\begin{beweis}
  \begin{description}
    \item[\textsfbf{Induktionsanfang.}]
      ~\par
      Wenn $\vartheta$ atomar ist, muss $\vartheta = \varphi$ sein.
      Dann ist $\vartheta' = \psi$, also $\vartheta \equiv \vartheta'$.
    \item[\textsfbf{Induktionsschritt.}]
      ~\par
      Wenn $\vartheta = \varphi$, dann können wir wie im Induktionsanfang argumentieren.
      \par
      Anderenfalls unterscheiden wir drei Fälle.
      \begin{enumerate}
        \item
          $\vartheta = \lnot \vartheta_1$.
          \par
          Dann hat $\vartheta'$ die Form $\lnot \vartheta_1'$,
          wobei man $\vartheta_1'$ aus $\vartheta_1$ erhält,
          indem man ein Vorkommen von $\varphi$ durch $\psi$ ersetzt.
          Nach Induktionsvoraussetzung (IV) gilt $\vartheta_1 \equiv \vartheta_1'$.
          Mit der Semantik der Negation folgt daraus $\vartheta \equiv \vartheta'$.
        \item
          $\vartheta = \vartheta_1 \lor \vartheta_2$.
          \par
          Dann wird $\varphi$ entweder in $\vartheta_1$ oder in $\vartheta_2$ durch $\psi$ ersetzt.
          Wir betrachten nur den ersten Fall: Dann ist $\vartheta' = \vartheta_1' \lor \vartheta_2$,
          mit $\vartheta_1'$ wie in 1.
          Nach IV gilt $\vartheta_1 \equiv \vartheta_1'$.
          Mit der Semantik der Disjunktion folgt daraus $\vartheta \equiv \vartheta'$.
        \item
          $\vartheta = \vartheta_1 \land \vartheta_2$.
          \par
          Analog zu 2.\qedhere
      \end{enumerate}
  \end{description}
%   ~\par\vspace*{-2.3\baselineskip}
\end{beweis}%

\pagebreak
% ===================================================================
\section*{T1.4~ Beispiel für die Wandlung Formel $\to$ Boolesche Funktion}

Sei $\varphi = (x_1 \land x_2) \lor (\lnot x_1 \land \lnot x_2)$ mit $|\textsf{Var}(\varphi)|=2$.

Aus der Verknüpfungstafel kann man direkt $f_\varphi(x_1,x_2)$ ablesen:

\begin{center}
  \begin{tabular}{cc|ccl}
    $V(x_1)$ & $V(x_2)$ & $V(\varphi)$ &        &                      \\\cline{1-3}
    0        & 0        & 1            & d.\,h. & $f_\varphi(0,0) = 1$ \\
    0        & 1        & 0            &        & $f_\varphi(0,1) = 0$ \\
    1        & 0        & 0            &        & $f_\varphi(1,0) = 0$ \\
    1        & 1        & 1            &        & $f_\varphi(1,1) = 1$
  \end{tabular}
\end{center}

% ===================================================================
\section*{T1.5~ Beweis des Theorems über funktionale Vollständigkeit}

\textsfbf{Theorem 1.10~ (funktionale Vollständigkeit).}~
% \par\noindent
Zu jeder Booleschen Funktion $f \in \mathcal{B}$ gibt es eine Formel $\varphi$ mit $f_\varphi=f$.

\par\medskip\noindent
\begin{beweis}
  Wenn $f \in \mathcal{B}^0$, dann wird $f$ durch die Formeln 0 oder 1 dargestellt
  (die Booleschen Konstanten sind ja auch Formeln).

  Für $f \in \mathcal{B}^n$ mit $n > 0$ argumentieren wir wie folgt.
  Jede Eingabe für $f$ hat die Form $t = (w_1,\dots,w_n) \in \{0,1\}^n$
  und kann als Formel
  \[
    \psi_t = \ell_1 \land \dots \land \ell_n
  \]
  dargestellt werden, wobei
  \[
    \ell_i = \begin{cases}
               x_i       & \text{wenn~} w_i = 1 \\
               \lnot x_i & \text{wenn~} w_i = 0.
             \end{cases}
  \]
  Aus $t = (0,1,0,1)$ beispielsweise wird:
  \[
    \psi_t = \lnot x_1 \land x_2 \land \lnot x_3 \land x_4
  \]
  Setzt man nun
  \[
    \varphi := \bigvee_{\substack{t = (w_1,\dots,w_n) \in \{0,1\}^n \\ f(t) = 1\,\textsfbf{(!)}}} \psi_t,
  \]
  so gilt $f_\varphi = f$.\qedhere
\end{beweis}

Ist also z.\,B.\ $n=2$ und die Funktion $f$ mit
\begin{center}
  \begin{tabular}{cc|cl}
    $w_1$ & $w_2$ & $f(w_1,w_2)$ & \\\cline{1-3}
    0     & 0     & 0            & \\
    0     & 1     & 1            & $\blacktriangleleft$ \\
    1     & 0     & 1            & $\blacktriangleleft$ \\
    1     & 1     & 0            &
  \end{tabular}
\end{center}
gegeben, dann ist $\varphi = (\lnot x_1 \land x_2) \lor (x_1 \land \lnot x_2)$.

% ===================================================================
\section*{T1.6~ Beweis des Theorems über KNF-/DNF-Umwandlung}

\textsfbf{Theorem 1.12~ (KNF-/DNF-Umwandlung).}~
% \par\noindent
Jede Formel lässt sich effektiv in eine äquivalente Formel in KNF
und DNF wandeln.

\par\medskip\noindent
\begin{beweis}
  Sei $\varphi$ eine Formel.
  Um eine äquivalente Formel in \textsfbf{DNF} zu erhalten,
  wende die Konstruktion aus dem Beweis des letzten Satzes auf $f_\varphi$ an.
  Diese Konstruktion ist offensichtlich effektiv.

  Aus der effektiven Konstruierbarkeit der DNF folgt auch die der \textsfbf{KNF:}
  \begin{xalignat*}{2}
    \varphi & \equiv \lnot \lnot \varphi                                     & & \text{(bekannte Äquivalenz: Doppelnegation)} \\
            & \equiv \lnot \bigvee_{i=1}^n \bigwedge_{j=1}^{m_i} \ell_{ij}   & & \text{(Wandeln von $\lnot \varphi$ in DNF;~ Ersetzungslemma)}\\
            & \equiv \bigwedge_{i=1}^n \lnot \bigwedge_{j=1}^{m_i} \ell_{ij} & & \text{(De Morgan, Ersetzungslemma)} \\
            & \equiv \bigwedge_{i=1}^n \bigvee_{j=1}^{m_i} \lnot \ell_{ij}   & & \text{(De Morgan, Ersetzungslemma)} 
  \end{xalignat*}
  Die entstandene Formel ist in KNF.\qedhere
\end{beweis}%

% ===================================================================
\section*{T1.x~ Existenz kleiner Formeln}

Im Wintersemester 2016/17 tauchte die Frage auf, ob jede Boolesche Funktion
durch eine (wie auch immer geartete) polynomiell große aussagenlogische Formeln dargestellt werden kann.
Diese Frage ist zu \emph{verneinen,} denn:

\begin{quote}
  Es gibt eine eine Familie von Booleschen Funktionen $f_1,f_2,f_3,\dots$
  mit $f_n \in \mathcal{B}^n$ für alle $n \geq 0$,
  so dass für alle $n \geq 0$ und alle Formeln $\varphi$ mit $f_n = f_\varphi$ gilt:
  \[
    |\varphi| > 2^{\mathcal{O}(n)}
  \]
\end{quote}

Um dies zu begründen, benötigt man zwei Überlegungen:
\begin{enumerate}
  \item
    Jede aussagenlogische Formel $\varphi$
    ist als Schaltkreis $C_\varphi$ mit
    $\neg$-, $\land$- und $\lor$-Gattern darstellbar,
    so dass $|C_\varphi|$ nur polynomiell größer als $|\varphi|$ ist.
  \item
    Nach dem Theorem von Shannon (1949) gibt es
    eine Familie von Booleschen Funktionen $f_1,f_2,f_3,\dots$
    mit $f_n \in \mathcal{B}^n$ für alle $n \geq 0$,
    so dass jeder Schaltkreis, der $f_n$ berechnet, eine Größe ${}> \frac{2^n}{10n}$ hat.
\end{enumerate}
Letzteres ist ein wichtiges Resultat in der Schaltkreiskomplexität.
Es wird durch ein Abzählargument bewiesen:
Wir wissen bereits, dass es $2^{2^n}$ Boolesche Funktionen der Stelligkeit $n$ gibt.
Dann bleibt zu zeigen, dass es ${}<2^{2^n}$ Schaltkreise der Größe $\frac{2^n}{10n}$ gibt.
Dies geschieht im Wesentlichen dadurch, dass man Schaltkreise als Zeichenketten
über einem festen Alphabet kodiert und dann kombinatorisch die Anzahl der
möglichen Zeichenketten einschränkt.
Mit komplexeren Abzählargumenten kann man sogar noch schärfere Schranken beweisen.
Details zum Theorem von Shannon sowie die Definition von Schaltkreisen sind nachzulesen in 
einem dedizierten Kapitel von \cite{AB09}.

% ===================================================================
\section*{T1.7~ Beispiel für {\boldmath $n$-ären} Junktor}

Betrachte $f \in \mathcal{B}^3$ wie folgt:
\begin{align*}
  f(0,x,y) & = x \lor y \\
  f(1,x,y) & = x \land y
\end{align*}
Die Verknüpfungstafel liefert die Semantik für einen dreistelligen Junktor $f$:
\begin{center}
  \begin{tabular}{ccc|cl}
    $x$ & $y$      & $z$ & $f(x,y,z)$ \\\hline
    0   & 0        & 0   & 0          \\
    0   & 0        & 1   & 1          \\
    0   & 1        & 0   & 1          \\
        & $\vdots$ &     &            \\
    1   & 1        & 1   & 1
  \end{tabular}
\end{center}
Eine Formel über der Junktormenge $\{\lnot,\land,\lor,f\}$ wäre z.\,B.:
\[
  x \,\lor\, \lnot f(x \lor y,~ f(y,y,z),~ \lnot z)
\]

% ===================================================================
\section*{T1.8~ Funktionale Vollständigkeit des Junktors Nand}

Da wir bereits gezeigt haben, dass die Menge $\{\lnot,\land\}$ funktional vollständig ist,
genügt es zu zeigen:
\begin{itemize}
  \item
    Mit $\mid$ kann man $\lnot$ ausdrücken:
    \begin{xalignat*}{2}
      \varphi \mid \varphi & \equiv \lnot (\varphi \land \varphi) & & \text{(Definition von $\mid$\,)} \\
                           & \equiv \lnot \varphi                 & & \text{(Idempotenz)}
    \end{xalignat*}
  \item
    Mit $\mid$ kann man $\land$ ausdrücken:
    \begin{xalignat*}{2}
      (\varphi \mid \psi) \mid (\varphi \mid \psi) & \equiv \lnot (\varphi \mid \psi)        & & \text{(gerade gezeigt)}          \\
                                                   & \equiv \lnot \lnot (\varphi \land \psi) & & \text{(Definition von $\mid$\,)} \\
                                                   & \equiv \varphi \land \psi               & & \text{(Doppelnegation)}
    \end{xalignat*}
\end{itemize}

% ===================================================================
\section*{T1.9~ (co)NP-Vollständigkeit von Erfüllbarkeit bzw.\ Gültigkeit}

\textsfbf{Theorem 1.17~ (Komplexität).}~
Das Erfüllbarkeitsproblem der Aussagenlogik ist NP-voll\-ständig.
Dies gilt auch für Formeln in KNF, sogar bei max.\ 3 Literalen pro Konjunkt.

\par
Das Gültigkeitsproblem der Aussagenlogik ist co-NP-vollständig.
Dies gilt auch für Formeln in DNF, sogar bei max.\ 3 Literalen pro Disjunkt.

\par\smallskip\noindent
\begin{beweis}
  ~\par
  \textsfbf{Erfüllbarkeit ist in NP.}~
  Sei $\varphi$ die Eingabeformel mit $|\textsf{Var}(\varphi)| = n$.
  Eine Turingmaschine kann mit $n$ \emph{nichtdeterministischen} Übergängen
  eine Belegung $V$ für $\varphi$ aufs Band schreiben (also diese Belegung "`raten"').
  Die weitere Berechnung prüft deterministisch, ob $V \models \varphi$ gilt (geht in Linearzeit!);
  sie ist erfolgreich, wenn dies der Fall ist.
  Dann gilt:
  \begin{center}
    \begin{tabular}{@{}l@{~~}c@{~~}l@{}}
      $M$ akzeptiert $\varphi$ & gdw. & es erfolgreiche Berechnung von $M$ auf $\varphi$ gibt \\
                               & gdw. & es Belegung $V$ gibt mit $V \models \varphi$          \\
                               & gdw. & $\varphi$ erfüllbar
    \end{tabular}
  \end{center}

  \par\medskip
  \textsfbf{Erfüllbarkeit ist NP-hart.}~
  Dies folgt aus dem Theorem von Cook \& Levin
  % TODO: Skript-Referenz aktualisieren auf WiSe 16/17, SoSe 17;
  %       hier passenden Literaturverweis einfügen
  (siehe Skript "`Theoretische Informatik 2"' \cite{SkriptThI} oder die Literaturverweise dort).
  Der Beweis verwendet nur Formeln in KNF.
  Durch eine geeignete Reduktion kann man auch zeigen, dass 3SAT
  (d.\,h.\ Erfüllbarkeit der Einschränkung auf KNFs mit genau 3 Literalen pro Konjunkt)
  bereits NP-hart ist; siehe ebenfalls Theorie 2.
  Im Gegensatz dazu ist 2SAT in Polyzeit lösbar!

  \par\medskip
  \textsfbf{Gültigkeit ist coNP-vollständig.}~
  Die Dualität von Erfüllbarkeit und Gültigkeit (vorhergehendes Lemma)
  liefert eine Polynomialzeitreduktion des Gültigkeitsproblems
  auf das Erfüllbarkeitsproblem bzw.\ zurück.
  Daraus folgen dann coNP-Zugehörigkeit bzw.\ -Härte des Gültigkeitsproblems.\qedhere
\end{beweis}%

% ===================================================================
\section*{T1.10~ Beispiele für den Horn-Erfüllbarkeitsalgorithmus}

\textsfbf{Beispiel 1.}~
Betrachte die Horn-Formel auf der vorhergehenden Folie
(mit den Aussagenvariablen \textsf{Regen}, \textsf{Schnee}, \textsf{Niederschlag},
\textsf{Temp$\leq$0}, \textsf{Temp$<$0}).

Dann berechnet der Algorithmus
\begin{itemize}
  \item
    in Zeile 1:~ $V = \{\textsf{Regen},\textsf{Schnee}\}$
  \item
    in Zeilen 2--4:~ $V = \{\textsf{Regen},\textsf{Schnee}\} \cup \{\textsf{Temp$\leq$0}, \textsf{Temp$<$0}\}$
\end{itemize}
Wegen des Konjunkts $\textsf{Temp$\leq$0} \land \textsf{Temp$<$0} \to 0$
wird in Zeile 6 "`unerfüllbar"' zurückgegeben.

\par\medskip
\textsfbf{Beispiel 2.}~
Sei
$
  \varphi ~=~ x ~\land~ y ~\land~ (x \to z) ~\land~ (y \land z \to u) ~\land~ (u \land w \to 0).
$
Dann berechnet der Algorithmus
\begin{itemize}
  \item
    in Zeile 1:~ $V = \{x,y\}$
  \item
    in Zeilen 2--4: $V = \{x,y\} \cup \{z,u\}$ (2 Iterationen!)
\end{itemize}
Da der einzige Constraint in $\varphi$ das Konjunkt $u \land w \to 0$ ist
und nicht gleichzeitig $u$ und $w$ in $V$ sind,
wird in Zeile 8 "`erfüllbar"' zurückgegeben.


% ===================================================================
\section*{T1.11~ Korrektheit und Zeitbedarf des Horn-Algorithmus}

\textsfbf{Lemma 1.23.}~
Der Algorithmus für Erfüllbarkeit von Horn-Formeln ist korrekt
und läuft in polynomieller Zeit.

\par\noindent
\begin{beweis}
  ~\par
  \textsfbf{Zeitbedarf.}~
  Offensichtlich terminiert der Algorithmus auf jeder Eingabe $\varphi$
  nach maximal $|\textsf{Var}(\varphi)|$ Durchläufen der while-Schleife,
  also in polynomieller Zeit.

  \par\medskip
  \textsfbf{Korrektheit.}~
  Wir müssen zeigen:
  der Algorithmus antwortet bei Eingabe $\varphi$ "`erfüllbar"' gdw.\ $\varphi$ erfüllbar ist.
  \begin{description}
    \item[$(\Rightarrow)$]
      Angenommen, der Algorithmus antwortet bei Eingabe $\varphi$ "`erfüllbar"'.
      Sei $V$ die dabei berechnete Menge, betrachtet als Belegung.
      Wir zeigen: $V \models \varphi$.
      Dazu genügt es zu zeigen, dass für jedes Konjunkt $C$ von $\varphi$ gilt: $V \models C$.
      Sei also $C$ ein Konjunkt von $\varphi$. Wir unterscheiden drei Fälle.
      \begin{enumerate}
        \item
          $C = x$~ (Fakt).
          \par
          Dann ist $x \in V$ wegen Zeile 1 des Algorithmus, also $V \models x$.
        \item
          $C = x_1 \land \dots \land x_k \to x$~ (Regel).
          \par
          Wenn $\{x_1,\dots,x_k\} \nsubseteq V$,
          dann $V \models C$.
          Anderenfalls muss $x \in V$ sein (wegen Zeilen 2--4)
          und damit ebenfalls $V \models C$.
        \item
          $C = x_1 \land \dots \land x_k \to 0$~ (Constraint).
          \par
          Da der Algorithmus "`erfüllbar"' antwortet,
          muss wegen Zeile 5 $\{x_1,\dots,x_k\} \nsubseteq V$ gelten,
          also $V \models C$.
      \end{enumerate}
    \item[$(\Leftarrow)$]
      Angenommen $\varphi$ sei erfüllbar.
      Man zeigt leicht per Induktion über die Anzahl der Schleifendurchläufe
      in Zeilen 2--4:
      \begin{equation*}
        \tag{$*$}
        V \subseteq \widehat V \quad \text{für alle Modelle $\widehat V$ von $\varphi$}
      \end{equation*}
      Um nun zu zeigen, dass der Algorithmus "`erfüllbar"' antwortet,
      betrachten wir ein beliebiges Konjunkt $x_1 \land \dots \land x_k \to 0$ von $\varphi$.
      Für dieses müssen wir zeigen: $\{x_1,\dots,x_k\} \nsubseteq V$.
      Angenommen $\{x_1,\dots,x_k\} \subseteq V$.
      Da $\varphi$ nach Voraussetzung erfüllbar ist,
      gibt es ein Modell $\widehat V$ von $\varphi$.
      Mit $(*)$ gilt $\widehat V \models x_1 \land \dots \land x_k$,
      also $\widehat V \not\models x_1 \land \dots \land x_k \to 0$,
      was im Widerspruch zu $\widehat V \models \varphi$ steht.\qedhere
  \end{description}
%   ~\par\vspace*{-2.2\baselineskip}
\end{beweis}%

% ===================================================================
\section*{T1.12~ Nicht-Horn-Ausdrückbarkeit der Disjunktion}

\enlargethispage{7mm}
\textsfbf{Lemma 1.25~ (Nicht-Horn-Ausdrückbarkeit).}~
Keine Horn-Formel ist äquivalent zu $x \lor y$.

\par\noindent
\begin{beweis}
  Angenommen, es gäbe eine zu $x \lor y$ äquivalente Horn-Formel $\varphi$.
  Dann hätte $\varphi$ und damit auch $x \lor y$ ein minimales Modell $V$.
  Betrachte nun folgende Modelle von $x \lor y$:
  \[
    V_x = \{x\} \qquad V_y = \{y\}
  \]
  Offenbar sind beides Modelle von $x \lor y$.
  Für das minimale Modell $V$ müsste dann gelten:
  $V \subseteq V_x \cap V_y$, wegen Bedingung 2 für minimale Modelle.
  Also $V = \emptyset$, was aber kein Modell von $x \lor y$ ist.
  Damit haben wir einen Widerspruch zur Annahme gefolgert;
  diese muss also falsch sein.\qedhere
\end{beweis}%

% ===================================================================
\section*{T1.13~ Beweis Resolutionslemma}

\textsfbf{Lemma~1.28~ (Resolutionslemma).}~
Sei $M$ eine Klauselmenge, $C_1, C_2 \in M$ und $C$ die Resolvente von $C_1$ und $C_2$.
Dann gilt: $M \equiv M \cup \{C\}$

\par\noindent
\begin{beweis}
  Es ist zu zeigen, dass für alle Belegungen $V$ gilt:
  \begin{equation*}
    \tag{$*$}
    V \models M
    \qquad\text{gdw.}\qquad
    V \models M \cup \{C\}
  \end{equation*}
  Die Richtung "`$\Leftarrow$"' von $(*)$ ist dabei trivial,
  denn wenn $V$ alle Formeln in $M \cup \{C\}$ erfüllt,
  dann auch alle Formeln in $M$ (Teilmenge von $M \cup \{C\}$\,!).

  Für die Richtung "`$\Rightarrow$"' nehmen wir an, es gelte $V \models M$.
  Da $C$ die Resolvente von $C_1,C_2 \in M$ ist, gilt
  \[
    C ~=~ (C_1 \setminus \{\ell\}) ~\cup~ (C_2 \setminus \{\overline\ell\}).
  \]
  Wir unterscheiden zwei Fälle.
  \begin{enumerate}
    \item
      $V(\ell) = 1$.
      \par\smallskip
      Wegen $V \models C_2$ gilt dann auch $V \models C_2 \setminus \{\overline\ell\}$
      (denn das "`negative"' Disjunkt $\overline\ell$ kann nichts zur "`positiven"' Disjunktion $C_2$ beigetragen haben);
      also $V \models C$.
      \par\smallskip
    \item
      $V(\ell) = 0$.
      \par\smallskip
      Wegen $V \models C_1$ gilt dann auch $V \models C_1 \setminus \{\ell\}$
      (wie oben);
      also $V \models C$.\qedhere
  \end{enumerate}
%   ~\par\vspace*{-2.4\baselineskip}
\end{beweis}%

% ===================================================================
\section*{T1.14~ Beispiel für wiederholte Resolventenbildung}

Sei
$\varphi = x_1 \wedge (\neg x_1 \vee x_2) \wedge (\neg x_2 \vee x_3) \wedge \neg x_3$.

Dann ist $M = M(\varphi) = \big\{\, \{x_1\},\, \{\lnot x_1,x_2\},\, \{\lnot x_2,x_3\},\, \{\lnot x_3\}\, \big\}$
und somit $\textsf{Res}^0(M) = M$.
Wenn wir jeweils systematisch alle Paare von bisher erzeugten Klauseln durchgehen, so erhalten wir:
%
\begin{align*}
  \textsf{Res}^1(M) & = \textsf{Res}^0(M) \cup \big\{\, \{x_2\},\, \{\lnot x_1,x_3\},\, \{\lnot x_2\}\, \big\} \\
  \textsf{Res}^2(M) & = \textsf{Res}^1(M) \cup \big\{\, \{x_3\},\, \{\lnot x_1\},\, \Box\, \big\}              \\
  \textsf{Res}^3(M) & = \textsf{Res}^2(M)
\end{align*}
%
Also ist:
%
\begin{align*}
  \textsf{Res}^*(M) & = \textsf{Res}^3(M) \\
                    & = \big\{ \{x_1\},\;\! \{\lnot x_1,x_2\},\;\! \{\lnot x_2,x_3\},\;\! \{\lnot x_3\},\;\! \{x_2\},\;\! \{\lnot x_1,x_3\},\;\! \{\lnot x_2\},\;\!\{x_3\},\;\! \{\lnot x_1\},\;\! \Box \big\}\hspace*{-2pt}
\end{align*}

% ===================================================================
\newcommand{\TBewResSatzKorr}{T1.15}
\section*{\hypertarget{TBewResSatzKorr}{\TBewResSatzKorr}~ Beweis Resolutionssatz, Korrektheit}

\textsfbf{Behauptung:}~ \\
Wenn $M$ eine endliche Klauselmenge ist und $\Box \in \textsf{Res}^*(M)$,
dann ist $M$ unerfüllbar.

\par\noindent
\begin{beweis}
  Da $\Box \in \textsf{Res}^*(M)$, ist $\textsf{Res}^*(M)$ unerfüllbar.
  Es genügt zu zeigen: $\textsf{Res}^*(M) \equiv M$

  Mittels Resolutionslemma (Lemma~1.28) und per Induktion über $i$ zeigt man leicht:
  \[
%    \tag{$*$}
    \textsf{Res}^i(M) \equiv M \quad\text{für alle~} i \geq 0
  \]
  Wegen Lemma~1.30\,(2) ist $\textsf{Res}^*(M) = \textsf{Res}^i(M)$ für ein $i \geq 0$.
  Also $\textsf{Res}^*(M) \equiv M$.
  \qedhere
\end{beweis}

% ===================================================================
\section*{T1.16~ Beweis Resolutionssatz, Vollständigkeit}

\textsfbf{Lemma~1.32.}~
Wenn eine endliche Klauselmenge $M$ \emph{un}erfüllbar ist, dann gilt:
%
\begin{enumerate}
  \item[(1)]
    $M^+$ und $M^-$ sind \emph{un}erfüllbar;
  \item[(2)]
    $\Box \in \textsf{Res}^*(M)$ oder $\{\lnot x\} \in \textsf{Res}^*(M)$;
  \item[(3)]
    $\Box \in \textsf{Res}^*(M)$ oder $\{x\} \in \textsf{Res}^*(M)$;
  \item[(4)]
    $\Box \in \textsf{Res}^*(M)$.
\end{enumerate}

\par\noindent
\begin{beweis}
  \tikzset{baseline=5mm, grow=up, level distance=12mm, sibling distance=-18mm}
  \begin{description}
    \item[(1)]
%      ~\par
      Angenommen, $M^+$ sei erfüllbar und $V \models M^+$.
      Erweitere $V$ durch $V(x) = 1$.
      Man prüft leicht, dass $V \models M$ (klauselweise, Fallunterscheidung ob 
%              $C \in M^+$).
      $x \in C$ und Anwendung der Definition von $M^+$).
      Dies widerspricht der Annahme, dass $M$ unerfüllbar ist.
      Also ist $M^+$ unerfüllbar.

      Die Unerfüllbarkeit von $M^-$ wird analog begründet.
    \item[(2)--(4)]
      Wir gehen per Induktion über $|\textsf{Var}(M)|$ vor
      (denn jeder Resolutionsschritt entspricht dem Eliminieren einer Variable).
      %
      \begin{description}
        \item[Induktionsanfang.]
          ~\par
          Wenn $|\textsf{Var}(M)| = 0$, dann $M = \emptyset$ oder $M = \{\Box\}$.
          Der Fall $M = \emptyset$ wird dadurch ausgeschlossen, dass $\emptyset$ erfüllbar ist,%
          \footnote{%
            Zur Erinnerung: $V \models M$, wenn $V \models C$ für alle $C \in M$.
            Wenn also $M = \emptyset$, dann ist \emph{jede} Belegung $V$ Modell von $M$.
            Also ist $M = \emptyset$ erfüllbar.%
          }
          was der Voraussetzung widerspricht.
          Also $M = \{\Box\}$ und damit $\Box \in \textsf{Res}^*(M)$,
          wodurch (2)--(4) gezeigt sind.
        \item[Induktionsschritt.]
          ~\par
          \begin{description}
            \item[(2)]
        %      ~\par
              Wenn $|\textsf{Var}(M)| = n+1$, dann $|\textsf{Var}(M^+)| = n$,
              denn $x$ wurde gelöscht.
              Also kann man auf $M^+$ die Induktionsvoraussetzung anwenden:
              weil wegen~(1) $M^+$ unerfüllbar ist,
              gilt $\Box \in \textsf{Res}^*(M^+)$.
              Also gibt es Klauseln $C_1,\dots,C_m$, so dass $C_m = \Box$ 
              und für alle $i \leq m$ gilt:
              %
              \begin{enumerate}
                \item[(a)]
                  $C_i \in M^+$\quad oder
                \item[(b)]
                  $C_i$ ist Resolvente von $C_j$ und $C_k$ für gewisse $j,k < i$.
              \end{enumerate}
              %
              Nun können zwei Fälle eintreten:
              %
              \begin{enumerate}
                \item[(i)]
                  Alle Klauseln $C_i$ der Form (a) sind auch in $M$
                  (d.\,h.\ in keiner der "`Originalklauseln"' in $M$ kam $\lnot x$ vor).
                  Dann prüft man leicht, dass $C_1, \dots, C_m \in \textsf{Res}^*(M)$,
                  also insbesondere $\Box = C_m \in \textsf{Res}^*(M)$.
                \item[(ii)]
                  Für mindestens eine Klausel $C_i$ der Form (a) ist $C_i \cup \{\lnot x\} \in M$.
                  Wir erhalten durch Wiedereinfügen von $\lnot x$ eine Folge von Klauseln
                  \[
                    C_1',\dots,C_m' \in \textsf{Res}^*(M),
                  \]
                  die bezeugt, dass $\{\lnot x\} \in \textsf{Res}^*(M)$:
        
                  \begin{center}
        %                     \tikzset{>={Stealth[length=8pt, inset=1.6pt]}, baseline=-3pt}%
        %                     \tikzgraphsset{math nodes, nodes={draw,circle}, grow right=16mm, group shift=(-54:13mm)}%
                    aus~~
                    \tikz \node {$C_i$} child {node {$C_j$}} child {node {$C_k$}};
                    ~~wird~~
                    \tikz \node {$C_i \cup \{\lnot x\}$} child {node {$C_j \cup \{\lnot x\}$}} child {node {$C_k$}};
                  \end{center}
        
                  Wenn also das Literal $\lnot x$ an einer Stelle eingeführt wird,
                  dann wird es auch an die jeweilige Resolvente weitergegeben.
                  Am Ende wird aus $C_m = \Box$ dann $C'_m = \{\lnot x\}$,
                  also $\{\lnot x\} \in \textsf{Res}^*(M)$.
              \end{enumerate}
            \item[(3)]
        %      ~\par
              Wird analog zu (2) bewiesen, unter Verwendung von $M^-$ statt $M^+$.
            \item[(4)]          
%              Sei $|\textsf{Var}(M)| = n+1$ für ein $n \geq 0$.
%              Wähle eine Variable $x \in \textsf{Var}(M)$ und betrachten die Klauselmengen
%              $M^+$ und $M^-$, die auf Folien~55/56 definiert sind.
%              %
%              Aus Lemma 1.32~(2) und~(3) folgt nun, dass $\Box \in \textsf{Res}^*(M)$
              Aus~(2) und~(3) folgt, dass $\Box \in \textsf{Res}^*(M)$
              oder $\{x\},\{\lnot x\} \in \textsf{Res}^*(M)$.
              Aus letzterem folgt aber mit
              %
              \begin{center}
                \tikz \node {$\Box$} child {node {$\{\lnot x\}$}} child {node {$\{x\}$}};
              \end{center}
              %
              auch $\Box \in \textsf{Res}^*(M)$.
          \qedhere
          \end{description}
      \end{description}
  \end{description}
\end{beweis}

\pagebreak
% ===================================================================
\section*{T1.17~ Beispiel Einheitsresolution}

Gegeben sei die Klauselmenge
\[
  M = \big\{\{ \neg x_1, \neg x_2, \neg x_3, x_4 \},\, \{ x_1 \},\, \{ x_2 \},\, \{x_3\},\, \{ \neg x_3, \neg x_4 \}\big\}.
\]
Ein möglicher Resolutionsbeweis mittels Einheitsresolution ist folgender.

\begin{center}
%   \tikzset{node distance=30mm,on grid=false}
  \begin{tikzpicture}
    \node (0)                                   {$\{\lnot x_1, \lnot x_2, \lnot x_3, x_4\}$};
    \node (1) [right=10mm of 0]                 {$\{x_1\}$};
    \node (2) [right=10mm of 1]                 {$\{x_2\}$};
    \node (3) [right=10mm of 2]                 {$\{x_3\}$};
    \node (4) [right=10mm of 3]                 {$\{\lnot x_3,\lnot x_4\}$};
    \begin{scope}[on grid]
      \node (5) [below right=12mm and 15mm of 0] {$\{\lnot x_2, \lnot x_3, x_4\}$};
      \node (6) [below right=12mm and 15mm of 5] {$\{\lnot x_3, x_4\}$};
      \node (7) [below right=12mm and 15mm of 6] {$\{x_4\}$};
      \node (8) [below right=12mm and 15mm of 7] {$\{\lnot x_3\}$};
      \node (9) [below right=12mm and 15mm of 8] {$\Box$};
    \end{scope}
    \path (0) edge (5)
          (1) edge (5)
          (5) edge (6)
          (2) edge (6)
          (6) edge (7)
          (3) edge (7)
          (7) edge (8)
          (4) edge (8)
          (8) edge (9)
          (3) edge [bend left] (9);
  \end{tikzpicture}
\end{center}
Natürlich gibt es auch hier wieder mehrere Resolutionsbeweise;
entsprechend enthält $\textsf{ERes}^*(M)$ mehr Klauseln als die oben gezeigten.
Um $\textsf{ERes}^*(M)$ zu bestimmen, gehe vor wie in T1.14,
aber wende \emph{nur Einheitsresolution} an.


% ===================================================================
\section*{T1.18~ Beweis Resolutionssatz für Einheitsresolution}

\textsfbf{Theorem~1.37~ (Resolutionssatz für Einheitsresolution).} \\
Eine endliche Menge $M$ von Hornklauseln ist unerfüllbar ~gdw.~ $\Box \in \textsf{ERes}^*(M)$.

\par\noindent
\begin{beweis}
  \begin{description}
    \item[\textsfbf{Richtung {\boldmath "`$\Leftarrow$"'.}}]~
      (Korrektheit)
      \par
      Wie im Resolutionssatz (\hyperlink{TBewResSatzKorr}{\TBewResSatzKorr}),
      denn man zeigt genauso: $\textsf{ERes}^*(M) \equiv M$.
    \item[\textsfbf{Richtung {\boldmath "`$\Rightarrow$"'.}}]~
      (Vollständigkeit)
      \par
      Wir verwenden die Korrektheit unseres ursprünglichen Algorithmus
      für Erfüllbarkeit von Horn-Formeln (Folie~43).
      Setze in Analogie zu diesem Algorithmus:
      %
      \begin{align*}
        V^0     & = \big\{x \mid M \text{~enthält~} \{x\}\big\} \\
        V^{i+1} & = V^i \cup \big\{x \mid \text{es gibt~} x_1,\dots,x_k \in V_i \text{~mit~} \{\lnot x_1,\dots,\lnot x_k,x\} \in M\big\} \\[2mm]
        V^*     & = \displaystyle\bigcup_{i \geq 0} V^i
      \end{align*}
      %
      Mit der Korrektheit des ursprünglichen Algorithmus gilt:
      \[
        \tag{$*$}
        M \text{~ist unerfüllbar}
        \quad\text{gdw.}\quad
        \text{es $x_1,\dots,x_k \in V^*$ gibt mit~} \{\lnot x_1,\dots,\lnot x_k\} \in M
      \]
      Wir zeigen zunächst, dass für alle $i \geq 0$ gilt:
      \[
        \tag{$**$}
        x \in V^i
        \quad\text{impliziert}\quad
        \{x\} \in \textsf{ERes}^*(M)
      \]
      Dazu gehen wir per Induktion über $i$ vor.
      \begin{description}
        \item[Induktionsanfang.]
          ~\par
          Wenn $x \in V^0$, dann $\{x\} \in M$ nach Definition von $V^0$.
          Da $M \subseteq \textsf{ERes}^*(M)$,
          gilt auch $\{x\} \in \textsf{ERes}^*(M)$.
        \item[Induktionsschritt.]
          ~\par
          Sei $x \in V^{i+1}$.
          Wenn $x \in V^i$, dann folgt die Behauptung bereits nach Induktionsvoraussetzung.
          Wenn $x \notin V^i$, dann gibt es nach Definition von $V^{i+1}$
          Variablen $x_1,\dots,x_k \in V^i$ mit $\{\lnot x_1,\dots,\lnot x_k,x\} \in M$.
          Nach Induktionsvoraussetzung sind $\{x_1\},\dots,\{x_k\} \in \textsf{ERes}^*(M)$.
          Nun bezeugt die folgende Ableitung von $\{x\}$ mittels Einheitsresolution,
          dass $\{x\} \in \textsf{ERes}^*(M)$.
          \begin{center}
            \begin{tikzpicture}
              \node (0)                                   {$\{\lnot x_1, \dots, \lnot x_k, x\}$};
              \node (1) [right=10mm of 0]                 {$\{x_1\}$};
              \node (2) [right=10mm of 1]                 {$\dots$};
              \node (3) [right=10mm of 2]                 {$\{x_k\}$};
              \begin{scope}[on grid]
                \node (4) [below right=12mm and 15mm of 0] {$\{\lnot x_2, \dots, \lnot x_k, x\}$};
                \node (5) [below right=12mm and 15mm of 4,rotate=52] {\rule[-6pt]{0pt}{0pt}$\vdots$};
                \node (6) [below right=12mm and 15mm of 5] {$\{x\}$};
              \end{scope}
              \path (0) edge (4)
                    (1) edge (4)
                    (4) edge (5)
                    (5) edge (6)
                    (3) edge (6);
            \end{tikzpicture}
          \end{center}
          \vspace*{-1.7\baselineskip}
          ~\hspace*{\fill} Ende Beweis von $(**)$.
      \end{description}

      \par\bigskip\noindent
      Nun können wir mit $(*)$ und $(**)$ die gewünschte Implikation beweisen.
      Sei also $M$ unerfüllbar.
      Mit $(*)$ und $(**)$ gibt es $\{\lnot x_1,\dots\lnot x_k\} \in M$ mit $\{x_1\},\dots,\{x_k\} \in \textsf{ERes}^*(M)$.
      Folgende Ableitung mittels Einheitsresolution zeigt $\Box \in \textsf{ERes}^*(M)$.
      \begin{center}
        \begin{tikzpicture}
          \node (0)                                   {$\{\lnot x_1, \dots, \lnot x_k\}$};
          \node (1) [right=10mm of 0]                 {$\{x_1\}$};
          \node (2) [right=10mm of 1]                 {$\dots$};
          \node (3) [right=10mm of 2]                 {$\{x_k\}$};
          \begin{scope}[on grid]
            \node (4) [below right=12mm and 15mm of 0] {$\{\lnot x_2, \dots, \lnot x_k\}$};
            \node (5) [below right=12mm and 15mm of 4,rotate=52] {\rule[-6pt]{0pt}{0pt}$\vdots$};
            \node (6) [below right=12mm and 15mm of 5] {$\Box$};
          \end{scope}
          \path (0) edge (4)
                (1) edge (4)
                (4) edge (5)
                (5) edge (6)
                (3) edge (6);
        \end{tikzpicture}
      \end{center}
      ~\qedhere
  \end{description}
%   ~\par\vspace*{-2.2\baselineskip}
\end{beweis}%

\pagebreak
% ===================================================================
\section*{T1.19~ Beispiel DPLL-Algorithmus}

Sei $M = \big\{\{x_1, \neg x_2, x_3\},\, \{\neg x_1, x_2, \neg x_3\},\, \{\neg x_1, x_3, \neg x_4\},\, \{\neg x_1, x_3\}\big\}$.

\par\medskip\noindent
\fbox{\parbox{.95\textwidth}{%
  \textsfbf{Aufruf \texttt{DPLL}$(M)$}
  %
  \begin{itemize}
    \item
      \emph{Einheitsklauseln vorhanden?}\quad Nein.
    \item
      \emph{$\Box$ vorhanden?}\quad Nein.
    \item
      \emph{Pure Literale vorhanden?}\quad Ja, und zwar $\lnot x_4$ (und kein weiteres).

      Also lösche die vorletzte Klausel, d.\,h.
      \par\vspace*{-.8\baselineskip}
      \[
        M = \big\{\{x_1, \neg x_2, x_3\},\, \{\neg x_1, x_2, \neg x_3\},\, \{\neg x_1, x_3\}\big\}.
      \]
      \par\vspace*{-.6\baselineskip}
    \item
      \emph{$M = \emptyset$\,?}\quad Nein.
    \item
      \emph{Nichtdeterministische Verzweigung}

      Wähle $\ell=x_1$ (d.\,h.\ "`probiere"' $V(x_1) = 1$).

      \fbox{\parbox{.85\textwidth}{%
        \textsfbf{Aufruf \texttt{DPLL}$\big(\big\{\{x_1, \neg x_2, x_3\},\, \{\neg x_1, x_2, \neg x_3\},\, \{\neg x_1, x_3\},\, \{x_1\}\big\}\big)$}
        %
        \begin{itemize}
          \item[$\bullet$]
            \emph{Einheitsklauseln vorhanden?}\quad Ja, und zwar $\{x_1\}$.
            %
            \begin{itemize}
              \item[--]
                \emph{Unit Subsumption:}~ Lösche alle Klauseln, die $x_1$ enthalten.
                \par\vspace*{-.5\baselineskip}
                \[
                  M = \big\{\{\neg x_1, x_2, \neg x_3\},\, \{\neg x_1, x_3\}\big\}
                \]
                \par\vspace*{-.1\baselineskip}
              \item[--]
                \emph{Unit Resolution:}~ Lösche $\lnot x_1$ aus den übrigen Klauseln.
                \par\vspace*{-.5\baselineskip}
                \[
                  M = \big\{\{x_2, \neg x_3\},\, \{x_3\}\big\}
                \]
                \par\vspace*{-.1\baselineskip}
            \end{itemize}
          \item[$\bullet$]
            \emph{Einheitsklauseln vorhanden?}\quad Ja, und zwar $\{x_3\}$.
            %
            \begin{itemize}
              \item[--]
                \emph{Unit Subsumption:}~ Lösche alle Klauseln, die $x_3$ enthalten.
%                 \par\vspace*{-.5\baselineskip}
%                 \[
%                   M = \big\{\{x_2, \neg x_3\}\big\}
%                 \]
%                 \par\vspace*{-.1\baselineskip}
              \item[--]
                \emph{Unit Resolution:}~ Lösche $\lnot x_3$ aus den übrigen Klauseln.
                \par\vspace*{-.5\baselineskip}
                \[
                  M = \big\{\{x_2\}\big\}
                \]
                \par\vspace*{-.1\baselineskip}
            \end{itemize}
          \item[$\bullet$]
            \emph{Einheitsklauseln vorhanden?}\quad Ja, und zwar $\{x_2\}$.
            %
            \begin{itemize}
              \item[--]
                \emph{Unit Subsumption:}~ Lösche alle Klauseln, die $x_2$ enthalten.
                \par\vspace*{-.5\baselineskip}
                \[
                  M = \emptyset
                \]
                \par\vspace*{-.1\baselineskip}
              \item[--]
                \emph{Unit Resolution:}~ Keine Veränderung, da $M$ leer ist.
            \end{itemize}
          \item[$\bullet$]
            \emph{$\Box$ vorhanden?}\quad Nein.
          \item[$\bullet$]
            \emph{Pure Literale vorhanden?}\quad Nein.
          \item[$\bullet$]
            \emph{$M = \emptyset$\,?}\quad Ja\quad $\Rightarrow$ \textbfsf{Ausgabe "`erfüllbar"'}
        \end{itemize}
        ~\par\vspace*{-1\baselineskip}
      }}

      \par\smallskip
      $\Rightarrow$ \textbfsf{Ausgabe "`erfüllbar"'}
  \end{itemize}
  ~\par\vspace*{-1.4\baselineskip}
}}

% ===================================================================
\section*{T1.20~ Beispiel Hilbert-Kalkül}

Die Formel $x \to x$ ist herleitbar:

\par\medskip\noindent
\begin{tabular}{l@{~~}ll@{}}
  (a) & $x \to \big((y \to x) \to x\big)$                          & Instanz von Axiom 1 \\
      &                                                            & mit~ $\varphi = x$ und $\psi = (y \to x)$ \\[12pt]
  (b) & $\Big(x \to \big((y \to x) \to x\big)\Big)$                & Instanz von Axiom 2 \\[-1pt]
      & ${} \to \Big(\big(x \to (y \to x)\big) \to (x \to x)\Big)$ & \raisebox{8pt}{mit~ $\varphi = x$,~ $\psi = (y \to x)$,~ $\vartheta = x$} \\[12pt]
  (c) & $\big(x \to (y \to x)\big) \to (x \to x)$                  & Modus Ponens (MP) angewandt auf (a), (b) \\[12pt]
  (d) & $x \to (y \to x)$                                          & Instanz von Axiom 1 \\
      &                                                            & mit~ $\varphi = x$ und $\psi = y$ \\[12pt]
  (e) & $x \to x$                                                  & MP angewandt auf (c), (d)
\end{tabular}

%% ===================================================================
%\section*{T1.21~ Beispiel 4-Färbbarkeit}
%
%Der folgende ungerichtete Graph modelliert die Grenzbeziehungen europäischer Länder:
%seine Knoten sind Ländernamen (im Bild mit den üblichen Kürzeln\footnote{\url{https://de.wikipedia.org/wiki/ISO-3166-1-Kodierliste}}),
%und es gibt eine Kante zwischen zwei Ländern, wenn diese eine gemeinsame Grenz\emph{linie} haben.
%\begin{center}
%  \begin{tikzpicture}[node distance=18mm]
%    \node (DK)                                   {DK};
%    \node (DE) [below=9mm of DK]                 {DE};
%    \node (NL) [left of=DE]                      {NL};
%    \node (BE) [below=8mm of NL]                 {BE};
%    \node (LU) [below right=1.5mm and 2mm of BE] {LU};
%    \node (FR) [below=10mm of BE]                {FR};
%    \node (ES) [below left=5mm and 4mm of FR]    {ES};
%    \node (PT) [below left=5mm and 4mm of ES]    {PT};
%    \node (PL) [right of=DE]                     {PL};
%    \node (CZ) [below=9mm of PL]                 {CZ};
%    \node (AT) [below=9mm of CZ]                 {AT};
%    \node (CH) [right of=FR]                     {CH};
%    \node (LI) [below right=2.5mm and 2mm of CH] {LI};
%    \node (IT) [below=8mm of LI]                 {IT};
%    \path (DK) edge (DE)
%          (DE) edge (NL)
%          (DE) edge (BE)
%          (DE) edge (LU)
%          (DE) edge [out=260,in=10] (FR)
%          (DE) edge (CH)
%          (DE) edge (AT)
%          (DE) edge (CZ)
%          (DE) edge (PL)
%          (NL) edge (BE)
%          (BE) edge (LU)
%          (BE) edge (FR)
%          (LU) edge (FR)
%          (FR) edge (ES)
%          (ES) edge (PT)
%          (FR) edge (CH)
%          (FR) edge (IT)
%          (CH) edge (IT)
%          (CH) edge (LI)
%          (CH) edge (AT)
%          (AT) edge (LI)
%          (AT) edge (IT)
%          (PL) edge (CZ)
%          (CZ) edge (AT);
%  \end{tikzpicture}
%\end{center}
%Dieser Graph ist planar, also kann er laut 4-Farben-Satz (endliche Variante) mit 4 Farben gefärbt werden -- probiert es aus.

% ===================================================================
\section*{T1.21~ Beweis 4-Farben-Satz (unendliche Variante)}

\textsfbf{Theorem~1.44~ (4-Farben-Satz, beliebige Graphen).} \\
Jeder (möglicherweise unendliche) planare Graph ist 4-färbbar.

\par\noindent
\begin{beweis}
  Sei $G=(V,E)$ ein (möglicherweise unendlicher) planarer Graph.
  Definiere folgende Formelmenge.
  \begin{align*}
    \Gamma & = \{x_{v1} \lor x_{v2} \lor x_{v3} \lor x_{v4} \mid v \in V\} \\
           & \quad \cup \{\lnot (x_{vi} \land x_{vj} \mid v \in V,~ 1 \leq i < j \leq 4\} \\
           & \quad \cup \{\lnot (x_{vi} \land x_{wi} \mid \{v,w\} \in E,~ 1 \leq i \leq 4\}
  \end{align*}
  Wir haben also für jeden Knoten $v \in V$ vier Aussagenvariablen $x_{vi}$, $1 \leq i \leq 4$, eingeführt.
  Intuitiv steht $x_{vi}$ für: "`Knoten $v$ ist mit Farbe $i$ gefärbt"'.
  Die Formeln in $\Gamma$ drücken nun aus, dass es sich um eine zulässige Färbung handelt:
  \begin{itemize}
    \item
      Jeder Knoten ist mit mindestens einer Farbe gefärbt (1.\ Zeile).
    \item
      Jeder Knoten ist mit höchstens einer Farbe gefärbt (2.\ Zeile).
    \item
      Keine zwei benachbarten Knoten sind mit derselben Farbe gefärbt (3.\ Zeile).
  \end{itemize}
  Insbesondere entspricht jede erfüllende Belegung für $\Gamma$ einer zulässigen 4-Färbung von $G$ und umgekehrt.
  Es genügt also zu zeigen, dass $\Gamma$ erfüllbar ist.
  Wegen des Kompaktheitssatzes genügt es zu zeigen:

  \par\smallskip\noindent
  \textsfbf{Behauptung.}~
  Jede endliche Teilmenge $\Delta \subseteq \Gamma$ ist erfüllbar.

  \par\smallskip\noindent
  \textsfbf{Beweis der Behauptung.}~
  Sei $\Delta \subseteq \Gamma$ endlich.
  Sei $V' \subseteq V$ die Menge der Knoten $v \in V$,
  sodass $x_{vi}$ in $\Delta$ vorkommt für mindestens ein $i$.
  Wir betrachten den endlichen Teilgraphen $G'$ von $G$,
  den man durch Einschränkung auf die Knotenmenge $V'$ erhält.
  $G'$ ist ein endlicher planarer Graph,
  also laut 4-Farben-Satz (endliche Variante) 4-färbbar,
  und jede 4-Färbung liefert eine erfüllende Belegung für $\Delta$.
  
  \par\smallskip\noindent
  Wegen der Behauptung und dem Kompaktheitssatz ist $\Gamma$ erfüllbar.
  Jede erfüllende Belegung liefert eine 4-Färbung von $G$.  
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T1.22~ Beweis Kompaktheitssatz}

\textsfbf{Theorem~1.41~ (Kompaktheitssatz).} \\
Für alle (potentiell unendlichen) Mengen $\Gamma \subseteq \textsf{AL}$ gilt:
\begin{center}
  $\Gamma$  ist erfüllbar gdw.\ jede endliche Teilmenge von $\Gamma$ erfüllbar ist.
\end{center}

\par\noindent
\begin{beweis}
  Die Richtung "`$\Rightarrow$"' ist trivial,
  wenn man sich die Definition der Erfüllbarkeit für Formel\emph{mengen} in Erinnerung ruft (Folie~72).

  Um "`$\Leftarrow$"' zu zeigen,
  nennen wir fortan eine Menge $\Gamma \subseteq \textsf{AL}$ \emph{Limit-erfüllbar},
  wenn alle endlichen Teilmengen von $\Gamma$ erfüllbar sind.
  Wir müssen also zeigen:
  \begin{center}
    Wenn $\Gamma$ Limit-erfüllbar ist, dann ist $\Gamma$ erfüllbar.
  \end{center}
  Sei also $\Gamma$ Limit-erfüllbar.
  Da die Menge $\textsf{Var}$ aller Aussagenvariablen abzählbar ist,
  gibt es eine Aufzählung
  \[
    \varphi_1,\varphi_2,\varphi_3,\dots
  \]
  von \textsf{AL}.%
  \footnote{
    Da sowohl die Formellänge als auch die Anzahl der Variablen unbegrenzt wachsen können,
    darf man die Formeln nicht lexikographisch aufzählen,
    sondern muss \emph{Dove tailing} verwenden.%
  }
  Wir wollen nun $\Gamma$ in dem Sinne "`vervollständigen"',
  dass für jede Formel $\varphi_i$ entweder $\varphi_i$ oder $\lnot\varphi_i$
  enthalten ist.
  Dies tun wir schrittweise, indem wir eine aufsteigende Folge
  \[
    \Gamma = \Gamma_0 \subseteq \Gamma_1 \subseteq \Gamma_2 \subseteq \dots
  \]
  von Limit-erfüllbaren Formelmengen $\Gamma_i$ wie folgt konstruieren.
  Um zu beschreiben, wie man $\Gamma_{i+1}$ aus $\Gamma_i$ erhält,
  beobachten wir zunächst:
  %
  \begin{description}
    \item[Behauptung.]~
      $\Gamma_i \cup \{\varphi_{i+1}\}$ oder
      $\Gamma_i \cup \{\lnot \varphi_{i+1}\}$ ist Limit-erfüllbar.
    \item[Beweis der Behauptung.]
      Per Kontraposition: wir nehmen an, dass beide Mengen nicht Limit-erfüllbar seien.
      Also gibt es endliche Mengen $\Delta,\Delta' \subseteq \Gamma_i$,
      so dass $\Delta \cup \{\varphi_{i+1}\}$ und
      $\Delta' \cup \{\lnot\varphi_{i+1}\}$ unerfüllbar sind.
      Dann ist $\Delta \cup \Delta' \subseteq \Gamma_i$ unerfüllbar.
      Dies steht jedoch im Widerspruch zur Limit-Erfüllbarkeit von $\Gamma_i$.
  \end{description}
  %
  Nun setzen wir:
  \[
    \Gamma_{i+1} = \begin{cases}
                     \Gamma_i \cup \{\varphi_{i+1}\}       & \text{falls~} \Gamma_i \cup \{\varphi_{i+1}\} \text{~Limit-erfüllbar ist} \\
                     \Gamma_i \cup \{\lnot \varphi_{i+1}\} & \text{sonst}
                   \end{cases}
  \]
  Sei weiterhin:
  \[
    \Gamma_\omega = \bigcup_{i \geq 0} \Gamma_i
  \]
  Da alle $\Gamma_i$ Limit-erfüllbar sind, ist dies auch $\Gamma_\omega$:
  %
  \begin{description}
    \item[Behauptung.]~
      \[
        \tag{$*$}
        \Gamma_\omega \text{~ist Limit-erfüllbar.}
      \]

    \item[Beweis der Behauptung.]
      Angenommen, dies sei nicht der Fall.
      Dann gibt es eine endliche Teilmenge $\Delta \subseteq \Gamma_\omega$,
      die unerfüllbar ist.
      Da $\Delta$ endlich ist, gibt es ein $\ell \geq 0$ mit $\Delta \subseteq \Gamma_\ell$.
      Dann wäre aber $\Gamma_\ell$ auch nicht Limit-erfüllbar,
      was der obigen Definition der $\Gamma_\ell$ widerspricht.
  \end{description}
  %
  Wir verwenden nun die Definition und Limit-Erfüllbarkeit von $\Gamma_\omega$,
  um eine erfüllende Belegung für $\Gamma_\omega$ zu konstruieren.
  Diese ist wegen $\Gamma \subseteq \Gamma_\omega$ dann auch die gewünschte
  erfüllende Belegung für $\Gamma$.
  Wir definieren $V$ wie folgt.
  \[
    V(x) = \begin{cases}
             1 & \text{wenn~} x \in \Gamma_\omega \\
             0 & \text{sonst (d.\,h.\ $\lnot x \in \Gamma_\omega$)}
           \end{cases}
  \]
  Wir brauchen nur noch zu zeigen: $V \models \Gamma_\omega$.
  Dazu zeigen wir per Induktion über die Struktur von $\varphi$:
  \[
    V \models \varphi
    \quad\text{gdw.}\quad
    \varphi \in \Gamma_\omega
    \qquad\text{für alle $\varphi \in \textsf{AL}$}
  \]
  \begin{description}
    \item[Induktionsanfang.]
      Wenn $\varphi$ Variable ist, dann folgt die Behauptung aus der Definition von $V$.
      Die Konstante 1 (bzw.\ 0) ist nach Konstruktion in $\Gamma_\omega$
      enthalten (bzw.\ nicht enthalten).
    \item[Induktionsschritt.]
      Hier genügt es zwei Fälle zu unterscheiden:
      \begin{itemize}
        \item
          $\varphi = \lnot \psi$.
          \par
          Dann gilt:
          \begin{xalignat*}{2}
            V \models \varphi & ~~\text{gdw.}~~ V \not\models \psi        & & \text{(Semantik von $\lnot$)}    \\
                              & ~~\text{gdw.}~~ \psi \notin \Gamma_\omega & & \text{(Induktionsvoraussetzung)} \\
                              & ~~\text{gdw.}~~ \varphi \in \Gamma_\omega & & \text{(Konstruktion von $\Gamma_\omega$)}
          \end{xalignat*}
        \item
          $\varphi = \psi \land \vartheta$.
          \par
          Für die Richtung "`$\Rightarrow$"' nehmen wir $V \models \varphi$ an,
          d.\,h.\ $V \models \psi$ und $V \models \vartheta$.
          Nach Induktionsvoraussetzung gilt dann auch $\psi \in \Gamma_\omega$ und $\vartheta \in \Gamma_\omega$.
          Nach Konstruktion von $\Gamma_\omega$ muss eine der beiden Formeln $\psi \land \vartheta$
          und $\lnot(\psi \land \vartheta)$ in $\Gamma_\omega$ enthalten sein.
          Wenn $\lnot(\psi \land \vartheta)$ enthalten wäre,
          dann wäre $\{\psi,\vartheta,\lnot(\psi \land \vartheta)\}$ eine unerfüllbare Teilmenge von $\Gamma_\omega$,
          was im Widerspruch zu $(*)$ stünde.
          Also $\psi \land \vartheta \in \Gamma_\omega$, wie gewünscht.
          \par
          Für die Richtung "`$\Leftarrow$"' nehmen wir $\psi \land \vartheta \in \Gamma_\omega$ an.
          Dann sind auch $\psi,\vartheta \in \Gamma_\omega$:
          wäre z.\,B.\ $\psi \notin \Gamma_\omega$, dann wäre
          $\lnot\psi \in \Gamma_\omega$, und damit wäre
          $\{\psi \land \vartheta,\lnot\psi\} \subseteq \Gamma_\omega$
          eine unerfüllbare Teilmenge, im Widerspruch zu $(*)$ -- und analog für $\vartheta$.
          Nach Induktionsvoraussetzung folgt nun $V \models \psi$ und $V \models \vartheta$,
          also $V \models \psi \land \vartheta$.\qedhere
      \end{itemize}
  \end{description}
% ~\par\vspace*{-2.4\baselineskip}
\end{beweis}%


% ===================================================================
% ===================================================================
% ===================================================================
\part{Prädikatenlogik Grundlagen}

% ===================================================================
\section*{T2.1~ Beispiel: Strukturen als kantenbeschriftete Graphen}

Sei $\mathfrak{A} = (A, P_1^{\mathfrak{A}}, P_2^{\mathfrak{A}}, P_3^{\mathfrak{A}})$ mit
\begin{align*}
  A                  & = \{x,y,z\}                 \\
  P_1^{\mathfrak{A}} & = \{(x,y),\,(x,z)\}         \\
  P_2^{\mathfrak{A}} & = \{(x,y),\,(y,z),\,(z,x)\} \\
  P_3^{\mathfrak{A}} & = \{(z,z)\}
\end{align*}
Diese Struktur entspricht dem folgenden Graphen.
\begin{center}
  \begin{tikzpicture}[%
    >=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=8mm},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (x)                                   {$x$};
    \node[state] (y) [above right= 10mm and 30mm of x] {$y$};
    \node[state] (z) [below right= 10mm and 30mm of x] {$z$};
    \path[->] (x) edge                node [above left]  {$P_1,P_2$} (y)
              (x) edge[bend right=15] node [below left]  {$P_1$}     (z)
              (z) edge[bend right=15] node [above right] {$P_2$}     (x)
              (y) edge                node [right]       {$P_2$}     (z)
              (z) edge[loop right]    node [right]       {$P_3$}     ();
  \end{tikzpicture}
\end{center}

% ===================================================================
\section*{T2.2~ Beispiel: Struktur für die drei Blöcke R, G, B}

Da die gegebene Struktur nur unäre und binäre Relationssymbole enthält,
kann man sie leicht als Graph darstellen:
\begin{center}
  \begin{tikzpicture}[%
    node distance=30mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=8mm},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (bb)                    {bb};
    \node[state] (rb) [right=of bb]      {rb};
    \node[state] (gb) [above=20mm of rb] {gb};
    \path[->] (bb) edge[bend right=15] node [below] {\textsf{neben}} (rb)
              (rb) edge[bend right=15] node [above] {\textsf{neben}} (bb)
              (rb) edge[bend right=15] node [right] {\textsf{unter}} (gb)
              (gb) edge[bend right=15] node [left]  {\textsf{auf}}   (rb);
    \node (lbb) [left=1mm of bb]  {\textsf{\begin{tabular}{@{}r@{}}Block\\B\end{tabular}}};
    \node (lgb) [right=1mm of gb] {\textsf{\begin{tabular}{@{}l@{}}G\\Block\end{tabular}}};
    \node (lrb) [right=1mm of rb] {\textsf{\begin{tabular}{@{}l@{}}R\\Block\\lieblingsblock\end{tabular}}};
  \end{tikzpicture}
\end{center}

% ===================================================================
\section*{T2.3~ Beispiel: Struktur für Film-Datenbank}

Die Struktur ist $\Amf = (A, \textsf{Film}^\Amf, \textsf{Schauspieler\_in}^\Amf)$ mit
%
\begin{align*}
  A                              & = \big\{\,\text{Die Vögel},~ \text{Marnie},~ \text{Goldfinger},~ 1963,~ 1964,                \\[-2pt]
                                 & \hspace*{7.5mm}\,\text{Hitchcock},~ \text{Hamilton},~ \text{Connery},~ \text{Hedren}\,\big\} \\[2pt]
  \textsf{Film}^\Amf             & = \big\{\,(\text{Die Vögel},\, \text{1963},\, \text{Hitchcock}),                             \\[-2pt]
                                 & \hspace*{7.5mm}\,(\text{Marnie},\, \text{1963},\, \text{Hitchcock}),                         \\[-2pt]
                                 & \hspace*{7.5mm}\,(\text{Goldfinger},\, \text{1964},\, \text{Hamilton})\,\big\}               \\[2pt]
  \textsf{Schauspieler\_in}^\Amf & = \big\{\,(\text{Connery},\, \text{Marnie}),                                                 \\[-2pt]
                                 & \hspace*{7.5mm}\,(\text{Connery},\, \text{Goldfinger}),                                      \\[-2pt]
                                 & \hspace*{7.5mm}\,(\text{Hedren},\, \text{Marnie})\,\big\}
\end{align*}
%
Da $\textsf{Film}^\Amf$ eine ternäre Relation ist, kann man $\Amf$ höchstens als Hypergraphen darstellen.
Das ist aber kaum übersichtlicher als die Tupel-Schreibweise.

% ===================================================================
\section*{T2.4~ Beispiel: Struktur für XML-Dokument}

Die Struktur ist $\Amf = (A, \textsf{succ}^\Amf, \textsf{sord}^\Amf, \textsf{inventory}^\Amf, \textsf{drink}^\Amf, \dots, \textsf{amount}^\Amf)$ mit
%
\begin{align*}
  A                       & = \{\varepsilon,0,1,00,01,11,000,001,010,011,110,111\}   \\[2pt]
  \textsf{succ}^\Amf      & = \{(w,w0) \mid w0 \in A\} \cup \{(w,w1) \mid w1 \in A\} \\[2pt]
  \textsf{sord}^\Amf      & = \{(w0,w1) \mid w0,w1 \in A\}                           \\[2pt]
  \textsf{inventory}^\Amf & = \{\varepsilon\}                                        \\[2pt]
                          & ~\,\vdots                                                \\[2pt]
%   \textsf{price}^\Amf     & = \{000,010,110\}                                        \\[2pt]
  \textsf{amount}^\Amf     & = \{001,011,111\}
\end{align*}
%
Als Bild:

\par\vspace*{-1.5\baselineskip}
\begin{center}
  \begin{tikzpicture}[%
%     parent anchor=east, child anchor=west, grow=east,
%     sibling distance=15mm, level distance=15mm,
    every node/.style = {ellipse, draw=black, fill=black!10, inner sep=1mm, minimum size=4mm},
    level 1/.style = {sibling distance = 55mm},
    level 2/.style = {sibling distance = 40mm},
    level 3/.style = {sibling distance = 20mm},
    edge from parent/.style = {draw=black, thin, -Latex}%
  ]
    \node[inner sep=1.7mm] (eps) {$\varepsilon$}
      child {
        node (0) {\,0\,}
        child {
          node (00) {00}
          child {
            node (000) {000}
          }
          child {
            node (001) {001}
          }
        }
        child {
          node (01) {01}
          child {
            node (010) {010}
          }
          child {
            node (011) {011}
          }
        }
        edge from parent node[above left, draw=none, fill=none] {\textsf{succ}}
      }
      child {
        node (1) {\,1\,}
        child [missing] {node {10}}
        child {
          node (11) {11}
          child {
            node (110) {110}
          }
          child {
            node (111) {111}
          }
        }
        edge from parent node[above right, draw=none, fill=none] {\textsf{succ}}
      };

    \path[dashed, -Latex, every node/.style = {}]
      (0)   edge[bend right=10] node[above] {\textsf{sord}} (1)
      (00)  edge[bend right=20] node[above] {\textsf{sord}} (01)
%       (000) edge[bend right=40] node[below] {\textsf{sord}} (001)
%       (010) edge[bend right=40] node[below] {\textsf{sord}} (011)
%       (110) edge[bend right=40] node[below] {\textsf{sord}} (111);
      (000) edge[bend right=40] (001)
      (010) edge[bend right=40] (011)
      (110) edge[bend right=40] (111);

%     \draw[dashed,-Latex,bend right=10] (0)--(1);
%     \draw[dashed,-Latex,bend right=20] (00)--(01);
%     \draw[dashed,-Latex,bend right=40] (000)--(001);
%     \draw[dashed,-Latex,bend right=40] (010)--(011);
%     \draw[dashed,-Latex,bend right=40] (110)--(111);

    \node [draw=none, fill=none, above right=0mm and -1mm of eps]  {\textsf{inventory}};
    \node [draw=none, fill=none, above left =0mm and -1mm of 0]    {\textsf{drink}};
    \node [draw=none, fill=none, above right=0mm and -1mm of 1]    {\textsf{snack}};
    \node [draw=none, fill=none, above left =0mm and -1mm of 00]   {\textsf{lemonade}};
    \node [draw=none, fill=none, above right=0mm and -1mm of 01]   {\textsf{pop}};
    \node [draw=none, fill=none, above right=0mm and -1mm of 11]   {\textsf{chips}};
    \node [draw=none, fill=none, below left =.5mm and -6mm of 000] {\textsf{price}};
    \node [draw=none, fill=none, below left =.5mm and -6mm of 010] {\textsf{price}};
    \node [draw=none, fill=none, below left =.5mm and -6mm of 110] {\textsf{price}};
    \node [draw=none, fill=none, below right=.8mm and -8mm of 001] {\textsf{amount}};
    \node [draw=none, fill=none, below right=.8mm and -8mm of 011] {\textsf{amount}};
    \node [draw=none, fill=none, below right=.8mm and -8mm of 111] {\textsf{amount}};
  \end{tikzpicture}%
\end{center}

% ===================================================================
\section*{T2.5~ Beispiel: Ordnungen als Strukturen}

Betrachte zwei kommunizierende Prozesse. Wir verwenden 4 unäre Relationssymbole:
%
\begin{itemize}
  \item
    $W_i$: Prozess $i$ wartet auf Eintritt in den kritischen Abschnitt
  \item
    $A_i$: Prozess $i$ ist im kritischen Abschnitt
\end{itemize}
%
mit $i \in \{1,2\}$.

Jede Struktur $\Amf = (\mathbb{N}, <, W_1^\Amf, W_2^\Amf, A_1^\Amf, A_2^\Amf)$
modelliert dann einen zeitlichen Verlauf der beiden Prozesse, z.\,B.:

\par\smallskip
\begin{tikzpicture}[%
  node distance=17.35mm, >=Latex,
  every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=8mm},
  every edge/.style={draw=black,thin}
]
  \node[state] (0)                 {0};
  \node[state] (1)    [right of=0] {1};
  \node[state] (2)    [right of=1] {2};
  \node[state] (3)    [right of=2] {3};
  \node[state] (4)    [right of=3] {4};
  \node[state] (5)    [right of=4] {5};
  \node[state] (6)    [right of=5] {6};
  \node[state] (7)    [right of=6] {7};
  \node        (dots) [right of=7] {\dots};
  \path[->] (0) edge                node [above]  {$<$} (1)
            (1) edge                node [above]  {$<$} (2)
            (2) edge                node [above]  {$<$} (3)
            (3) edge                node [above]  {$<$} (4)
            (4) edge                node [above]  {$<$} (5)
            (5) edge                node [above]  {$<$} (6)
            (6) edge                node [above]  {$<$} (7)
            (7) edge                node [above]  {$<$} (dots)
            (0) edge[bend left=35]  node [above]  {$<$} (2)
            (1) edge[bend left=35]  node [above]  {$<$} (3)
            (0) edge[bend left=55]  node [above]  {$<$} (3);
  \node (l1) [below=0mm of 1]  {\begin{tabular}{@{}c@{}}$W_1$\end{tabular}};
  \node (l2) [below=0mm of 2]  {\begin{tabular}{@{}c@{}}$A_1$\end{tabular}};
  \node (l4) [below=0mm of 4]  {\begin{tabular}{@{}c@{}}$W_2$\end{tabular}};
  \node (l5) [below=0mm of 5]  {\begin{tabular}{@{}c@{}}$A_2$\\$W_1$\end{tabular}};
  \node (l6) [below=0mm of 6]  {\begin{tabular}{@{}c@{}}$A_2$\\$W_1$\end{tabular}};
  \node (l7) [below=0mm of 7]  {\begin{tabular}{@{}c@{}}$A_1$\end{tabular}};
  \node (ld) [above=4mm of 3]  {\dots};
\end{tikzpicture}

\par\smallskip
Diese Struktur modelliert einen möglichen Verlauf, und zwar denjenigen, in dem
\begin{itemize}
  \item
    Prozess 1 in Zeitpunkt 1 auf den kritischen Bereich wartet,
    diesen in Zeitpunkt 2 betritt und in Zeitpunkt 3 wieder verlässt,
  \item
    Prozess 2 in Zeitpunkt 4 auf den kritischen Bereich wartet,
    diesen in Zeitpunkt 5 betritt und erst in Zeitpunkt 7 wieder verlässt,
  \item
    Prozess 1 in Zeitpunkten 5 und 6 auf den kritischen Bereich wartet,
    diesen (wegen Prozess 2) erst in Zeitpunkt 7 betritt\qquad usw.
\end{itemize}

% ===================================================================
\section*{T2.6~ Beispiel: Zuweisung}

Betrachte folgende Struktur $\Amf$ mit unären Funktionssymbolen $f,g$
und Konstante $c$.

\begin{center}
  \begin{tikzpicture}[%
    node distance=30mm, >=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=8mm},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (a1)                                  {$a_1$};
    \node[state] (a2) [above right=3mm and 15mm of a1] {$a_2$};
    \node[state] (a3) [below right=3mm and 15mm of a2] {$a_3$};
    \node[state] (a4) [below right=3mm and 15mm of a1] {$a_4$};
    \path[->] (a1) edge             node [above left]  {$g$} (a2)
              (a2) edge             node [above right] {$f$} (a3)
              (a3) edge             node [below right] {$f,g$} (a4)
              (a4) edge             node [below left]  {$f$} (a1)
              (a2) edge             node [right]       {$g$} (a4)
              (a1) edge[loop left]  node [left]        {$f$} ()
              (a4) edge[loop below] node [above right] {~$g$} ();

    \node[above left=-.5mm and -.5mm of a2] {$c$};
  \end{tikzpicture}
\end{center}

\enlargethispage*{10mm}
\vspace*{-\baselineskip}
Dann muss für \emph{jede} Zuweisung $\beta$ gelten:
%
\begin{alignat*}{2}
  \beta (c)      & = a_2 & \quad & (\text{da}~ c^\Amf = a_2)            \\
  \beta(g(f(c))) & = a_4 &       & (\text{da}~ g^\Amf(f^\Amf(c)) = a_4)
\end{alignat*}
%
Außerdem gilt:
%
\begin{itemize}
  \item
    Wenn $\beta(x) = a_1$, dann $\beta(g(f(x))) = a_2$.
  \item
    Wenn $\beta(x) = a_3$, dann $\beta(g(f(x))) = a_4$.
\end{itemize}
%
(Beachte jeweils: in $g(f(\cdot))$ wird zuerst $f$ angewendet und dann $g$.)
\pagebreak

% ===================================================================
\section*{T2.7~ Beispiel: Erfülltheitsrelation}

Betrachte die Struktur $\Amf$ aus \textsfbf{Beispiel 1} (T2.2):

\begin{center}
  \begin{tikzpicture}[%
    node distance=30mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=8mm},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (bb)                    {bb};
    \node[state] (rb) [right=of bb]      {rb};
    \node[state] (gb) [above=20mm of rb] {gb};
    \path[->] (bb) edge[bend right=15] node [below] {\textsf{neben}} (rb)
              (rb) edge[bend right=15] node [above] {\textsf{neben}} (bb)
              (rb) edge[bend right=15] node [right] {\textsf{unter}} (gb)
              (gb) edge[bend right=15] node [left]  {\textsf{auf}}   (rb);
    \node (lbb) [left=1mm of bb]  {\textsf{\begin{tabular}{@{}r@{}}Block\\B\end{tabular}}};
    \node (lgb) [right=1mm of gb] {\textsf{\begin{tabular}{@{}l@{}}G\\Block\end{tabular}}};
    \node (lrb) [right=1mm of rb] {\textsf{\begin{tabular}{@{}l@{}}R\\Block\\lieblingsblock\end{tabular}}};
  \end{tikzpicture}
\end{center}

Für alle Zuweisungen $\beta$ gilt:
\par\smallskip
\begin{itemize}
  \item
    $\Amf,\beta \models \exists x\,\textsf{R}(x) \land \exists x\,\textsf{G}(x) \land \exists x\,\textsf{B}(x)$,
    \par\smallskip
    denn $\Amf,\beta \models \exists x\,\textsf{R}(x)$ und  $\Amf,\beta \models \exists x\,\textsf{G}(x)$ und $\Amf,\beta \models \exists x\,\textsf{B}(x)$,
    \par\smallskip
    denn $\Amf,\beta[x/\text{rb}] \models \textsf{R}(x)$ und  $\Amf,\beta[x/\text{gb}] \models \textsf{G}(x)$ und $\Amf,\beta[x/\text{bb}] \models \textsf{B}(x)$
    \par\smallskip
  \item
    $\Amf,\beta \not\models \exists x\,\textsf{neben}(x,x)$
    \par\smallskip
  \item
    $\Amf,\beta \models \exists x\,\Big(\,\textsf{R}(x) \land \forall y\,\big(\textsf{auf}(y,x) \to \textsf{G}(y)\big)\,\Big)$
  \item
    $\Amf,\beta \models \forall x\Big(\,\big(\textsf{R}(x) \land \textsf{B}(x)\big) \to \textsf{G}(x)\,\Big)$
\end{itemize}
\par\medskip
Betrachte $\beta$ mit $\beta(x) = \text{bb}$, $\beta(y) = \text{gb}$ und $\beta(z) = \text{gb}$. Dann gilt:
\par\smallskip
\begin{itemize}
  \item
    $\Amf,\beta \models x \neq \textsf{lieblingsblock}$
  \item
    $\Amf,\beta \models \exists z\,\Big(\,\textsf{neben}(x,z) \land \textsf{unter}(z,y)\,\Big)$
\end{itemize}

\par\bigskip
Nun betrachte die Struktur $\Nmf = (\mathbb{N},+,\cdot,0,1)$ aus \textsfbf{Beispiel~4}. Dann gilt:
\par\smallskip
\begin{itemize}
  \item
    $\Nmf,\beta \models \forall x\,\forall y\,\big(x+y=y+x\big)$\quad für \emph{alle} $\beta$
    \par\smallskip
  \item
    $\Nmf,\beta \models \underbrace{\forall y\,\forall z\,\big(y \cdot z = \underline{x} \to y = 1 \lor z = 1\big) \land x \neq 0 \land x \neq 1}_{\text{{\small Abkürzung: {\boldmath $\textsfbf{Prim}(x)$}}}}$\\
    genau dann, wenn $\beta(x)$ eine Primzahl ist
    \par\smallskip
  \item
    $\Nmf,\beta \models \underbrace{\exists z\,\big(z \neq 0 \land \underline{x} + z = \underline{y}\big)}_{\text{{\small Abkürzung: {\boldmath $y > x$}}}}$\quad
    genau dann, wenn $\beta(y) > \beta (x)$
    \par\smallskip
  \item
    $\Nmf,\beta \models \forall x\,\Big(\,
      \textsf{Prim}(x) \to \exists y\,\big(
        y > x \land \textsf{Prim}(y)
      \big)
    \,\Big)$\\
    (Satz von Euklid: es gibt unendlich viele Primzahlen)
    \par\smallskip
  \item
    Es ist unbekannt, ob
    $\Nmf,\beta \models \forall x\,\exists y\,\big(
      y > x \land \textsf{Prim}(y) \land \textsf{Prim}(\hspace*{-9.4mm}\underbrace{y+2}_{\text{Abkürz.\ für $y+1+1$}}\hspace*{-9.4mm})
    \big)$.
    Dies ist ein schweres offenes Problem der Zahlentheorie: gibt es unendlich viele Primzahl\emph{zwillinge}?
    
\end{itemize}

% ===================================================================
\section*{T2.8~ Beispiel: Isomorphismus}

Betrachte die Signatur, die aus den Konstantensymbolen $c_1,c_2$,
einem einstelligen Funktionssymbol $f$ und einem zweistelligen Relationssymbol $R$ besteht.
Dann ist $\pi$ (gestrichelte Pfeile) ein Isomorphismus zwischen den folgenden
beiden Strukturen $\Amf$ und $\Bmf$.

\begin{center}
  \begin{tikzpicture}[%
    node distance=25mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=8mm},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (a1)                     {$a_1$};
    \node[state] (a2) [right=of a1]       {$a_2$};
    \node[state] (a3) [below right=of a1] {$a_3$};
    \node[state] (a7) [right=77mm of a1]  {$a_7$};
    \node[state] (b2) [right=of a7]       {$a_2$};
    \node[state] (a5) [below left=of b2]  {$a_5$};
    \path[->] (a1) edge                node [above] {$f$} (a2)
              (a1) edge[bend right=10] node [left]  {$R\,$} (a3)
              (a3) edge[bend right=10] node [right] {$\,R$} (a1)
              (a2) edge                node [right] {$f$} (a3)
              (b2) edge                node [above] {$f$} (a7)
              (b2) edge[bend right=10] node [left]  {$R\,$} (a5)
              (a5) edge[bend right=10] node [right] {$\,R$} (b2)
              (a7) edge                node [left]  {$f$} (a5)
              (a1) edge[loop left]     node [left]  {$R$} ()
              (a3) edge[loop below]    node [below] {$f$} ()
              (b2) edge[loop right]    node [right] {$R$} ()
              (a5) edge[loop below]    node [below] {$f$} ();
    \node [below right=-1mm and -1mm of a2] {$c_1$};
    \node [below left =-1mm and -1mm of a7] {$c_1$};
    \node [below left =-1mm and 0mm of a3] {$c_2$};
    \node [below right=-1mm and 0mm of a5] {$c_2$};

    \node [above left=2mm and 0mm of a1] {{\Large $\Amf$}};
    \node [above left=2mm and 0mm of a7] {{\Large $\Bmf$}};

    \path[->,densely dashed] (a1) edge[bend left=30]  node [below] {$\pi$} (b2)
                     (a2) edge[bend left=10]  node [below] {$\pi$} (a7)
                     (a3) edge[bend right=15] node [above] {$\pi$} (a5);
  \end{tikzpicture}
\end{center}

% ===================================================================
\section*{T2.9~ Beweis des Isomorphielemmas}

\textsfbf{Lemma~2.10 (Isomorphielemma).}~
Seien \Amf, \Bmf Strukturen und $\pi: A \rightarrow B$ ein Isomorphismus.
\par
Dann gilt f\"ur alle Formeln $\varphi(x_1,\dots,x_n)$ und alle $a_1,\dots,a_n \in A$:
%
\[
  \Amf \models \varphi[a_1,\dots,a_n] \text{ gdw. } \Bmf \models \varphi[\pi(a_1),\dots,\pi(a_n)]
\]

% \par\medskip\noindent
\begin{beweis}
  Sei $\pi: A \rightarrow B$ ein Isomorphismus von \Amf nach \Bmf.
  Wir schreiben die zu zeigende Aussage zunächst so auf,
  dass sie die Zuweisung $\beta$ explizit macht,
  was für den Beweis bequemer ist:

  Es ist zu zeigen:
  \begin{quote}
    Für alle FO-Formeln $\varphi$
    und für alle Interpretationen $\Imf_\Amf = (\Amf,\beta)$ und $\Imf_\Bmf = (\Bmf,\beta')$
    mit $\beta'(x) = \pi(\beta(x))$ für alle $x \in \textsf{Frei}(\varphi)$ gilt:
    \[
      \tag{$*$}
      \Imf_\Amf \models \varphi
      \qquad\text{gdw.}\qquad
      \Imf_\Bmf \models \varphi
    \]
  \end{quote}

  Da Syntax und Semantik der Prädikatenlogik in zwei Schritten aufgebaut ist
  (Terme und Formeln), bietet es sich an, $(*)$ ebenfalls in zwei Schritten zu beweisen.

  \par\medskip\noindent
  \textsfbf{Schritt 1.}~
  Man zeigt zunächst leicht per Induktion über die Struktur von $t$,
  dass für alle Terme mit Variablen aus $\textsf{Frei}(\varphi)$ gilt:
  \[
    \tag{$**$}
    \beta'(t) = \pi(\beta(t))
  \]
  \begin{description}
    \item[Induktionsanfang.]
      ~\par\vspace*{-.2\baselineskip}
      \begin{itemize}
        \item
          Für $t=x$ folgt $(**)$ aus der Voraussetzung $\beta'(x) = \pi(\beta(x))$ für alle $x \in \textsf{Frei}(\varphi)$.
        \item
          Für $t=c$ (Konstante) gilt $(**)$ wegen
          \begin{xalignat*}{2}
            \beta'(c) & = c^\Bmf        & & \text{(Definition Zuweisung)} \\
                      & = \pi(c^\Amf)   & & \text{(Definition Isomorphismus)} \\
                      & = \pi(\beta(c)) & & \text{(Definition Zuweisung)}
          \end{xalignat*}
      \end{itemize}

    \item[Induktionsschritt.]
      Sei $t = f(t_1,\dots,t_n)$. Dann gilt:
      \begin{xalignat*}{2}
        \beta'(t) & = \beta'(f(t_1,\dots,t_n))                        & & \\
                  & = f^\Bmf(\beta'(t_1), \dots, \beta'(t_n))         & & \text{(Definition Zuweisung)} \\
                  & = f^\Bmf(\pi(\beta(t_1)), \dots, \pi(\beta(t_n))) & & \text{(Induktionsvoraussetzung)} \\
                  & = \pi(f^\Amf(\beta(t_1), \dots, \beta(t_n)))      & & \text{(Definition Isomorphismus)} \\
                  & = \pi(\beta(f(t_1, \dots, t_n))                   & & \text{(Definition Zuweisung)} \\
                  & = \pi(\beta(t))
      \end{xalignat*}
  \end{description}


  \par\medskip\noindent
  \textsfbf{Schritt 2.}~
  Nun können wir $(*)$ per Induktion über die Struktur von $\varphi$ beweisen und dabei $(**)$ verwenden.
  \begin{description}
    \item[Induktionsanfang.]
      ~\par\vspace*{-.2\baselineskip}
      \begin{itemize}
        \item
          Wenn $\varphi = (t_1 = t_2)$, dann haben wir:
          \begin{xalignat*}{2}
            \Imf_A \models t_1 = t_2 & \text{~~gdw.~~} \beta(t_1) = \beta(t_2)           & & \text{(Def.\ Semantik FO)} \\
                                     & \text{~~gdw.~~} \pi(\beta(t_1)) = \pi(\beta(t_2)) & & \text{(weil $\pi$ Funktion und injektiv)} \\
                                     & \text{~~gdw.~~} \beta'(t_1) = \beta'(t_2)         & & (**) \\
                                     & \text{~~gdw.~~} \Imf_B \models t_1 = t_2          & & \text{(Def.\ Semantik FO)}
          \end{xalignat*}
        \item
          Wenn $\varphi = P(t_1,\dots,t_n)$, dann haben wir:
          \begin{xalignat*}{2}
            \Imf_A \models P(t_1,\dots,t_n) & \text{~~gdw.~~} (\beta(t_1),\dots,\beta(t_n)) \in P^\Amf           & & \text{(Def.\ Semantik FO)} \\
                                            & \text{~~gdw.~~} (\pi(\beta(t_1)),\dots,\pi(\beta(t_n))) \in P^\Bmf & & \text{(weil $\pi$ Isomorphismus)} \\
                                            & \text{~~gdw.~~} (\beta'(t_1),\dots,\beta'(t_n)) \in P^\Bmf         & & (**) \\
                                            & \text{~~gdw.~~} \Imf_B \models P(t_1,\dots,t_n)                    & & \text{(Def.\ Semantik FO)}
          \end{xalignat*}
      \end{itemize}

    \item[Induktionsschritt.]
      ~\par\vspace*{-.2\baselineskip}
      \begin{itemize}
        \item
          Die Fälle $\varphi = \lnot \psi$, $\varphi = \psi_1 \land \psi_2$ und $\varphi = \psi_1 \lor \psi_2$
          sind eine gute Gelegenheit zum Üben -- probiert es aus!
        \item
          Im Fall $\varphi = \exists x\,\psi$ argumentieren wir wie folgt.
          \begin{xalignat*}{2}
            \Imf_A \models \exists x\,\psi & \text{~~gdw.~~} \Amf,\beta[x/a] \models \psi \text{~für ein~} a \in A       & & \text{(Def.\ Semantik FO)} \\
                                           & \text{~~gdw.~~} \Bmf,\beta'[x/\pi(a)] \models \psi \text{~für ein~} a \in A & & \text{(Induktionsvoraussetzung)} \\
                                           & \text{~~gdw.~~} \Bmf,\beta'[x/b] \models \psi \text{~für ein~} b \in B      & & \text{(weil $\pi$ surjektiv)} \\
                                           & \text{~~gdw.~~} \Imf_B \models \exists x\,\psi                              & & \text{(Def.\ Semantik FO)}
          \end{xalignat*}
          Um im zweiten Schritt die Induktionsvoraussetzung anwenden zu können,
          müssen wir natürlich prüfen, ob die Voraussetzung von $(*)$
          von $(\Amf,\beta[x/a])$ und $(\Bmf,\beta'[x/\pi(a)])$ erfüllt sind.
          Dies ist der Fall, denn wir arbeiten unter der Voraussetzung
          \[
            \beta'(y) = \pi(\beta(y)) \quad\text{für alle~} y \in \textsf{Frei}(\exists x\,\psi),
          \]
          woraus folgt, dass
          \[
            \beta'[x/\pi(a)](y) = \pi(\beta'[x/a](y)) \quad\text{für alle~} y \in \textsf{Frei}(\exists x\,\psi),
          \]
          d.\,h.\ $y=x$ ist möglich.
        \item
          Im Fall $\varphi = \forall x\,\psi$ argumentieren wir analog.\qedhere
      \end{itemize}
  \end{description}
\end{beweis}%

% ===================================================================
\section*{T2.10~ Beispiel für den Auswertungsalgorithmus}

Betrachte die Eingabe $(\Amf,\beta,\varphi)$ bestehend aus
%
\begin{itemize}
  \item
    der Struktur $\Amf$:~
    \raisebox{-5pt}{%
      \begin{tikzpicture}[%
        node distance=15mm,>=Latex,
        every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
        every edge/.style={draw=black,thin}
      ]
        \node[state] (a)              {$a$};
        \node[state] (b) [right=of a] {$b$};
        \path[->] (b) edge                node [above] {$R$} (a);
        \node [left=0mm of a] {$P$};
      \end{tikzpicture}%
    }
    \par\medskip
  \item
    der leeren Zuweisung $\beta$\quad und
    \par\smallskip
  \item
    dem Satz
    $
      \varphi = \forall x\,
      \underbrace{
        \exists y\,\Big(
        \overbrace{
          P(x) \lor R(x,y)
        }^{
          \vartheta(x,y)
        }
        \Big)
      }_{
        \psi(x)
      }
    $\,.
\end{itemize}
%
Ein Lauf des Algorithmus auf dieser Eingabe wird durch den Baum in Abbildung~\ref{fig:ausw} wiedergegeben.
Dabei steht jeder Knoten für einen Aufruf von \texttt{ausw} mit den angegebenen Parametern.
Die Kinder jedes Knoten stehen für die Unteraufrufe in diesem Aufruf.
Dabei steht "`\dots"' für die Zuweisung, die bereits im Elternknoten verwendet wurde.
Die Operatoren $\forall,\exists,\lor$ geben die Art der jeweiligen Verzweigung an (äußerer Operator der Formel in diesem Aufruf).
Die Zahlen 0 und 1 geben den Rückgabewert des jeweiligen Aufrufs an.

Der Aufruf $\texttt{ausw}(\Amf,\beta,\varphi)$ liefert den Wert 1 zurück;
also gilt $\Amf,\beta \models \varphi$.

\begin{landscape}
\begin{figure}
  \vspace*{-11pt}
  \begin{center}
    \begin{tikzpicture}[%
  %     parent anchor=east, child anchor=west, grow=east,
  %     sibling distance=15mm, level distance=15mm,
      transform shape,
      every node/.style = {rectangle, rounded corners=1.5mm, draw=black, fill=black!10, inner sep=1.3mm, minimum size=4mm},
      level 1/.style = {sibling distance = 103mm, level distance = 30mm},
      level 2/.style = {sibling distance =  51mm, level distance = 30mm},
      level 3/.style = {sibling distance =  25mm, level distance = 30mm},
      edge from parent/.style = {draw=black, thin, -Latex}%
    ]
      \node (phi) {$\Amf, \beta, \varphi$}
        child {
          node (psi_a) {$\Amf, \{x \mapsto a\}, \psi$}
          child {
            node (theta_aa) {$\Amf, \{x \mapsto a,\, y \mapsto a\}, \vartheta$}
            child {
              node (P_aa) {$\Amf, \dots, P(x)$}
            }
            child {
              node (R_aa) {$\Amf, \dots, R(x,y)$}
            }
          }
          child {
            node (theta_ab) {$\Amf, \{x \mapsto a,\, y \mapsto b\}, \vartheta$}
            child {
              node (P_ab) {$\Amf, \dots, P(x)$}
            }
            child {
              node (R_ab) {$\Amf, \dots, R(x,y)$}
            }
          }
        }
        child {
          node (psi_b) {$\Amf, \{x \mapsto b\}, \psi$}
          child {
            node (theta_ba) {$\Amf, \{x \mapsto b,\, y \mapsto a\}, \vartheta$}
            child {
              node (P_ba) {$\Amf, \dots, P(x)$}
            }
            child {
              node (R_ba) {$\Amf, \dots, R(x,y)$}
            }
          }
          child {
            node (theta_bb) {$\Amf, \{x \mapsto b,\, y \mapsto b\}, \vartheta$}
            child {
              node (P_bb) {$\Amf, \dots, P(x)$}
            }
            child {
              node (R_bb) {$\Amf, \dots, R(x,y)$}
            }
          }
        };

%       \node [draw=none, fill=none, above right=-1mm and -1mm of phi]      {\textsfbf{1}};
%       \node [draw=none, fill=none, above right=-1mm and -1mm of psi_a]    {1};
%       \node [draw=none, fill=none, above right=-1mm and -1mm of psi_b]    {1};
%       \node [draw=none, fill=none, above right=-1mm and -1mm of theta_aa] {1};
%       \node [draw=none, fill=none, above right=-1mm and -1mm of theta_ab] {1};
%       \node [draw=none, fill=none, above right=-1mm and -1mm of theta_ba] {1};
%       \node [draw=none, fill=none, above right=-1mm and -1mm of theta_bb] {0};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of P_aa]   {1};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of R_aa]   {0};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of P_ab]   {1};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of R_ab]   {0};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of P_ba]   {0};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of R_ba]   {1};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of P_bb]   {0};
%       \node [draw=none, fill=none, above right= 0mm and -3.5mm of R_bb]   {0};
% 
      \node [draw=none, fill=none, above=0mm of phi]      {\textsfbf{1}};
      \node [draw=none, fill=none, above=0mm of psi_a]    {1};
      \node [draw=none, fill=none, above=0mm of psi_b]    {1};
      \node [draw=none, fill=none, above=0mm of theta_aa] {1};
      \node [draw=none, fill=none, above=0mm of theta_ab] {1};
      \node [draw=none, fill=none, above=0mm of theta_ba] {1};
      \node [draw=none, fill=none, above=0mm of theta_bb] {0};
      \node [draw=none, fill=none, above=0mm of P_aa]     {1\,};
      \node [draw=none, fill=none, above=0mm of R_aa]     {\,0};
      \node [draw=none, fill=none, above=0mm of P_ab]     {1\,};
      \node [draw=none, fill=none, above=0mm of R_ab]     {\,0};
      \node [draw=none, fill=none, above=0mm of P_ba]     {0\,};
      \node [draw=none, fill=none, above=0mm of R_ba]     {\,1};
      \node [draw=none, fill=none, above=0mm of P_bb]     {0\,};
      \node [draw=none, fill=none, above=0mm of R_bb]     {\,0};

      \node [draw=none, fill=none, below=0mm of phi]      {$\forall$};
      \node [draw=none, fill=none, below=0mm of psi_a]    {$\exists$};
      \node [draw=none, fill=none, below=0mm of psi_b]    {$\exists$};
      \node [draw=none, fill=none, below=1mm of theta_aa] {$\lor$};
      \node [draw=none, fill=none, below=1mm of theta_ab] {$\lor$};
      \node [draw=none, fill=none, below=1mm of theta_ba] {$\lor$};
      \node [draw=none, fill=none, below=1mm of theta_bb] {$\lor$};
    \end{tikzpicture}%
  \end{center}
  \vspace*{-10.86pt}
  \caption{Beispiellauf des Auswertungsalgorithmus}
  \label{fig:ausw}
\end{figure}
\end{landscape}

% ===================================================================
\section*{T2.11~ Korrektheit \& Platzbedarf des Auswertungsalgorithmus}

\textsfbf{Lemma~2.13.}~
Der Algorithmus \texttt{ausw}
\begin{enumerate}
  \item
    ist korrekt: $\texttt{ausw}(\Amf,\beta,\varphi) = 1$ gdw.\ $\Amf,\beta \models \varphi$;
  \item
    benötigt nur polynomiell viel Platz.
\end{enumerate}
% \par\medskip\noindent
\begin{beweis}
  \begin{enumerate}
    \item
      Dies lässt sich durch einfache Induktion über die Struktur von $\varphi$ zeigen:
      Die Fälle des Algorithmus spiegeln direkt die Semantik der Operatoren wider.
    \item
      Jeder einzelne Fall (z.\,B.\ Prüfen, ob $\beta(t) = \beta(t')$
      oder Iteration über alle $a \in A$) kann mit polynomiell viel Platz
      ausgeführt werden.
      Die Rekursionstiefe ist durch $\textsf{st}(\varphi)$ (Schachtelungstiefe)
      begrenzt, also wird auch der Rekursionsstapel nur polynomiell groß.\qedhere
  \end{enumerate}
%   \vspace*{-1.2\baselineskip}
\end{beweis}%

% ===================================================================
\section*{T2.12~ Weitere Beispiele für Datenbankanfragen}

Freie Variablen sind unterstrichen.
\begin{itemize}
  \item
    "`Gib alle Paare von Schauspieler\_innen und Regisseur\_innen,
    so dass erstere\_r in einem Film von letzterer/m mitgespielt hat"'.
    %
    \begin{align*}
      \psi(x,y)               & = \exists z\,\exists z'\,\Big(\textsf{Schauspieler\_in}(\underline{x},z) \land \textsf{Film}(z,z',\underline{y})\Big) \\[4pt]
      \textsf{ans}(\Amf,\psi) & = \{(\text{Connery},\text{Hitchcock}),~(\text{Connery},\text{Hamilton}),~(\text{Hedren},\text{Hitchcock})\}
    \end{align*}
  \item
    "`Gib alle Paare von verschiedenen Filmen,
    die im selben Jahr gedreht wurden"'.
    %
    \begin{align*}
      \vartheta(x,y)               & = \exists z_1\,\exists z_2\,\exists z_3\,\Big(\textsf{Film}(\underline{x},z_1,z_2) \land \textsf{Film}(\underline{y},z_1,z_3) \land x \neq y\Big) \\[4pt]
      \textsf{ans}(\Amf,\vartheta) & = \{(\text{Marnie},\text{Goldfinger}),~(\text{Goldfinger},\text{Marnie})\}
    \end{align*}
    (Man beachte das zweifache Vorkommen von $z_1$, was einem "`equijoin"' in SQL entspricht.)
\end{itemize}

% ===================================================================
\section*{T2.13~ Beispiele für domänenabhängige Formeln}

Betrachte ein einstelliges Relationssymbol $P$
und die Strukturen $\Amf$ mit $A=\{a\}$ und $P^\Amf = \{a\}$
sowie $\Bmf$ mit $B=\{a,a'\}$ und $P^\Bmf = \{a\}$.
Die folgenden Formeln sind domänen\-\emph{abhängig}:
\begin{itemize}
  \item
    $\varphi(x) = \lnot P(\underline{x})$,
    \par
    denn $\textsf{ans}(\Amf,\varphi) = \emptyset$,
    aber $\textsf{ans}(\Bmf,\varphi) = \{a'\}$
    \par\smallskip
  \item
    $\psi(x) = P(\underline{x}) \lor \exists y.P(y)$,
    \par
    denn $\textsf{ans}(\Amf,\psi) = \{a\}$,
    aber $\textsf{ans}(\Bmf,\psi) = \{a,a'\}$
\end{itemize}

% ===================================================================
\section*{T2.14~ Beispiele für Gültigkeit, Erfüllbarkeit, Konsequenz}

\begin{itemize}
  \item
    Die folgenden Sätze sind gültig:
    \begin{align*}
      & \forall x\, \exists y\, \Big(y = f(x)\Big) \\
      & \forall x\, \Big( f(x) = x \to f(f(x)) = x \Big)
    \end{align*}
  \item
    Der folgende Satz ist erfüllbar, aber nur in Modellen mit \emph{unendlich großem} Universum:
%     \begin{align*}
%       & \forall x\, \exists y\, P(x,y) \\
%       & {} \land \forall x\,\forall y\,\forall z\, \Big( P(x,y) \land P(y,z) \to P(x,z) \Big) \\
%       & {} \land \lnot \exists x\,P(x,x)
%     \end{align*}
    \[
      \forall x\, \exists y\, P(x,y)
      \quad\land\quad
      \forall x\,\forall y\,\forall z\, \Big( P(x,y) \land P(y,z) \to P(x,z) \Big)
      \quad\land\quad
      \lnot \exists x\,P(x,x)
    \]
    Die drei Teile des Satzes sagen, dass 
    \begin{enumerate}
      \item[(1)]
        jedes Element einen "`$P$-Nachfolger"' hat;
      \item[(2)]
        die Relation $P$ transitiv ist;
      \item[(3)]
        kein Element sich selbst als "`$P$-Nachfolger"' haben darf.
    \end{enumerate}
    Damit dieser Satz erfüllbar ist, muss es mindestens ein Element $a_1$ im Universum $A$ geben
    (Universen dürfen nicht leer sein).
    Wegen~(1) muss es ein Element $a_2$ mit $P^\Amf(a_1,a_2)$ geben.
    Wegen~(3) muss $a_2 \neq a_1$ sein.
    Wegen~(1) muss es ein Element $a_3$ mit $P^\Amf(a_2,a_3)$ geben.
    Wegen~(3) muss $a_3 \neq a_2$ sein.
    Wegen~(2) und~(3) muss $a_3 \neq a_1$ sein.
    So kann man die Argumentation induktiv fortsetzen und erhält eine (abzählbar) unendliche Folge
    $a_1,a_2,a_3,\dots$ von paarweise verschiedenen Elementen aus $A$.
    \par\smallskip
  \item
    Folgendes ist ein Beispiel für Konsequenz:
    \[
      \exists x\, \forall y\, (x=y)
      ~\models~
      f(c) = c
    \]
    Anschaulich gesprochen: wenn es nur ein Element im Universum gibt (linke Seite),
    dann muss der Funktionswert jedes Elements das Element selbst sein,
    für eine beliebige einstellige Funktion $f$ und ein beliebiges Element
    (durch die Konstante $c$ repräsentiert).
\end{itemize}

\pagebreak
% ===================================================================
\section*{T2.15~ Beweis der Äquivalenzen für das PNF-Theorem}

\textsfbf{Lemma.}~
Falls $x$ nicht frei in $\varphi$ vorkommt, gilt:
%
\begin{enumerate}
  \item[(1)]
    $\varphi \vee \exists x \, \psi   ~\equiv~ \exists x \, (\varphi \vee \psi)$
  \item[(2)]
    $\varphi \wedge \exists x \, \psi ~\equiv~ \exists x \, (\varphi \wedge \psi)$
  \item[(3)]
    $\varphi \vee \forall x \, \psi   ~\equiv~ \forall x \, (\varphi \vee \psi)$
  \item[(4)]
    $\varphi \wedge \forall x \, \psi ~\equiv~ \forall x \, (\varphi \wedge \psi)$
\end{enumerate}
%
\begin{beweis}
  Wir beweisen exemplarisch~(1).

  Sei $(\Amf, \beta)$ eine beliebige Interpretation. Dann gilt:

  \begin{center}
    \parbox{.7\textwidth}{%
      $\Amf,\beta \models \varphi \lor \exists x\, \psi$

      \par\smallskip
      \hspace*{5mm}gdw.

      \par\smallskip
      $\Amf,\beta \models \varphi$ oder es gibt $a \in A$ mit $\Amf,\beta[x/a] \models \psi$

      \par\smallskip
      \hspace*{5mm}gdw.

      \par\smallskip
      es gibt $a \in A$, so dass $\Amf,\beta[x/a] \models \varphi$ oder $\Amf,\beta[x/a] \models \psi$

      \par\smallskip
      \hspace*{5mm}gdw.

      \par\smallskip
      $\Amf,\beta \models \exists x \, (\varphi \vee \psi)$
    }
  \end{center}

  Der erste und dritte Schritt gilt wegen der Semantik der Operatoren $\lor,\exists$.
  Der zweite Schritt gilt wegen $x \notin \textsf{Frei}(\varphi)$,
  denn deshalb liefert das Koinzidenzlemma:
  \[
    \Amf,\beta \models \varphi
    \quad\text{gdw.}\quad
    \Amf,\beta[x/a] \models \varphi
  \]
  ~\par\vspace*{-2.4\baselineskip}
   \qedhere
\end{beweis}%

% ===================================================================
\section*{T2.16~ Beweis des PNF-Theorems}

\textsfbf{Theorem 2.21.}~
Jede FO-Formel $\varphi$ kann in Linearzeit in eine äquivalente Formel in PNF gewandelt werden.
%
\begin{beweis}
  Wir beweisen das Theorem
  per Induktion über die Struktur von $\varphi$,
  nach \cite{SkriptGraedel}.
  %
  \begin{description}
    \item[Induktionsanfang.]
      Wenn $\varphi$ atomar ist (d.\,h.\ $\varphi = (t_1 = t_2)$ oder $\varphi = P(t_1,\dots,t_n)$),
      dann enthält die Formel keinen Quantor, ist also trivialerweise in PNF.
    \item[Induktionsschritt.]
      Wir unterscheiden drei Fälle:
%      Wegen Lemma~2.16 müssen wir nur noch drei Fälle untersuchen:
      \begin{enumerate}
        \item[(1)]
          $\varphi = \lnot \psi$.
          \par\smallskip
          Nach Induktionsvoraussetzung gibt es eine PNF-Formel
          \[
            \psi' ~=~ \textsf{Q}_1x_1 \cdots \textsf{Q}_nx_n\, \vartheta
          \]
          mit $\psi' \equiv \psi$.
          Die Dualität von $\exists$ und $\forall$\,%
          \footnote{%
            d.\,h\, für alle Formeln $\xi$ gilt
            ~$\lnot \forall x\,\xi \equiv \exists x\, \lnot \xi$~
            und 
            ~$\lnot \exists x\,\xi \equiv \forall x\, \lnot \xi$~
          }
          liefert
          \[
            \varphi ~\equiv~ \underbrace{\overline{\textsf{Q}_1} x_1 \cdots \overline{\textsf{Q}_n} x_n\, \lnot \vartheta}_{\text{in PNF}}\,,
          \]
          wobei $\overline{\exists} = \forall$ und $\overline{\forall} = \exists$.
          \pagebreak
          \par\smallskip
        \item[(2)]
          $\varphi = \psi_1 \circ \psi_2$ mit $\circ \in \{\land,\lor\}$.
          \par\smallskip
          Nach Induktionsvoraussetzung gibt es PNF-Formeln
          $\psi_1',\psi_2'$ mit $\psi_1' \equiv \psi_1$ und $\psi_2' \equiv \psi_2$.
          Durch Variablenumbenennung erreichen wir,
          dass $\psi_1'$ und $\psi_2'$ folgende Form haben:
          \begin{align*}
            \psi_1' & ~=~ \textsf{Q}_1  x_1 \cdots \textsf{Q}_n  y_n \, \vartheta_1 \\
            \psi_2' & ~=~ \textsf{Q}'_1 y_1 \cdots \textsf{Q}'_m y_m \, \vartheta_2
          \end{align*}
          wobei die Variablen $x_1,\dots,x_n,y_1,\dots,y_m$ paarweise verschieden
          sowie verschieden von allen freien Variablen in $\psi_1'$ und $\psi_2'$ sind.

          Offenbar ist
          \[
            \varphi' ~=~ \textsf{Q}_1 x_1 \cdots \textsf{Q}_n x_n \, \textsf{Q}'_1 y_1 \cdots \textsf{Q}'_m y_m\, (\vartheta_1 \circ \vartheta_2)
          \]
          in PNF.
          Da $y_1,\dots,y_m$ nicht in $\psi_1'$ vorkommen 
          und $x_1,\dots,x_n$ nicht in $\psi_2'$,
          liefern die Äquivalenzen des obigen Lemmas,
          wenn man sie $(n+m)$-mal auf $\psi_1' \circ \psi_2'$ anwendet:
          $\varphi' \equiv \varphi$.
          \par\smallskip
        \item[(3)]
          $\varphi = \textsf{Q} x\,\psi$ mit $\textsf{Q} \in \{\exists,\forall\}$.
          \par\smallskip
          Nach Induktionsvoraussetzung gibt es eine PNF-Formel
          $\psi' = \textsf{Q}_1x_1 \cdots \textsf{Q}_nx_n\, \vartheta$
          mit $\psi' \equiv \psi$.
          Durch Umbenennen kann erreicht werden, dass
          $x \notin \{x_1,\dots,x_n\}$.
%           \footnote{%
%             Sonst wäre im nächsten Schritt $\textsf{Q} x\,\psi'$ nicht bereinigt.%
%           }
          Dann ist $\textsf{Q} x\,\psi'$ äquivalent zu $\varphi$ und in PNF
          (insbesondere haben wir durch das Umbenennen sichergestellt,
          dass $\textsf{Q} x\,\psi'$ bereinigt ist).
          \qedhere
      \end{enumerate}
  \end{description}
\end{beweis}%

% ===================================================================
\section*{T2.17~ Beispiel zur Umwandlung in PNF}

Sei
\[
  \varphi ~=~
  \lnot \forall x\, \Big(
    \underbrace{R(x,x)}_{\text{PNF}}
    ~\land~
    \underbrace{\forall \underline{x}\, \exists y\, R(\underline{x},y)}_{\text{PNF}}
  \Big).
\]
Um $\varphi$ in PNF zu wandeln, gehen wir gemäß der strukturellen Induktion im vorangehenden Beweis
von innen nach außen vor. Die größten Teilformeln, die bereits in PNF sind,
sind markiert.
Als nächstes muss die Konjunktion gemäß Fall~(2) umgeformt werden.
Dazu ist es zunächst notwendig, das \emph{gebundene} Vorkommen von $x$ in der rechten Teilformel
(durch Unterstreichen markiert) umzubenennen:
\[
  \varphi ~\equiv~
  \lnot \forall x\, \Big(
    R(x,x)
    \land
    \forall \underline{z}\, \exists y\, R(\underline{z},y)
  \Big).
\]
Die Konstruktion in Fall~(2) liefert dann:
\[
  \varphi ~\equiv~
  \lnot~ \underbrace{
    \forall x\, \forall z\, \exists y\, \Big(
      R(x,x) \land R(z,y)
    \Big)
  }_{\text{PNF}}
\]
Gemäß Fall~(1) müssen wir jetzt nur noch Quantoren "`umdrehen"'
und die Negation nach innen ziehen:
\[
  \varphi ~\equiv~
  \exists x\, \exists z\, \forall y\, \lnot \Big(
    R(x,x) \land R(z,y)
  \Big)
\]

% ===================================================================
\section*{T2.18~ Beispiel für das Postsche Korrespondenzproblem (PKP)}

Sei $F =
  \underbrace{(0,1)}_{\text{Index}~1},~
  \underbrace{(1,10)}_{\text{Index}~2},~
  \underbrace{(01,1)}_{\text{Index}~3}%
$.~
Dann ist die Indexfolge $2,3$ eine Lösung, denn
%
\par\smallskip
\begin{itemize}
  \item
    die linke Konkatenation liefert $1 \cdot 01 = 101$\quad und
  \item
    die rechte Konkatenation liefert $10 \cdot 1 = 101$.
\end{itemize}
%
Schematisch kann man das auch so darstellen:

\vspace*{-.5\baselineskip}
\begin{center}
  \begin{tabular}{@{}lccc@{}}
                         & {\scriptsize 2} & \multicolumn{2}{c}{{\scriptsize 3}} \\
    Linke Konkatenation  & 1               & \multicolumn{1}{|c}{0} & 1          \\\cline{3-3}
    Rechte Konkatenation & 1               & \multicolumn{1}{c|}{0} & 1
  \end{tabular}
\end{center}

% ===================================================================
\section*{T2.19~ Beispiel für die Kodierung des PKP}

Für das PKP $F$ aus dem vorangehenden Beispiel erhält man ein unendliches Modell,
das wie folgt aussieht
("`$\cdots$"' deuten an, dass sowohl das Universum $A$
als auch die Interpretationen der Funktionen $f_1,f_1$ und des Relationssymbols $P$ unendlich sind):

\vspace*{-.5\baselineskip}
% \enlargethispage*{10mm}
\begin{center}
  \begin{tikzpicture}[%
    >=Latex,
%     parent anchor=east, child anchor=west, grow=east,
%     sibling distance=15mm, level distance=15mm,
    every node/.style = {ellipse, draw=black, fill=black!10, inner sep=1mm, minimum size=4mm},
    level 1/.style = {sibling distance = 75mm, level distance=20mm},
    level 2/.style = {sibling distance = 37mm, level distance=20mm},
    level 3/.style = {sibling distance = 18mm, level distance=20mm},
    edge from parent/.style = {draw=black, thin, ->}%
  ]
    \node[inner sep=1.7mm] (eps) {$\varepsilon$}
      child {
        node (0) {\,0\,}
        child {
          node (00) {00}
          child {
            node (000) {000}
            edge from parent node[above left, draw=none, fill=none] {$f_0$}
          }
          child {
            node (001) {001}
            edge from parent node[above right, draw=none, fill=none] {$f_1$}
          }
          edge from parent node[above left, draw=none, fill=none] {$f_0$}
        }
        child {
          node (01) {01}
          child {
            node (010) {010}
            edge from parent node[above left, draw=none, fill=none] {$f_0$}
          }
          child {
            node (011) {011}
            edge from parent node[above right, draw=none, fill=none] {$f_1$}
          }
          edge from parent node[above right, draw=none, fill=none] {$f_1$}
        }
        edge from parent node[above left, draw=none, fill=none] {$f_0$}
      }
      child {
        node (1) {\,1\,}
        child {
          node (10) {10}
          child {
            node (100) {100}
            edge from parent node[above left, near end, draw=none, fill=none] {$f_0$}
          }
          child {
            node (101) {101}
            edge from parent node[above right, near end, draw=none, fill=none] {$f_1$}
          }
          edge from parent node[below right, near start, draw=none, fill=none] {$f_0$}
        }
        child {
          node (11) {11}
          child {
            node (110) {110}
            edge from parent node[above left, draw=none, fill=none] {$f_0$}
          }
          child {
            node (111) {111}
            edge from parent node[above right, draw=none, fill=none] {$f_1$}
          }
          edge from parent node[above right, draw=none, fill=none] {$f_1$}
        }
        edge from parent node[above right, draw=none, fill=none] {$f_1$}
      };

    \path[%
      ->, ultra thick,
      draw=black!50, fill=black!50,
%       draw opacity=.5, fill opacity=.5, 
      every node/.style = {ultra thick, rounded corners, draw=black!50, text=black!70}%
    ]
      (0)   edge[bend left =11]       node[above=.5mm]             (P1) {\textsfbf{1}} (1)
      (1)   edge[bend right=23]       node[left=2.5mm, near end]   (P2) {\textsfbf{2}} (10)
      (01)  edge[bend left =11]       node[above left]             (P3) {\textsfbf{3}} (1)
      (010) edge[out=25,in=190]       node[above=.7mm, near start] (P4) {\textsfbf{4}} (11)
      (101) edge[in=240,out=300,loop] node[below=.8mm]             (P5) {\textsfbf{5}} ();

%     \draw[dashed,-Latex,bend right=10] (0)--(1);
%     \draw[dashed,-Latex,bend right=20] (00)--(01);
%     \draw[dashed,-Latex,bend right=40] (000)--(001);
%     \draw[dashed,-Latex,bend right=40] (010)--(011);
%     \draw[dashed,-Latex,bend right=40] (110)--(111);


    \begin{scope}[every node/.style = {ultra thick, rounded corners, draw=black!50, text=black!70}]
      \node [below left=10mm and -3.4mm of 000] (legend1)  {\textsfbf{1}};
      \node [below=2mm of legend1]           (legend2)  {\textsfbf{2}};
      \node [below=2mm of legend2]           (legend3)  {\textsfbf{3}};
      \node [below=2mm of legend3]           (legend4)  {\textsfbf{4}};
      \node [below=2mm of legend4]           (legend5)  {\textsfbf{5}};
      \node [right=6mm of legend4]           (legend41) {\textsfbf{3}};
      \node [right=6mm of legend5]           (legend51) {\textsfbf{2}};
    \end{scope}

    \begin{scope}[every node/.style = {ultra thick, rounded corners, draw=none, text=black!70}]
      \node [left=1mm of P1]                {{\boldmath $P$}};
      \node [above right=-1mm and -1mm of P2] {{\boldmath $P$}};
      \node [below left=-2mm and 1mm of P3]  {{\boldmath $P$}};
      \node [above right=-5mm and 1mm of P4] {{\boldmath $P$}};
      \node [above right=0mm and -.5mm of P5] {{\boldmath $P$}};
    \end{scope}

    \begin{scope}[every node/.style = {draw=none, fill=none}]
      \node [above right=0mm and -1mm of eps]  {$c_\varepsilon$};

      \foreach \x in {000, 001, 010, 011, 100, 110, 111} \node [below=-2mm of \x] {$\vdots$};

      \foreach \x in {1,2,3,4,5} \node [right=.1mm of legend\x] {:};
%       \node [right=.1mm of legend1] {:};
%       \node [right=.1mm of legend2] {:};
%       \node [right=.1mm of legend3] {:};
%       \node [right=.1mm of legend4] {:};
%       \node [right=.1mm of legend5] {:};

      \node [right=5mm of legend1] {Indexfolge 1};
      \node [right=5mm of legend2] {Indexfolge 2};
      \node [right=5mm of legend3] {Indexfolge 3};
      \node [right=-.5mm of legend41] {${} \cdot (0,1)$,~ also Indexfolge $3,1$};
      \node [right=-.5mm of legend51] {${} \cdot (01,1)$,~ also Indexfolge $2,3$};
    \end{scope}
  \end{tikzpicture}%
\end{center}

$P$-Kante Nr.\,5 bezeugt, dass $F$ eine Lösung hat.

% ===================================================================
\section*{T2.20~ Beweis der Korrektheit der PKP-Reduktion}

Wir verwenden die auf Folie~59 eingeführte Notation $t_w(x)$:
\begin{itemize}
  \item
    F\"ur ein Wort $w=w_1 \cdots w_n \in \{0,1\}^*$ steht $t_w(x)$ f\"ur $f_{w_n}(f_{w_{n-1}}(\cdots f_{w_1}(x)))$.
  \item
    Wir schreiben außerdem $t_w^\Amf(x)$ f\"ur $f_{w_n}^\Amf(f_{w_{n-1}}^\Amf(\cdots f_{w_1}^\Amf(x)))$.
\end{itemize}

\par\medskip\noindent
\textsfbf{Lemma~2.24.}~
$F$ hat eine L\"osung\quad gdw.\quad $\varphi_F$ g\"ultig ist.

%
\begin{beweis}
  Sei $F = (u_1,v_1), \dots, (u_k,v_k)$.
  Wir beweisen beide Richtungen von "`genau dann, wenn"' getrennt.
  \begin{description}
    \item[{\boldmath "`$\Leftarrow$"'}]
      Sei $\varphi_F$ gültig.
      Dann ist jede Struktur ein Modell von $\varphi_F$.
      Unter diesen Modellen gibt es auch Strukturen, die völlig anders beschaffen sind,
      als wir es im vorigen Bild gezeichnet haben, d.\,h.\ das Universum ist kein Baum
      und/oder die Funktions- und Relationssymbole werden anders interpretiert, als wir es beabsichtigen.
      Wir betrachten jedoch ein spezielles Modell, das sich so verhält, wie wir es wollen,
      und das deshalb auch \emph{kanonisches Modell} genannt wird.
      Es ist die Struktur
      %
      \begin{align*}
        \Amf               & = \{A, c_\varepsilon, f_0, f_1, P) \qquad \text{mit} \\[8pt]
        A                  & = \{0,1\}^*                                          \\
        c_\varepsilon^\Amf & = \varepsilon                                        \\
        f_0^\Amf(w)        & = w0 ~~\text{für alle}~ w \in A                      \\
        f_1^\Amf(w)        & = w1 ~~\text{für alle}~ w \in A                      \\
        P^\Amf             & = \big\{(u,v) \mid \text{es gibt $i_1,\dots,i_\ell$ mit $u=u_{i_1}\cdots u_{i_\ell}$ und $v=v_{i_1}\cdots v_{i_\ell}$}\big\}
      \end{align*}
      %
      Für dieses Modell gilt:
      \par\smallskip
      \begin{enumerate}
        \item[(1)]
          $\Amf \models \varphi$:~
          nach Definition von $P^\Amf$ und wegen $t_w(c_\varepsilon)^\Amf = w$ für alle $w \in \{0,1\}^*$
          \par
        \item[(2)]
          $\Amf \models \psi$:~
          Wenn $P^\Amf(u,v)$, dann folgt mit Definition von $P^\Amf$ auch $P^\Amf(uu_i,vv_i)$ für alle $i \leq k$.
          Wegen $t_w^\Amf(w') = w'w$ für alle $w,w \in \{0,1\}^*$
          gilt so $P^\Amf(t_{u_i}^\Amf(u), t_{v_i}^\Amf(v))$.
      \end{enumerate}
      \par\smallskip
      Weil $\varphi_F$ gültig ist, folgt aus~(1) und~(2) $\Amf \models \exists x\, P(x,x)$.
      Nach Definition von $P^\Amf$ hat also $F$ eine Lösung.
      \par\medskip
    \item[{\boldmath "`$\Rightarrow$"'}]
      Sei $i_1,\dots,i_\ell$ eine Lösung für $F$ und $\Amf = \{A, c_\varepsilon, f_0, f_1, P)$ eine beliebige Struktur.
      Zu zeigen ist $\Amf \models \varphi_F$.
      Wenn $\Amf \not\models \varphi \land \psi$, dann gilt $\Amf \models \varphi_F$.
      Nehmen wir nun also $\Amf \models \varphi \land \psi$ an und zeigen $\Amf \models \exists x\, P(x,x)$.

      Obwohl \Amf nicht notwendigerweise kanonisch ist,
      können wir darin trotzdem die Lösung von $F$ wiederfinden.
      Dazu definieren wir eine Abbildung $h : \{0,1\}^* \to A$, die jedem $0$-$1$-Wort das zugehörige Element im Universum von \Amf zuordnet:
      %
      \begin{align*}
        h(\varepsilon) & = c_\varepsilon^\Amf                                \\
        h(w0)          & = f_0^\Amf(h(w)) ~~\text{für alle}~ w \in \{0,1\}^* \\
        h(w1)          & = f_1^\Amf(h(w)) ~~\text{für alle}~ w \in \{0,1\}^*
      \end{align*}
      %
      Man sieht nun leicht, dass $h(w) = t_w^\Amf(c_\varepsilon)$ für alle $w \in \{0,1\}^*$ gilt.
      Wegen $\Amf \models \varphi$ gilt also
      \[
        \big(h(u_{i_1}),~h(v_{i_1})\big) \in P^\Amf.
      \]
      Wegen $\Amf \models \psi$ können wir induktiv schließen, dass
      \[
        \tag{$*$}
        \big(h(u_{i_1} \cdots u_{i_r}),~h(v_{i_1} \cdots v_{i_r})\big) \in P^\Amf \quad\text{für alle~} r \leq \ell.
      \]
      Sei nun $u_{i_1} \cdots u_{i_\ell} = v_{i_1} \cdots v_{i_\ell} = w$ (da $i_1,\dots,i_\ell$ eine Lösung für $F$ ist).
      Dann gilt wegen $(*)$ also $(h(w),\,h(w)) \in P^\Amf$ und damit $\Amf \models \exists x\, P(x,x)$, was zu zeigen war.
      \qedhere
  \end{description}
\end{beweis}%

% ===================================================================
\section*{T2.21~ Beispiel für endliche Erfüllbarkeit}

Folgender FO-Satz ist erfüllbar, aber nicht endlich erfüllbar:
%
% \begin{align*}
%   & \forall x \, \neg R(x,c) \\
%   & {} \land \forall x \, \exists y \, R(x,y) \\
%   & {} \land \forall x \forall x' \forall y \, \;\!\big(\;\! R(x,y) \wedge R(x',y) \rightarrow  x=x' \;\!\big)
% \end{align*}
\[
  \forall x \, \neg R(x,c)
  \quad\land\quad
  \forall x \, \exists y \, R(x,y)
  \quad\land\quad
  \forall x\, \forall x'\, \forall y \, \;\!\big(\;\! R(x,y) \wedge R(x',y) \rightarrow  x=x' \;\!\big)
\]
%
Dieser Satz ist eine leichte Variation des 2.\ Beispiels in T2.14.
Seine Teile sagen, dass 
\begin{enumerate}
  \item[(1)]
    das Element $c^\Amf$ keinen "`$R$-Vorgänger"' hat;
  \item[(2)]
    jedes Element einen "`$R$-Nachfolger"' hat;
  \item[(3)]
    kein Element zwei "`$R$-Vorgänger"' haben darf.
\end{enumerate}
Damit dieser Satz erfüllbar ist, muss es mindestens ein Element $a_0 = c^\Amf$ im Universum $A$ geben.
Wegen~(2) muss es ein Element $a_1$ mit $R^\Amf(a_0,a_1)$ geben.
Wegen~(1) muss $a_1 \neq a_0$ sein.
Wegen~(2) muss es ein Element $a_2$ mit $R^\Amf(a_1,a_2)$ geben.
Wegen~(1) muss $a_2 \neq a_0$ sein;
wegen~(3) muss $a_2 \neq a_1$ sein.
So kann man die Argumentation induktiv fortsetzen und erhält eine (abzählbar) unendliche Folge
$a_0,a_1,a_2,\dots$ von paarweise verschiedenen Elementen aus $A$.

% ===================================================================
\section*{T2.22~ Beispiele für Theorien}

\begin{enumerate}
  \item
    Die Menge $\textsf{Taut}(\tau)$ aller Tautologien in einer fixen Signatur $\tau$ ist
    \begin{itemize}
      \item
        eine FO-Theorie:
        \par
        Wegen der Def.\ von Tautologien gilt:
%         \[
%           \tag{$*$}
%           \Amf \models \textsf{Taut}(\tau)\qquad \text{für \emph{jede} Struktur~} \Amf
%         \]
        $\Amf \models \textsf{Taut}(\tau)$ für \emph{jede} Struktur $\Amf$\quad $(*)$
        \par
        Also ist
        \begin{itemize}
          \item
            $\textsf{Taut}(\tau)$ erfüllbar wegen $(*)$;
          \item
            $\textsf{Taut}(\tau)$ abgeschlossen unter Konsequenz:
            wenn $\textsf{Taut}(\tau) \models \varphi$,
            dann ist $\varphi$ Tautologie (wegen $(*)$ und der Definition von $\models$\,)
            und damit $\varphi \in \textsf{Taut}(\tau)$.
        \end{itemize}
        \par\smallskip
      \item
        nicht vollständig:
        \par
        Es gibt Sätze $\varphi$, die weder Tautologie sind noch unerfüllbar -- also gilt weder
        $\varphi \in \textsf{Taut}(\tau)$, noch $\lnot\varphi \in \textsf{Taut}(\tau)$.
        Finde selbst einen solchen Satz.
        \par\smallskip
      \item
        enthalten in allen anderen Theorien:
        \par
        Jede Theorie enthält alle Tautologien, denn diese sind Konsequenzen \emph{aller} Formelmengen (siehe Def.\ Tautologie bzw.\ Konsequenz).
    \end{itemize}
    \par\smallskip
  \item
    Sei \Amf eine $\tau$-Struktur. Dann ist
    \[
      \tag{$*$}
      \textsf{Th}(\Amf)=\{ \varphi \text{ ist $\tau$-Satz} \mid \Amf \models \varphi \}
    \]
    %
    \begin{itemize}
      \item
        eine FO-Theorie:
        \par
        \begin{itemize}
          \item
            $\textsf{Th}(\Amf)$ ist erfüllbar, denn wegen $(*)$ gilt $\Amf \models \textsf{Th}(\Amf)$.\quad $(**)$
          \item
            $\textsf{Th}(\Amf)$ ist abgeschlossen unter Konsequenz, denn
            wenn $\textsf{Th}(\Amf) \models \varphi$,
            dann wegen $(**)$ auch $\Amf \models \varphi$;
            also gilt wegen $(*)$: $\varphi \in \textsf{Th}(\Amf)$.
        \end{itemize}
        \par\smallskip
      \item
        vollständig:
        \par
        Für jede $\tau$-Struktur \Amf und jeden $\tau$-Satz $\varphi$ gilt $\Amf \models \varphi$ oder $\Amf \models \lnot\varphi$
        (was leicht per strukturelle Induktion gezeigt werden kann).
    \end{itemize}
    \par\smallskip
  \item
    Sei $\Omega$ eine erf\"ullbare Menge von FO-S\"atzen.
    Dann ist
    \[
      \textsf{Abschluss}(\Omega) = \{ \varphi \text{ ist $\tau$-Satz} \mid \Omega \models \varphi \}
    \]
    \begin{itemize}
      \item
        eine FO-Theorie:
        \par
        \begin{itemize}
          \item
            $\textsf{Abschluss}(\Omega)$ ist erfüllbar, da $\Omega$ erfüllbar ist
            und alle Konsequenzen aus $\Omega$ in den Modellen von $\Omega$ ebenfalls wahr sind.
          \item
            $\textsf{Abschluss}(\Omega)$ ist aufgrund seiner Definition und der Transitivität der Konsequenz abgeschlossen unter Konsequenz:
            Wenn $\textsf{Abschluss}(\Omega) \models \varphi$, dann bereits $\Omega \models \varphi$,
            also $\varphi \in \textsf{Abschluss}(\Omega)$.
        \end{itemize}
        \par\smallskip
      \item
        im Allgemeinen nicht vollständig:
        \par
        Für $\Omega = \emptyset$ beispielsweise ist $\textsf{Abschluss}(\Omega) = \textsf{Taut}(\tau)$,
        was wegen Punkt~1 nicht vollständig ist.
        Ist andererseits $\Omega$ selbst bereits eine vollständige Theorie,
        dann ist $\textsf{Abschluss}(\Omega) = \Omega$ und damit vollständig.
    \end{itemize}
    \par\smallskip
  \item
    Sei $\Kmc$ eine Klasse von $\tau$-Strukturen. Dann ist
    \[
      \textsf{Th}(\Kmc) = \bigcap_{\Amf \in \Kmc} \textsf{Th}(\Amf)
    \]
    %
    \begin{itemize}
      \item
        eine FO-Theorie:
        \par
        \begin{itemize}
          \item
            $\textsf{Th}(\Kmc)$ ist erfüllbar: wegen $(**)$ aus Punkt~2 gilt 
            $\Amf \models \textsf{Th}(\Kmc)$ für alle $\Amf \in \Kmc$.
          \item
            $\textsf{Th}(\Kmc)$ abgeschlossen unter Konsequenz, weil es der Schnitt von unter Konsequenz abgeschlossenen Mengen ist:
            Wenn $\textsf{Th}(\Kmc) \models \varphi$, dann $\Amf \models \varphi$
            für alle $\Amf \in \Kmc$.
            Also $\varphi \in \textsf{Th}(\Amf)$ wegen Punkt~2,
            und damit $\varphi \in \textsf{Th}(\Kmc)$.
        \end{itemize}
        \par\smallskip
      \item
        im Allgemeinen nicht vollständig:
        \par
        Wenn beispielweise $\Kmc$ die Klasse \emph{aller} $\tau$-Strukturen ist,
        dann ist $\textsf{Th}(\Kmc) = \textsf{Taut}(\tau)$,
        was wegen Punkt~1 nicht vollständig ist.
        Ist andererseits $\Kmc=\{\Amf\}$ eine einelementige Klasse,
        dann ist $\textsf{Th}(\Kmc) = \textsf{Th}(\Amf)$ und wegen Punkt~2 vollständig.
    \end{itemize}
\end{enumerate}

% ===================================================================
\section*{T2.23~ Beweis des Lemmas über Vollständigkeit von Theorien}

\par\medskip\noindent
\textsfbf{Lemma~2.30.}~
Sei $\Gamma$ eine FO-Theorie. Dann sind die folgenden Aussagen \"aquivalent:
\begin{enumerate}
  \item[(1)]
    $\Gamma$ ist vollst\"andig
  \item[(2)]
    $\Gamma=\textsf{Th}(\Amf)$ f\"ur eine Struktur \Amf
  \item[(3)]
    alle Modelle $\Amf',\Amf''$ von $\Gamma$ sind elementar \"aquivalent
\end{enumerate}
%
\begin{beweis}
  \begin{description}
    \item[{\boldmath "`(1) $\Rightarrow$ (2)"'.}]
      ~\par\smallskip
      Sei $\Gamma$ vollständig.
      Da $\Gamma$ als Theorie erfüllbar ist, gibt es ein Modell $\Amf$ mit $\Amf \models \Gamma$;
      also ist $\Gamma \subseteq \textsf{Th}(\Amf)$.
      Es bleibt zu zeigen, dass die umgekehrte Inklusion $\textsf{Th}(\Amf) \subseteq \Gamma$ gilt.
      Sei also $\varphi \in \textsf{Th}(\Amf)$.
      Da $\Gamma$ vollständig ist, gilt $\varphi \in \Gamma$ oder $\lnot\varphi \in \Gamma$.
      Letzteres ist aber unmöglich, weil $\Amf \models \Gamma$. Also $\varphi \in \Gamma$.
      \par\smallskip
    \item[{\boldmath "`(2) $\Rightarrow$ (3)"'.}]
      ~\par\smallskip
      Sei $\Gamma=\textsf{Th}(\Amf)$
      und seien $\Amf',\Amf''$ Modelle von $\Gamma$.
      Sei $\Amf' \models \varphi$. Zu zeigen ist $\Amf'' \models \varphi$.
      Wegen $\Amf \models \varphi$ oder $\Amf \models \lnot\varphi$
      ist auch $\varphi \in \Gamma$ oder $\lnot\varphi \in \Gamma$.
      Da $\Amf' \models \Gamma$ und $\Amf' \models \varphi$,
      ist $\neg\varphi \in \Gamma$ ausgeschlossen.
      Also ist $\varphi \in \Gamma$ und wegen $\Amf'' \models \Gamma$ auch $\Amf'' \models \varphi$.
      \par\smallskip
    \item[{\boldmath "`(3) $\Rightarrow$ (1)"'.}]
      ~\par\smallskip
      Seien alle Modelle von $\Gamma$ elementar äquivalent
      und sei $\varphi$ ein Satz.
      Zu zeigen ist: $\varphi \in \Gamma$ oder $\lnot\varphi \in \Gamma$.
      Angenommen, keines von beiden ist der Fall.
      Dann gilt wegen der Abgeschlossenheit von $\Gamma$ unter Konsequenz mittels Kontraposition:
      $\Gamma \not\models \varphi$ und $\Gamma \not\models \lnot\varphi$.
      Also gibt es Modelle $\Amf',\Amf''$ von $\Gamma$ mit $\Amf' \models \lnot\varphi$
      und $\Amf'' \models \varphi$.
      Dann sind aber $\Amf'$ und $\Amf''$ nicht elementar äquivalent;
      ein Widerspruch zur Annahme.
      \qedhere
  \end{description}

\end{beweis}%


% ===================================================================
% ===================================================================
% ===================================================================
\part{Mehr zu Prädikatenlogik 1.\ Stufe}

% ===================================================================
\section*{T3.1~ Erklärungen zu den Schlussregeln des Sequenzenkalküls}

Am besten liest man die Regeln "`von oben nach unten"':
%
\par\medskip
\begin{description}
  \item[{\boldmath $(\land \Rightarrow)$}]
    $
      \displaystyle
      \frac{\Gamma,\vp,\psi \Rightarrow \Delta}{\Gamma, \vp \wedge \psi \Rightarrow \Delta}
    $
    ~\par\medskip
    Wenn die obere Sequenz $\Gamma,\vp,\psi \Rightarrow \Delta$ gültig ist,
    dann auch die untere Sequenz $\Gamma, \vp \wedge \psi \Rightarrow \Delta$,
    denn ihre Antezedensen $\Gamma \cup \{\varphi,\psi\}$ und
    $\Gamma \cup \{\varphi \land \psi\}$
    haben dieselben Modelle.
    \par\bigskip
  \item[{\boldmath $(\Rightarrow \land)$}]
    $
      \displaystyle
      \frac{\Gamma \Rightarrow \Delta,\vp \quad \Gamma \Rightarrow \Delta,\psi}{\Gamma \Rightarrow \Delta, \vp \wedge \psi}
    $
    ~\par\medskip
    Wenn die oberen beiden Sequenzen gültig sind, dann gilt:
    \[
      \bigwedge \Gamma \models
      \Big(
        \bigvee \big(\Delta \cup \{\varphi\}\big)
        \land
        \bigvee \big(\Delta \cup \{\psi\}\big)
      \Big)
    \]
    Nach dem Distributivgesetz%
    \footnote{%
      Das dürfen wir anwenden, weil wir \emph{endliche} Formelmengen betrachten
      und deshalb alle Konjunktionen bzw.\ Disjunktionen (endliche) FO-Formeln sind.%
    }
    gilt dann auch:
    \[
      \bigwedge \Gamma \models
      \bigvee \big(\Delta \cup \{\varphi \land \psi\}\big)
    \]
  \item[{\boldmath $(\lor \Rightarrow)$}]
    $
      \displaystyle
      \frac{\Gamma,\vp \Rightarrow \Delta \quad \Gamma,\psi \Rightarrow \Delta}{\Gamma, \vp \vee \psi \Rightarrow \Delta}
    $
    ~\par\medskip
    Diese Regel ist dual zu $(\Rightarrow \land)$
    in dem Sinne, dass hier die Antezedensen so verändert werden
    wie dort die Sukzedensen, wobei ``$\land$'' durch ``$\lor$'' ersetzt wird.

    Man kann hier auch wieder analog wie oben argumentieren, unter Verwendung des Distributivgesetzes (probiert es aus).
    \par\bigskip
  \item[{\boldmath $(\Rightarrow \lor)$}]
    $
      \displaystyle
      \frac{\Gamma \Rightarrow \Delta,\vp,\psi}{\Gamma \Rightarrow \Delta, \vp \vee \psi}
    $
    ~\par\medskip
    Diese Regel ist dual zu $(\land \Rightarrow)$
    in dem Sinne, dass hier die Sukzedensen so verändert werden
    wie dort die Antezedensen, wobei ``$\land$'' durch ``$\lor$'' ersetzt wird.

    Man kann hier auch wieder analog wie ganz oben argumentieren:
    die Sukzedensen $\Delta \cup\{\vp,\psi\}$ und $\Delta \cup \{\vp \vee \psi\}$
    (als Disjunktionen aufgefasst!)
    haben dieselben Modelle.
    \par\bigskip
  \item[{\boldmath $(\lnot \Rightarrow)$}]
    $
      \displaystyle
      \frac{\Gamma \Rightarrow \Delta,\vp}{\Gamma,\neg \vp \Rightarrow \Delta}
    $
    ~\par\medskip
    Wenn die obere Sequenz gültig ist, dann gilt:
    \[
      \tag{$*$}
      \bigwedge \Gamma \models
      \bigvee \big(\Delta \cup \{\varphi\}\big)
    \]
    Um zu zeigen, dass daraus
    \[
      \tag{$**$}
      \bigwedge \big(\Gamma \cup \{\lnot\varphi\}\big) \models
      \bigvee \Delta\
    \]
    folgt, betrachten wir ein beliebiges Modell $\Amf \models \bigwedge \big(\Gamma \cup \{\lnot\varphi\}\big)$.
    Insbesondere haben wir also $\Amf \models \bigwedge \Gamma$ und $\Amf \models \lnot\varphi$ (Semantik der Konjunktion).
    Wegen $\Amf \models \bigwedge \Gamma$ und $(*)$ gilt $\Amf \models \bigvee \big(\Delta \cup \{\varphi\}\big)$.
    Zusammen mit $\Amf \models \lnot\varphi$ folgt $\Amf \models \bigvee \Delta$.
    Also ist $(**)$ gültig.
    \par\bigskip
  \item[{\boldmath $(\Rightarrow \lnot)$}]
    $
      \displaystyle
      \frac{\Gamma,\vp \Rightarrow \Delta}{\Gamma \Rightarrow \Delta,\neg \vp}
    $
    ~\par\medskip
    Wenn die obere Sequenz gültig ist, dann gilt:
    \[
      \tag{$*$}
      \bigwedge \big(\Gamma\cup \{\varphi\}\big) \models
      \bigvee \Delta
    \]
    Um zu zeigen, dass daraus
    \[
      \tag{$**$}
      \bigwedge \Gamma \models
      \bigvee \big(\Delta \cup \{\lnot\varphi\}\big)
    \]
    ~\par\medskip
    folgt, betrachten wir ein beliebiges Modell $\Amf \models \bigwedge \Gamma$.
    Wenn $\Amf \models \varphi$, dann folgt wegen $(*)$, dass $\Amf \models \bigvee \Delta$,
    also auch $\Amf \models \bigvee \big(\Delta \cup \{\lnot \varphi\}\big)$.
    Wenn $\Amf \models \lnot \varphi$, dann gilt sowieso $\Amf \models \bigvee \big(\Delta \cup \{\lnot \varphi\}\big)$.
    Also ist $(**)$ gültig.
    \par\bigskip
  \item[{\boldmath $(\exists \Rightarrow)$}]
    $
      \displaystyle
      \frac{\Gamma,\vp[c] \Rightarrow \Delta}{\Gamma, \exists x \, \vp(x) \Rightarrow \Delta}
    $
    ~wenn die Konstante $c$ nirgends in $\Gamma,\Delta,\varphi(x)$ vorkommt.
    ~\par\medskip
    Intuitiv besagt diese Regel, dass man eine Konstante, die sonst nirgends vorkommt,
    auch durch ein "`anonymes Objekt"' ersetzen darf.

    Genauer:
    Wenn die obere Sequenz gültig ist, dann gilt:
    \[
      \tag{$*$}
      \bigwedge \big(\Gamma\cup \{\varphi[c]\}\big) \models
      \bigvee \Delta
    \]
    Um zu zeigen, dass daraus
    \[
      \tag{$**$}
      \bigwedge \big(\Gamma\cup \{\exists x\,\varphi(x)\}\big) \models
      \bigvee \Delta
    \]
    folgt, betrachten wir ein beliebiges Modell $\Amf \models \bigwedge \big(\Gamma\cup \{\exists x\,\varphi(x)\}\big)$.
    Insbesondere gilt $\Amf \models \exists x\,\varphi(x)$, also gibt es ein $a \in A$ mit $\Amf \models \varphi[a]$.
    Sei $\Amf'$ die Struktur, die man aus $\Amf$ erhält, indem man zusätzlich $c^{\Amf'} = a$ setzt.
    Dann gilt:
    \begin{itemize}
      \item 
        $\Amf' \models \varphi[c]$ (weil $c$ nicht in $\varphi(x)$ vorkommt, kann sich der Wahrheitswert von $\varphi$ durch die Transformation auch nicht ändern)\quad und
      \item
        und $\Amf' \models \Gamma$ (weil $c$ nicht in $\Gamma$ vorkommt).
    \end{itemize}
    Also $\Amf' \models \bigwedge \big(\Gamma\cup \{\varphi[c]\}\big)$.
    Wegen $(*)$ erhalten wir 
    $\Amf' \models \bigvee \Delta$.
    Weil $c$ nicht in $\Delta$ vorkommt, folgt $\Amf \models \bigvee \Delta$.
    Also ist $(**)$ gültig.

    \par\smallskip
    Diese Argumentation benutzt die Seitenbedingung "`wenn die Konstante $c$ nirgends in $\Gamma,\Delta,\varphi(x)$ vorkommt"'.
    Ohne diese Bedingung wäre die Regel nicht korrekt, was man am besten an konkreten Beispielen sieht:
    \par\medskip
    \begin{center}
      \begin{tabular}{r@{~}c@{\qquad}l@{}}
        $P(c), Q(c) ~\Rightarrow~ P(c) \land Q(c)$            & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $P(c), \exists x\,Q(x) ~\Rightarrow~ P(c) \land Q(c)$ & & ist nicht gültig
      \end{tabular}
    \end{center}
    \par\medskip
    \begin{center}
      \begin{tabular}{r@{~}c@{\qquad}l@{}}
        $P(c) \land Q(c) ~\Rightarrow~ P(c)$                      & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $\exists x\,\big(P(x) \land Q(x)\big) ~\Rightarrow~ P(c)$ & & ist nicht gültig
      \end{tabular}
    \end{center}
    \par\bigskip
  \item[{\boldmath $(\Rightarrow\exists)$}]
    $
      \displaystyle
      \frac{\Gamma \Rightarrow \Delta,\vp[t]}{\Gamma \Rightarrow \Delta, \exists x \, \vp(x)}
    $
    ~wobei $t$ ein beliebiger Term ist
    ~\par\medskip
    Intuitiv besagt diese Regel: wenn $\varphi[t]$ für ein konkretes Element $t$ \emph{impliziert wird},
    dann auch für ein beliebiges, existentiell quantifiziertes Objekt.
    Probiert die formale Argumentation gern selbst aus!
    \par\medskip
    Die Seitenbedingung wird nicht gebraucht;
    insbesondere sind die obigen Beispiele hier keine Gegenbeispiele:
    \begin{center}
      \begin{tabular}{l@{~}c@{\qquad}l@{}}
        $P(c), Q(c) ~\Rightarrow~ P(c) \land Q(c)$            & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $P(c), Q(c) ~\Rightarrow~ \exists x\,\big(P(x) \land Q(x)\big)$ & & ist auch gültig
      \end{tabular}
    \end{center}
    \par\medskip
    \begin{center}
      \begin{tabular}{l@{~}c@{\qquad}l@{}}
        $P(c) \land Q(c) ~\Rightarrow~ P(c)$            & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $P(c) \land Q(c) ~\Rightarrow~ \exists x\,P(x)$ & & ist auch gültig
      \end{tabular}
    \end{center}
    \par\bigskip
  \item[{\boldmath $(\forall\Rightarrow)$}]
    $
      \displaystyle
      \frac{\Gamma,\vp[t] \Rightarrow \Delta}{\Gamma, \forall x \, \vp(x) \Rightarrow \Delta}
    $
    ~wobei $t$ ein beliebiger Term ist
    ~\par\medskip
    Dual zu $(\Rightarrow\exists)$.
    \par\bigskip
  \item[{\boldmath $(\Rightarrow\forall)$}]
    $
      \displaystyle
      \frac{\Gamma \Rightarrow \Delta,\vp[c]}{\Gamma \Rightarrow \Delta, \exists x \, \vp(x) }
    $
    ~wenn die Konstante $c$ nirgends in $\Gamma,\Delta,\varphi(x)$ vorkommt.
    ~\par\medskip
    Dual zu $(\exists\Rightarrow)$.
\end{description}

\pagebreak
% ===================================================================
\section*{Anmerkung zu den Seitenbedingungen von {\boldmath $(\exists \Rightarrow)$ und $(\Rightarrow \forall)$}}

\textsfbf{Diese Anmerkung ist nicht wesentlich} fürs Verständnis des Sequenzenkalküls
\textsfbf{und kann getrost übersprungen werden.}
Ich hatte sie aufgenommen, als im WiSe 2016/17 die Frage aufkam,
ob die Seitenbedingungen "`$c$ nicht in $\Gamma,\Delta,\varphi(x)$"'
der Regeln $(\exists \Rightarrow)$ und $(\Rightarrow \forall)$
abgeschwächt werden können.

Im obigen Beweis der Korrektheit von $(\exists \Rightarrow)$ wird verwendet,
dass $c$ \emph{weder} in $\Gamma$, \emph{noch} in $\Delta$, \emph{noch} in $\varphi(x)$ vorkommt.
Im vorangehenden Beispiel für die Inkorrektheit der Regel ohne die Seitenbedingung
kommt $c$ \emph{sowohl} in $\Gamma$ \emph{als auch} in $\Delta$ \emph{als auch} in $\varphi(x)$ vor.
Es gibt aber auch Beispiele, in denen die Regel inkorrekt ist, wenn $c$
\emph{nur in} $\Gamma$ oder \emph{nur in} $\Delta$ oder \emph{nur in} $\varphi(x)$ vorkommt:
%
\begin{itemize}
  \item
    nur in $\Delta$:
    \par\smallskip
    Betrachte $\Gamma = \emptyset$, $\Delta = P(c)$, $\varphi(x) = P(x)$; also $\varphi[c] = P(c)$.
    \par\smallskip
    \begin{center}
      \begin{tabular}{r@{~}c@{\qquad}l@{}}
        $P(c) ~\Rightarrow~ P(c)$            & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $\exists x\,P(c) ~\Rightarrow~ P(c)$ & & ist nicht gültig
      \end{tabular}
    \end{center}
    \par\smallskip
    Für die ungültige Sequenz in der unteren Zeile betrachte man $\Amf$ mit $A=\{a,b\}$, $c^\Amf = a$ und $P^\Amf = \{b\}$.
    \par\smallskip
  \item
    nur in $\Gamma$:
    \par\smallskip
    Betrachte $\Gamma = \lnot P(c)$, $\Delta = \emptyset$, $\varphi(x) = P(x)$; also $\varphi[c] = P(c)$.
    \par\smallskip
    \begin{center}
      \begin{tabular}{r@{~}c@{\qquad}l@{}}
        $\lnot P(c),P(c) ~\Rightarrow~ \emptyset$            & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $\lnot P(c),\exists x\,P(x) ~\Rightarrow~ \emptyset$ & & ist nicht gültig
      \end{tabular}
    \end{center}
    Für die gültige Sequenz in der oberen Zeile beobachte man, dass das Antezedens unerfüllbar ist;
    für die ungültige Sequenz in der unteren Zeile betrachte man dasselbe Modell $\Amf$ wie oben.
    \par\smallskip
  \item
    nur in $\varphi(x)$:
    \par\smallskip
    Betrachte $\Gamma = \Delta = \emptyset$, $\varphi(x) = P(x) \land \lnot P(c)$; also $\varphi[c] = P(c) \land \lnot P(c)$.
    \par\smallskip
    \begin{center}
      \begin{tabular}{r@{~}c@{\qquad}l@{}}
        $P(c) \land \lnot P(c) ~\Rightarrow~ \emptyset$              & & ist gültig \\[2pt]\cline{1-1}
        \rule{0pt}{12pt}%
        $\exists x\,(P(x) \land \lnot P(c)) ~\Rightarrow~ \emptyset$ & & ist nicht gültig
      \end{tabular}
    \end{center}
    \par\smallskip
    Die Argumentation für (Un)Gültigkeit ist dieselbe wie im letzten Fall.
\end{itemize}



% ===================================================================
\section*{T3.2~ Beispiel für eine ableitbare Sequenz}

\begin{itemize}
  \item
    $P(c),Q(c) ~\Rightarrow~ P(c),R(c)$\quad  ist ein Axiom, weil $P(c)$ auf beiden Seiten auftritt.
  \item
    $P(c),Q(c) ~\Rightarrow~ Q(c),R(c)$\quad  ist ein Axiom, weil $Q(c)$ auf beiden Seiten auftritt.
  \item
    Setzt man nun $\Gamma = \{P(c),Q(c)\}$ und $\Delta = \{R(c)\}$,
    so erhält man mit der Regel $(\Rightarrow \land)$ die Sequenz:

    $P(c),Q(c) ~\Rightarrow~ P(c) \land Q(c), R(c)$
\end{itemize}

% ===================================================================
\section*{T3.3~ Beispiele für SK-Beweise}

Man beginnt mit der zu beweisenden Sequenz und wendet Regeln \emph{von unten nach oben} an,
bis man Axiome erhält. Man lese die folgenden Beweise also \emph{von unten nach oben!}

\begin{enumerate}
  \item
    Für beliebige Formeln $\varphi,\psi$ ist folgendes ein SK-Beweis:
    \par\smallskip
    \begin{center}
      \begin{tabular}{cccl}
        $\varphi ~\Rightarrow~ \varphi,\psi$                       & \qquad & $\psi ~\Rightarrow~ \varphi,\psi$                       &                       \\[-6pt]
        \hrulefill                                                 &        & \hrulefill                                              & $(\Rightarrow \lor)$  \\[-2pt]
        $\varphi ~\Rightarrow~ \varphi \lor \psi$                  & \qquad & $\psi ~\Rightarrow~ \varphi \lor \psi$                  &                       \\[-6pt]
        \hrulefill                                                 &        & \hrulefill                                              & $(\lnot \Rightarrow)$ \\[-2pt]
        $\lnot(\varphi \lor \psi),\varphi ~\Rightarrow~ \emptyset$ & \qquad & $\lnot(\varphi \lor \psi),\psi ~\Rightarrow~ \emptyset$ &                       \\[-6pt]
        \hrulefill                                                 &        & \hrulefill                                              & $(\Rightarrow\lnot)$  \\[-2pt]
        $\lnot(\varphi \lor \psi) ~\Rightarrow~ \lnot\varphi$      & \qquad & $\lnot(\varphi \lor \psi) ~\Rightarrow~ \lnot\psi$      &                       \\[-6pt]
        \multicolumn{3}{c}{\hrulefill}                                                                                                & $(\Rightarrow\land)$  \\[-2pt]
        \multicolumn{3}{c}{$\lnot(\varphi \lor \psi) ~\Rightarrow~ \lnot\varphi \land \lnot\psi$}                                     &
      \end{tabular}
    \end{center}
    \par\medskip
  \item
    Ein SK-Beweis, der nur Quantoren-Regeln verwendet:
    \par\smallskip
    \begin{center}
      \begin{tabular}{cl}
        $R(c,d) ~\Rightarrow~ R(c,d)$                                             &                         \\[-6pt]
        \hrulefill                                                                & $(\Rightarrow \exists)$ \\[-2pt]
        $R(c,d) ~\Rightarrow~ \exists x\,R(x,d)$                                  &                         \\[-6pt]
        \hrulefill                                                                & $(\forall \Rightarrow)$ \\[-2pt]
        $\forall y\,R(c,y) ~\Rightarrow~ \exists x\,R(x,d)$                       &                         \\[-6pt]
        \hrulefill                                                                & $(\Rightarrow \forall)$ \\[-2pt]
        $\forall y\,R(c,y) ~\Rightarrow~ \forall y\,\exists x\,R(x,y)$            &                         \\[-6pt]
        \hrulefill                                                                & $(\exists \Rightarrow)$ \\[-2pt]
        $\exists x\,\forall y\,R(x,y) ~\Rightarrow~ \forall y\,\exists x\,R(x,y)$ &
      \end{tabular}
    \end{center}
    \par\smallskip
    Bei den unteren beiden Schritten muss die Seitenbedingung eingehalten werden;
    bei den oberen beiden Schritten nicht -- deshalb dürfen wir hier die bereits benutzten Terme (Konstanten) $c$ und $d$
    "`einführen"'.
    Es kommt also in diesem Beispiel auf die Reihenfolge der Regelanwendung an. Wenn wir die zwei letzten (obersten)
    Regeln $(\forall \Rightarrow)$ und $(\Rightarrow \exists)$ zuerst (zuunterst) anwenden würden,
    hätten wir bereits $c$ und $d$ eingeführt
    und dürften mit den anderen beiden Regeln wegen ihrer Seitenbedingung
    kein weiteres $c$ bzw.\ $d$ einführen.
    \par\medskip
  \item
    Ein SK-Beweis, der Formeln im Antezedens "`behält"' (siehe Folie 11):
    \par\smallskip
    \begin{center}
      \begin{tabular}{cccl}
        $P(c),P(d) ~\Rightarrow~ P(c)$ & \qquad & $P(c),P(d) ~\Rightarrow~ P(d)$ &                        \\[-6pt]
        \multicolumn{3}{c}{\hrulefill}                                           & $(\Rightarrow\land)$   \\[-2pt]
        \multicolumn{3}{c}{$P(c),P(d) ~\Rightarrow~ P(c) \land P(d)$}            &                        \\[-6pt]
        \multicolumn{3}{c}{\hrulefill}                                           & $(\forall\Rightarrow)$ \\[-2pt]
        \multicolumn{3}{c}{$\forall x\,P(x),P(c) ~\Rightarrow~ P(c) \land P(d)$} &                        \\[-6pt]
        \multicolumn{3}{c}{\hrulefill}                                           & $(\forall\Rightarrow)$ \\[-2pt]
        \multicolumn{3}{c}{$\forall x\,P(x) ~\Rightarrow~ P(c) \land P(d)$}      &
      \end{tabular}
    \end{center}
    \par\smallskip
    Im untersten Schritt wendet man also die Regel $(\forall\Rightarrow)$ auf $\forall x\,P(x)$ an, ohne dieses zu löschen.
    Das ist zugelassen, denn "`$\Gamma,\varphi \Rightarrow \Delta,\psi$"' schließt auch den Fall $\varphi \in \Gamma$ ein.
    In diesem Beispiel kann man zwar auf das Behalten von $(\forall\Rightarrow)$ verzichten,
    wenn man die letzte (oberste) Regel $(\Rightarrow\land)$ zuerst (zuunterst) anwendet;
    für das  Ableiten anderer Sequenzen ist das Behalten aber essentiell.
    Dies ist im übrigen auch der Grund, warum die Länge von SK-Beweisen
    \emph{nicht} exponentiell in der Länge der zu beweisenden Sequenz beschränkt ist.
\end{enumerate}

% ===================================================================
\section*{T3.4~ Beweis der Korrektheit des SK}

Nach den Bemerkungen auf Folie~12 genügt es zu zeigen, dass jede einzelne SK-Regel korrekt ist,
d.\,h.\ wenn die obere(n) Sequenz(en) gültig ist/sind, dann auch die untere.
Dies haben wir jedoch bereits in T3.1 für die einzelnen Regeln gezeigt.

% ===================================================================
\section*{T3.5~ Beispiele für die Vervollständigung von {\boldmath $\Gamma$}}

Der Beweis der Vollständigkeit des SK wird mittels Kontraposition geführt.
Wir nehmen also an, $\Gamma \Rightarrow \Delta$ sei \emph{nicht ableitbar}.
Das Ziel ist zu zeigen, dass es ein Modell $\Amf \models \Gamma \cup \lnot \Delta$ gibt,
wobei $\lnot \Delta = \{\lnot \varphi \mid \varphi \in \Delta\}$.
Dieses Modell $\Amf$ möchten wir gern aus $\Gamma$ "`ablesen"'.

\begin{enumerate}
  \item[(1)]
    Wenn $\Gamma = \{Q_1(c), \lnot Q_2(c), \exists x\,P(x), P(c)\}$
    und $\Delta = \{Q_2(c), \lnot P(c)\}$
    wie auf Folie~14,
    dann ist klar, wie man $\Amf$ aus $\Gamma$ ablesen kann und dass $\Amf \models \lnot \Delta$:
    \par\vspace*{-\baselineskip}
    \begin{center}
      \parbox{.2\textwidth}{%
        \begin{align*}
          A        & = \{a\} \\
          c^\Amf   & = a     \\
          P^\Amf   & = \{a\} \\
          Q_1^\Amf & = \{a\} \\
          Q_2^\Amf & = \emptyset
        \end{align*}
      }
      \hspace*{.1\textwidth}
      \parbox{.2\textwidth}{%
        \begin{tikzpicture}[%
          node distance=15mm,>=Latex,
          every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
          every edge/.style={draw=black,thin}
        ]
          \node[state] (a)       {$a$};
          \node [left=0mm of a]  {$c$};
          \node [right=0mm of a] {\begin{tabular}{@{}l@{}}$P$\\$Q_1$\end{tabular}};
        \end{tikzpicture}%
      }
    \end{center}
  \item[(2)]
    Sei nun $\Gamma = \{Q_1(c) \lor Q_2(c), \exists x\,P(x)\}$
    und $\Delta = \{\lnot \exists x\,Q_2(x), P(c), \dots\}$.
    Dann ist $\Amf$ durch $\Gamma$ nicht eindeutig bestimmt,
    denn
    \begin{enumerate}
      \item[(a)]
        es gibt zwei Möglichkeiten die Disjunktion $Q_1(c) \lor Q_2(c)$ zu erfüllen;
      \item[(b)]
        es muss ein konkretes Element benannt werden, das $\exists x\,P(x)$ "`bezeugt"';
      \item[(c)]
        damit $\Amf \models \lnot \Delta$, muss ein Element benannt werden,
        das $\exists x\,Q_2(x)$ "`bezeugt"'.
    \end{enumerate}
    Bevor man also $\Amf$ aus $\Gamma$ wie gewünscht ablesen kann,
    muss man $\Gamma$ schrittweise wie folgt erweitern:
    \begin{enumerate}
      \item[(a)]
        Man beobachte, dass eine der zwei folgenden Sequenzen nicht ableitbar sein kann:
        \begin{align*}
          \Gamma \cup \{Q_1(c)\} & ~\Rightarrow~ \Delta \tag{$i$}\\
          \Gamma \cup \{Q_2(c)\} & ~\Rightarrow~ \Delta \tag{$ii$}
        \end{align*}
        Wären nämlich beide ableitbar, dann auch $\Gamma \Rightarrow \Delta$
        (was im Widerspruch zur Annahme steht):
        \par\smallskip
        \begin{center}
          \begin{tabular}{cl}
            $\Gamma \cup \{Q_1(c)\} \Rightarrow \Delta \qquad \Gamma \cup \{Q_2(c)\} \Rightarrow \Delta$ &                     \\[-6pt]
            \hrulefill                                                                                   & $(\lor\Rightarrow)$ \\[-2pt]
            $\Gamma \cup \{Q_1(c) \lor Q_2(c)\} \Rightarrow \Delta$                                      &
          \end{tabular}
        \end{center}
        \par\smallskip
        Das Antezedens der unteren Sequenz ist dabei gleich $\Gamma$,
        weil $Q_1(c) \lor Q_2(c)$ bereits in $\Gamma$ enthalten ist.
        Je nachdem, welche der Sequenzen~$(i)$ oder~$(ii)$ nicht ableitbar ist,
        wird nun $\Gamma$ entsprechend erweitert.
        Wir nehmen o.\,B.\,d.\,A.\ an, dass~$(i)$ nicht ableitbar ist,
        also erweitern wir $\Gamma$ zu
        \[
          \Gamma := \{Q_1(c) \lor Q_2(c), \exists x\,P(x), Q_1(c)\}.
        \]
      \item[(b)]
        Wenn wir die Formel $\exists x\,P(x)$ aus $\Gamma$ betrachten,
        müssen wir ein Element "`festlegen"', welches in $\Amf$ dafür sorgt,
        dass $\Amf \models \exists x\,P(x)$. Dazu führen wir eine neue Konstante
        $c_{\textsf{neu}}$ ein, die weder in $\Gamma$, noch in $\Delta$ auftritt,
        und beobachten,
        dass $\Gamma \cup \{P(c_{\textsf{neu}})\} \Rightarrow \Delta$
        nicht ableitbar sein kann:
        \par\smallskip
        \begin{center}
          \begin{tabular}{cl}
            $\Gamma \cup \{P(c_{\textsf{neu}})\} \Rightarrow \Delta$ &                        \\[-6pt]
            \hrulefill                                               & $(\exists\Rightarrow)$ \\[-2pt]
            $\Gamma \cup \{\exists x\,P(x)\} \Rightarrow \Delta$     &
          \end{tabular}
        \end{center}
        \par\smallskip
        Die untere Sequenz besagt aber wieder, dass $\Gamma \Rightarrow \Delta$
        ableitbar wäre, was im Widerspruch zur Annahme steht.
        Wir erweitern also $\Gamma$ zu
        \[
          \Gamma := \{Q_1(c) \lor Q_2(c), \exists x\,P(x), Q_1(c), P(c_{\textsf{neu}})\}.
        \]
      \item[(c)]
        Nun ist zwar $\Amf$ im Sinne von Beispiel~(1)
        durch $\Gamma$ eindeutig bestimmt,
        aber $\Amf$ macht noch nicht $\exists x\, Q_2(x) \in \lnot \Delta$ wahr.
        Man muss also $\Gamma$ noch mehr erweitern:
        Wegen $\lnot \exists x\, Q_2(x) \in \Delta$
        ist $\Gamma \cup \{\exists x\,Q_2(x)\} \Rightarrow \Delta$
        nicht ableitbar -- denn wenn es das wäre, dann mittels $(\Rightarrow \lnot)$
        auch $\Gamma \Rightarrow \Delta$.
        Also wird $\Gamma$ wieder entsprechend erweitert,
        und es sind wegen der neu hinzugekommenen Formel $\exists x\,Q_2(x)$
        mehr Erweiterungen notwendig \dots
    \end{enumerate}
\end{enumerate}

% ===================================================================
\section*{T3.6~ Beweis des Kompaktheitssatzes}

\textsfbf{Theorem 3.10.}~
% \par\noindent
F\"ur alle Mengen von S\"atzen $\Gamma \subseteq \textsf{FO}$ und S\"atze $\vp \in \textsf{FO}$ gilt:
%
\begin{enumerate}
  \item[(1)]
    $\Gamma$ ist erf\"ullbar
    ~gdw.~
    jede endliche Teilmenge von $\Gamma$ erf\"ullbar ist.
  \item[(2)]
    $\Gamma \models \vp$
    ~gdw.~
    endliches $\Gamma_{\!\!\:\textsf{f}} \subseteq \Gamma$ existiert mit $\Gamma_{\!\!\:\textsf{f}} \models \vp$.
\end{enumerate}

%
\begin{beweis}
  Da~(1) mit den üblichen semantischen Beziehungen aus~(2) folgt
  (siehe Fragebogen),
  beschränken wir uns darauf, (2) zu zeigen.
  \begin{description}
    \item[{\boldmath "`$\Leftarrow$"'.}]
%       ~\par\smallskip
      Folgt unmittelbar, denn jedes Modell von $\Gamma$ ist ein Modell jeder Teilmenge von $\Gamma$,
      und nach Definition der Konsequenz
      ist dann auch jede Konsequenz von $\Gamma$ eine Konsequenz jeder beliebigen Teilmenge von $\Gamma$.
      \par\smallskip
    \item[{\boldmath "`$\Rightarrow$"'.}]
%       ~\par\smallskip
      Gelte $\Gamma \models \varphi$.
      Dann ist die Sequenz $\emptyset \Rightarrow \{\varphi\}$
      aus der Formelmenge $\Gamma$ folgerbar,
      d.\,h.\ $\Gamma \models \emptyset \Rightarrow \{\varphi\}$
      (s.\ Folie~25).
      Wegen der Vollständigkeit der $\Gamma$-Erweiterung des SK (Theorem~3.11)
      ist die Sequenz $\emptyset \Rightarrow \Delta$ in der $\Gamma$-Erweiterung ableitbar.
      Jeder SK-Beweis ist jedoch endlich, und dies gilt auch für die $\Gamma$-Erweiterung.
      Betrachte also einen endlichen SK-Beweis $B$ für $\emptyset \Rightarrow \Delta$
      in der $\Gamma$-Erweiterung.
      Dieser Beweis kann nur endlich oft die $\Gamma$-Regel anwenden
      und dabei nur endlich viele Elemente $\varphi \in \Gamma$ verwenden.
      Sei $\Gamma_{\!\!\:\textsf{f}}$ die Menge aller verwendeten $\varphi \in \Gamma$.
      Dann ist $B$ auch ein SK-Beweis in der $\Gamma_{\!\!\:\textsf{f}}$-Erweiterung.
      Wegen der Korrektheit der $\Gamma_{\!\!\:\textsf{f}}$-Erweiterung des SK
      folgt nun $\Gamma_{\!\!\:\textsf{f}} \models \emptyset \Rightarrow \{\varphi\}$,
      also $\Gamma_{\!\!\:\textsf{f}} \models \varphi$.
      \qedhere
  \end{description}
\end{beweis}%

% ===================================================================
\section*{T3.7~ Beweis des Satzes über unbeschränkte endliche Modelle}

\textsfbf{Theorem 3.12.}~
% \par\noindent
Wenn ein FO-Satz $\vp$ beliebig große endliche Modelle besitzt
(d.\,h.\ f\"ur jedes $n \geq 0$ gibt es Modell $\mathfrak{A}$ mit $|A|\geq n$),
dann hat $\vp$ auch ein unendliches Modell.
%
\begin{beweis}
  Sei $\varphi$ ein FO-Satz, der beliebig große Modelle besitzt.
  Setze
  \begin{align*}
    \Gamma & ~=~ \{\varphi\} \cup \{\psi_n \mid n > 0\},\quad \text{wobei} \\
    \psi_n & ~=~ \exists x_1\, \cdots \exists x_n\, \bigwedge_{1 \leq i < j \leq n} x_i \neq x_j\quad \text{für alle}~ n > 0.
  \end{align*}
  Die Sätze $\psi_n$ besagen also: "`Das Modell hat die Größe $\geq n$"';
  genauer: jede Formel $\psi_n$ 
  ist genau in denjenigen Strukturen erfüllt,
  deren Universum mindestens $n$ Elemente hat.

  Um zu zeigen, dass $\varphi$ ein unendliches Modell hat,
  genügt es demnach zu zeigen, dass $\Gamma$ erfüllbar ist
  (denn wegen der $\psi_n$ müssen die Modelle von $\Gamma$ dann
  mehr Elemente haben als jede natürliche Zahl $n$).
  Wegen Kompaktheit (Thm.~3.10) genügt es,
  die Erfüllbarkeit jeder endlichen Teilmenge $\Gamma_{\textsf{f}} \subseteq \Gamma$
  zu zeigen.
  Betrachte ein solches $\Gamma_{\textsf{f}}$.
  Dann kommen darin auch nur endlich viele der $\psi_n$ vor.
  Sei $n$ die größte Zahl mit $\psi_n \in \Gamma_{\textsf{f}}$.
  Nach Annahme gibt es ein Modell $\Amf$ von $\varphi$
  mit $|A| \geq n$.
  Offensichtlich ist $\Amf$ auch ein Modell von $\Gamma_{\textsf{f}}$.
  \qedhere
\end{beweis}%

% ===================================================================
\section*{(fakultativ)~ Beweis Satz von Löwenheim-Skolem, aufsteigend}

\textsfbf{Theorem 3.13.}~
% \par\noindent
Wenn ein FO-Satz $\vp$ ein unendliches Modell besitzt,
dann gibt es f\"ur jede Menge $U$ ein Modell $\mathfrak{A}$ von $\vp$ mit $|A| \geq |U|$.

\enlargethispage*{10mm}
\par\medskip\noindent
\textsfbf{Anmerkung.}~
Die Menge $U$ wird in der Formulierung des Satzes nur benötigt,
um auszudrücken, dass es "`beliebig große unendliche Modelle gibt"'.
Genauer heißt das: für jede Kardinalität $\kappa$ gibt es ein Modell,
das mindestens $\kappa$ viele Elemente hat.
Da nach dem Satz von Cantor (Diagonalisierung!) 
die Potenzmenge jeder Menge $M$ mächtiger ist als $M$ selbst,
gibt es unendlich viele Kardinalitäten (unendlicher) Mengen.
Diese werden alle durch die beliebige Menge $U$ repräsentiert.
%
\begin{beweis}
  Habe $\varphi$ ein unendliches Modell $\Amf$ und sei $U$ eine Menge.
  Sei $\{c_u \mid u \in U\}$ eine Menge von paarweise verschiedenen Konstanten,
  die nicht in $\varphi$ vorkommen.
  Setze
  \[
    \tag{$*$}
    \Gamma ~=~ \{\varphi\} \cup \{c_u \neq c_v \mid u,v \in U,\, u \neq v\}.
  \]
  Es genügt zu zeigen, dass $\Gamma$ erfüllbar ist
  (denn dann muss wegen der $c_u \neq c_v$
  ein Modell von $\Gamma$ mindestens $|U|$ Elemente haben).
  Wegen des Kompaktheitssatzes ist es ausreichend,
  die Erfüllbarkeit jeder endlichen Teilmenge $\Gamma_{\textsf{f}} \subseteq \Gamma$
  zu zeigen.
  Betrachte ein solches $\Gamma_{\textsf{f}}$.
  Sei
  \[
    C = \{c_u \mid u \in U \text{~und $c_u$ kommt in $\Gamma_{\textsf{f}}$ vor}\}.
  \]
  Da $C$ endlich ist, aber das obige Modell $\Amf$ von $\varphi$ ein unendliches
  Universum $A$ hat,
  gibt es eine injektive Abbildung
  $
    \delta : C \to A.
  $
  Sei nun $\widehat\Amf$ die Struktur, die man aus $\Amf$ erhält, indem man zusätzlich setzt:
  \[
    c_u^{\widehat\Amf} = \delta(c_u)\quad \text{~für alle~} c_u \in C
  \]
  Offensichtlich gilt $\widehat\Amf \models \Gamma_{\textsf{f}}$.
  \qedhere
\end{beweis}%
\goodbreak

% ===================================================================
\section*{(fakultativ)~ Beweis Satz von Löwenheim-Skolem, absteigend}

\textsfbf{Theorem 3.14.}~
% \par\noindent
Wenn ein FO-Satz $\varphi$ ein Modell besitzt,
dann hat $\varphi$ auch ein endliches oder abz\"ahlbar unendliches Modell.
%
\begin{beweis}
  Hier können wir den (in der Vorlesung nur skizzierten)
  Vollständigkeitsbeweis des SK verwenden:

  Sei $\varphi$ erfüllbar.
  Dann ist die Sequenz $\{\varphi\} \Rightarrow \emptyset$
  \emph{nicht} gültig.
  Wegen der Korrektheit des (nicht erweiterten) SK ist diese Sequenz
  auch nicht ableitbar.
  Im Vollständigkeitsbeweis des SK wird für jede nicht ableitbare Sequenz
  $\Gamma \Rightarrow \Delta$
  ein endliches oder abzählbar unendliches Modell für $\Gamma \cup \lnot \Delta$,
  also für
  \[
    \bigwedge \Gamma \land \bigwedge_{\varphi \in \Delta} \lnot \varphi
  \]
  konstruiert, in diesem Fall also für $\varphi$.
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T3.8~ Nicht-Ausdrückbarkeit Zusammenhang via Kompaktheit}

\textsfbf{Theorem 3.16.}~
% \par\noindent
Zusammenhang von ungerichteten Graphen ist \emph{nicht} FO-ausdrückbar.
%
\begin{beweis}
  Sei $\tau = \{E\}$.
  Angenommen, es gebe einen Satz $\varphi \in \textsf{FO}(\tau)$,
  der Zusammenhang ausdrückt.
  Seien $c_1,c_2$ Konstantensymbole. Für $n \geq 0$ definieren wir
  Formeln $\psi_n$, die ausdrücken sollen, dass es \emph{keinen} Pfad der Länge $n$
  zwischen $c_1$ und $c_2$ gibt, d.\,h.:
  %
  \begin{align*}
    \psi_n & = \lnot \Bigg(
                 \exists x_0\,\dots \exists x_n\,\Big(
                   c_1 = x_0 ~\land~ c_2 = x_n ~\land \bigwedge_{0 \leq i < n} \!\!E(x_i,x_{i+1})
                 \Big)
               \Bigg)
    \intertext{Wir setzen}
    \Gamma & = \{\varphi\} ~\cup~ 
               \big\{\forall x\,\forall y\,\big(E(x,y) \to E(y,x)\big)\big\} ~\cup~
               \{\psi_n \mid n \geq 0\}.
  \end{align*}
  %
  \begin{description}
    \item[Behauptung.]
      $\Gamma$ ist erfüllbar.
    \item[Beweis der Behauptung.]
      Wegen des Kompaktheitssatzes ist es ausreichend,
      die Erfüllbarkeit jeder \emph{endlichen} Teilmenge
      $\Gamma_{\!\!\:\textsf{f}} \subseteq \Gamma$ zu zeigen.
      Für ein beliebiges solches $\Gamma_{\!\!\:\textsf{f}}$
      sei $m$ maximal mit $\psi_m \in \Gamma_{\!\!\:\textsf{f}}$\,.
      Dann ist die folgende Struktur mit einem Pfad der Länge $m+1$
      zwischen $c_1$ und $c_2$ ein Modell von $\Gamma_{\!\!\:\textsf{f}}$\,:
      %
      \par\medskip
      \begin{center}
        \begin{tikzpicture}[%
          node distance=12mm,>=Latex,
          every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=4mm},
          every edge/.style={draw=black,thin}
        ]
          \node[state] (c1)               {};
          \node[state] (a1) [right=of c1] {};
          \node[state] (a2) [right=of a1] {};
          \node[state] (a3) [right=of a2] {};
          \node[state] (am) [right=16mm of a3] {};
          \node[state] (c2) [right=of am] {};
          \path[<->] (c1) edge node[above] {$E$} (a1)
                     (a1) edge node[above] {$E$} (a2)
                     (a2) edge node[above] {$E$} (a3)
                     (am) edge node[above] {$E$} (c2);

          \node [above=0mm of c1]  {$c_1$};
          \node [above=0mm of c2]  {$c_2$};
          \node [right=5mm of a3] {{\boldmath$\cdots$}};
        \end{tikzpicture}%
      \end{center}
  \end{description}
  %
  \par\medskip
  Da nun $\Gamma$ ein Modell $\Amf$ hat, muss insbesondere $\Amf \models \varphi$ gelten;
  somit ist der Graph $(A, E^\Amf)$ zusammenhängend.
  Da außerdem $\Amf \models \psi_n$ für alle $n \geq 0$,
  gibt es jedoch keinen Pfad von $c_1^\Amf \in A$ zu $c_2^\Amf \in A$;
  ein Widerspruch.
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T3.9~ Keine Kompaktheit auf endlichen Strukturen}

Der Kompaktheitssatz für endliche Strukturen würde lauten (Variante für Erfüllbarkeit):
\begin{quote}
  Eine Menge $\Gamma$ von FO-Sätzen ist \emph{endlich} erfüllbar
  gdw.\ jede endliche Teilmenge von $\Gamma$ \emph{endlich} erfüllbar ist.
\end{quote}
Dabei bedeutet "`endlich erfüllbar"',
dass die jeweilige Menge ein \emph{endliches} Modell $\Amf$ hat.

Diese Aussage lässt sich jedoch wie folgt widerlegen.
Betrachte dazu:
%
\begin{align*}
  \psi_n & = \exists x_1,\ \dots \exists x_n\,\bigwedge_{i \neq j} x_i \neq x_j \\
  \Gamma & = \{\psi_n \mid n \geq 0\}
\end{align*}
%
Jede endliche Teilmenge $\Gamma_{\!\!\:\textsf{f}} \subseteq \Gamma$
ist endlich erfüllbar:
wähle dazu eine beliebige Struktur $\Amf$ mit
\[
  |A| = \textsf{max}\{n \mid \psi_n \in \Gamma_{\!\!\:\textsf{f}}\}.
\]
Offensichtlich ist aber $\Gamma$ nicht endlich erfüllbar.

% ===================================================================
\section*{T3.10~ Beispiel eines Ehrenfeucht-Fraïssé-Spiels}

Betrachte die Signatur $\tau = \{E\}$ für ein binäres Relationssymbol $E$,
also die Signatur von (gerichteten) Graphen.
Das Spielbrett bestehe aus folgenden Strukturen.
\par
\begin{center}
  \parbox{.35\textwidth}{%
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (a1)                     {$a_1$};
      \node[state] (a2) [below right=of a1] {$a_2$};
      \node[state] (a3) [below left =of a2] {$a_3$};
      \node[state] (a4) [above left =of a3] {$a_4$};

      \path[->] (a1) edge node[above right] {$E$} (a2)
                (a2) edge node[below right] {$E$} (a3)
                (a3) edge node[below left]  {$E$} (a4)
                (a4) edge node[above left]  {$E$} (a1);

      \node [above left=1mm and 3mm of a1]  {$\Amf$};
    \end{tikzpicture}%
  }
  \parbox{.55\textwidth}{%
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (b1)               {$b_1$};
      \node[state] (b2) [right=of b1] {$b_2$};
      \node[state] (b3) [right=of b2] {$b_3$};
      \node[state] (b4) [right=of b3] {$b_4$};

      \path[->] (b1) edge node[above] {$E$} (b2)
                (b2) edge node[above] {$E$} (b3)
                (b3) edge node[above] {$E$} (b4);

      \node [above left=1mm and 3mm of b1]  {$\Bmf$};
    \end{tikzpicture}%
  }
\end{center}
\par\smallskip
Ein möglicher Spielverlauf ist:
\begin{center}
  \begin{tabular}{ccc}
    \hline\rule{0pt}{11pt}%
    Runde & \emph{Spoiler} & \emph{Duplicator} \\[1pt]
    \hline\rule{0pt}{11pt}%
    1     & $a_1$          & $b_2$             \\
    2     & $b_1$          & $a_4$             \\
    3     & $a_3$          & $b_3$             \\[1pt]
    \hline
  \end{tabular}
\end{center}

\goodbreak
% ===================================================================
\section*{T3.11~ Beispiele für partielle Isomorphismen}

Betrachte die Strukturen $\Amf,\Bmf$ aus dem vorangehenden Beispiel.
Dann ist
%
\par\smallskip
\begin{itemize}
  \item
    $\delta_1 : \begin{cases}
                  a_1 \mapsto b_1 \\
                  a_3 \mapsto b_3
                \end{cases}$
    \quad ein partieller Isomorphismus von $\Amf|_{\{a_1,a_3\}}$ nach $\Bmf|_{\{b_1,b_3\}}$:
    \par\smallskip

    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state]            (a1)                     {$a_1$};
      \node[state,opacity=.3] (a2) [below right=of a1] {$a_2$};
      \node[state]            (a3) [below left =of a2] {$a_3$};
      \node[opacity=.3,state] (a4) [above left =of a3] {$a_4$};

      \node[state]            (b1) [right=25mm of a2]  {$b_1$};
      \node[opacity=.3,state] (b2) [right=of b1]       {$b_2$};
      \node[state]            (b3) [right=of b2]       {$b_3$};
      \node[opacity=.3,state] (b4) [right=of b3]       {$b_4$};

      \node [above left=-3mm and 6mm of a1]  {$\Amf|_{\{a_1,a_3\}}$};
      \node [above left=1mm and 3mm of b1]  {$\Bmf|_{\{b_1,b_3\}}$};
      
      \path[opacity=.4,->] 
        (a1) edge node[above right] {$E$} (a2)
        (a2) edge node[below right] {$E$} (a3)
        (a3) edge node[below left]  {$E$} (a4)
        (a4) edge node[above left]  {$E$} (a1)
        (b1) edge node[above] {$E$} (b2)
        (b2) edge node[above] {$E$} (b3)
        (b3) edge node[above] {$E$} (b4);
        
      \path[->]
        (a1) edge[out=20,in=40] (b1)
        (a3) edge[out=0,in=200] (b3);
    \end{tikzpicture}%
    \par\smallskip
  \item
    $\delta_2 : \begin{cases}
                  a_1 \mapsto b_2 \\
                  a_2 \mapsto b_3
                \end{cases}$
    \quad ein partieller Isomorphismus
    \par\smallskip
  \item
    $\delta_3 : \begin{cases}
                  a_1 \mapsto b_2 \\
                  a_3 \mapsto b_3
                \end{cases}$
    \quad \emph{kein} partieller Isomorphismus
    \par\smallskip
  \item
    $\delta_4 : \begin{cases}
                  a_1 \mapsto b_1 \\
                  a_3 \mapsto b_1
                \end{cases}$
    \quad \emph{kein} partieller Isomorphismus
\end{itemize}

% ===================================================================
\section*{T3.12~ Beispiele für Gewinnstrategien in EF-Spielen}

Wir verwenden weiterhin die Signatur $\tau = \{E\}$ für ein binäres Relationssymbol $E$,
also die Signatur von (gerichteten) Graphen.

\par\medskip
\textsfbf{Beispiel 1.}~
Betrachte die folgenden Strukturen.
\par
\begin{center}
  \parbox{.45\textwidth}{%
    \begin{tikzpicture}[%
      node distance=15mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (a1)               {$a_1$};
      \node[state] (a2) [right=of a1] {$a_2$};

      \path[->] (a1) edge             node[below] {$E$} (a2)
                (a1) edge [loop left] node[left]  {$E$} ();

      \node [above right=2mm and 5mm of a1]  {$\Amf$};
    \end{tikzpicture}%
  }
  \parbox{.45\textwidth}{%
    \begin{tikzpicture}[%
      node distance=15mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (b1)               {$b_1$};
      \node[state] (b2) [right=of b1] {$b_2$};

      \path[->] (b1) edge              node[below] {$E$} (b2)
                (b2) edge [loop right] node[right] {$E$} ();

      \node [above right=2mm and 5mm of b1]  {$\Bmf$};
    \end{tikzpicture}%
  }
\end{center}
\par\smallskip
Dann können wir beobachten:
%
\begin{itemize}
  \item
    \emph{Duplicator} gewinnt $\Gmc_0(\Amf,\Bmf)$.
    (Die "`leere"' Abbildung ist auch ein partieller Isomorphismus,
    denn sie kann die Eigenschaften eines Isomorphismus nicht verletzen.)
  \item
    \emph{Duplicator} hat eine Gewinnstrategie für $\Gmc_1(\Amf,\Bmf)$,
    die sich wie folgt als Spielbaum darstellen lässt:
    \par
    \begin{center}
      \begin{tikzpicture}[%
        >=Latex,
    %     parent anchor=east, child anchor=west, grow=east,
    %     sibling distance=15mm, level distance=15mm,
        every node/.style = {draw=none, fill=none, inner sep=1mm, minimum size=1mm},
        level 1/.style = {sibling distance = 20mm, level distance=10mm},
%         level 2/.style = {sibling distance = 37mm, level distance=20mm},
%         level 3/.style = {sibling distance = 18mm, level distance=20mm},
        edge from parent/.style = {draw=black, thin, ->}%
      ]
        \node(root) {$\bullet$}
          child {
            node (a1) {$a_1$}
            child {
              node (a1b2) {$b_2$}
            }
          }
          child {
            node (a2) {$a_2$}
            child {
              node (b1a2) {$b_1$}
            }
          }
          child {
            node (b1) {$b_1$}
            child {
              node (b1a2) {$a_2$}
            }
          }
          child {
            node (b2) {$b_2$}
            child {
              node (b2a1) {$a_1$}
            }
          };

        \begin{scope}[every node/.style = {draw=none, fill=none}]
          \node[right=3mm of b2]    {Mögliche Züge \emph{Spoiler}};
          \node[right=3mm of b2a1]  {Antwort \emph{Duplicator}};
        \end{scope}
      \end{tikzpicture}%
    \end{center}
    \par
    Dabei definiert jeder Pfad einen partiellen Isomorphismus,
    z.\,B. $\{a_1 \mapsto b_2\}$.
  \item
    \emph{Spoiler} hat eine Gewinnstrategie für $\Gmc_2(\Amf,\Bmf)$,
    die sich wie folgt als Spielbaum darstellen lässt:
    \par
    \begin{center}
      \begin{tikzpicture}[%
        >=Latex,
    %     parent anchor=east, child anchor=west, grow=east,
    %     sibling distance=15mm, level distance=15mm,
        every node/.style = {draw=none, fill=none, inner sep=1mm, minimum size=1mm},
        level 1/.style = {sibling distance = 20mm, level distance=10mm},
        level 2/.style = {sibling distance = 20mm, level distance=10mm},
        level 3/.style = {sibling distance = 10mm, level distance=10mm},
        level 4/.style = {sibling distance = 10mm, level distance=10mm},
        edge from parent/.style = {draw=black, thin, ->}%
      ]
        \node(root) {$\bullet$}
          child {
            node (a1) {$a_1$}
            child {
              node (a1b1) {$b_1$}
              child {
                node (a1b1a1) {$a_1$}
                child {
                  node (a1b1a1b1) {$b_1$}
                }
                child {
                  node (a1b1a1b2) {$b_2$}
                }
              }
            }
            child {
              node (a1b2) {$b_2$}
              child {
                node (a1b2a2) {$a_2$}
                child {
                  node (a1b2a2b1) {$b_1$}
                }
                child {
                  node (a1b2a2b2) {$b_2$}
                }
              }
            }
          };

        \begin{scope}[every node/.style = {draw=none, fill=none}]
          \node[right=18mm of a1]       {Zug \emph{Spoiler}};
          \node[right=8mm of a1b2]     {Mögliche Antworten \emph{Duplicator}};
          \node[right=8mm of a1b2a2]   {Zug \emph{Spoiler}};
          \node[right=3mm of a1b2a2b2] {Mögliche Antworten \emph{Duplicator}};
        \end{scope}
      \end{tikzpicture}%
    \end{center}
    \par
    Dabei definiert \emph{kein} Pfad einen partiellen Isomorphismus,
    z.\,B. $\{a_1 \mapsto b_2,~ a_2 \mapsto b_2\}$.
\end{itemize}

\par\medskip
\textsfbf{Beispiel 2.}~
Betrachte die Strukturen aus den vergangenen beiden Beispielen:
\par
\begin{center}
  \parbox{.35\textwidth}{%
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (a1)                     {$a_1$};
      \node[state] (a2) [below right=of a1] {$a_2$};
      \node[state] (a3) [below left =of a2] {$a_3$};
      \node[state] (a4) [above left =of a3] {$a_4$};

      \path[->] (a1) edge node[above right] {$E$} (a2)
                (a2) edge node[below right] {$E$} (a3)
                (a3) edge node[below left]  {$E$} (a4)
                (a4) edge node[above left]  {$E$} (a1);

      \node [above left=1mm and 3mm of a1]  {$\Amf$};
    \end{tikzpicture}%
  }
  \parbox{.55\textwidth}{%
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (b1)               {$b_1$};
      \node[state] (b2) [right=of b1] {$b_2$};
      \node[state] (b3) [right=of b2] {$b_3$};
      \node[state] (b4) [right=of b3] {$b_4$};

      \path[->] (b1) edge node[above] {$E$} (b2)
                (b2) edge node[above] {$E$} (b3)
                (b3) edge node[above] {$E$} (b4);

      \node [above left=1mm and 3mm of b1]  {$\Bmf$};
    \end{tikzpicture}%
  }
\end{center}
\par\smallskip
Dann können wir beobachten:
%
\begin{itemize}
  \item
    \emph{Duplicator} hat eine Gewinnstrategie für $\Gmc_0(\Amf,\Bmf)$ und $\Gmc_1(\Amf,\Bmf)$
    (baue sie selbst).
  \item
    \emph{Spoiler} hat eine Gewinnstrategie für $\Gmc_2(\Amf,\Bmf)$,
    die sich wie folgt als Spielbaum darstellen lässt:
    \par
    \begin{center}
      \begin{tikzpicture}[%
        >=Latex,
    %     parent anchor=east, child anchor=west, grow=east,
    %     sibling distance=15mm, level distance=15mm,
        every node/.style = {draw=none, fill=none, inner sep=1mm, minimum size=1mm},
        level 1/.style = {sibling distance = 20mm, level distance=10mm},
        level 2/.style = {sibling distance = 20mm, level distance=10mm},
        level 3/.style = {sibling distance =  5mm, level distance=10mm},
        level 4/.style = {sibling distance =  4mm, level distance= 8mm},
        edge from parent/.style = {draw=black, thin, ->}%
      ]
        \node(root) {$\bullet$}
          child {
            node (b1) {$b_1$}
            child {
              node (b1a1) {$a_1$}
              child {
                node (b1a1a4) {$a_4$}
                child {
                  node (b1a1a4c1) {$\cdot$}
                }
                child {
                  node (b1a1a4c2) {$\cdot$}
                }
                child {
                  node (b1a1a4c3) {$\cdot$}
                }
                child {
                  node (b1a1a4c4) {$\cdot$}
                }
              }
            }
            child {
              node (b1a2) {$a_2$}
              child {
                node (b1a2a1) {$a_1$}
                child {
                  node (b1a2a1c1) {$\cdot$}
                }
                child {
                  node (b1a2a1c2) {$\cdot$}
                }
                child {
                  node (b1a2a1c3) {$\cdot$}
                }
                child {
                  node (b1a2a1c4) {$\cdot$}
                }
              }
            }
            child {
              node (b1a3) {$a_3$}
              child {
                node (b1a3a2) {$a_2$}
                child {
                  node (b1a3a2c1) {$\cdot$}
                }
                child {
                  node (b1a3a2c2) {$\cdot$}
                }
                child {
                  node (b1a3a2c3) {$\cdot$}
                }
                child {
                  node (b1a3a2c4) {$\cdot$}
                }
              }
            }
            child {
              node (b1a4) {$a_4$}
              child {
                node (b1a4a3) {$a_3$}
                child {
                  node (b1a4a3c1) {$\cdot$}
                }
                child {
                  node (b1a4a3c2) {$\cdot$}
                }
                child {
                  node (b1a4a3c3) {$\cdot$}
                }
                child {
                  node (b1a4a3c4) {$\cdot$}
                }
              }
            }
          };

        \begin{scope}[every node/.style = {draw=none, fill=none}]
          \node[right=38mm of b1]      {Zug \emph{Spoiler}};
          \node[right=8mm of b1a4]     {Mögliche Antworten \emph{Duplicator}};
          \node[right=8mm of b1a4a3]   {Zug \emph{Spoiler}};
          \node[right=3mm of b1a4a3c4] {Mögliche Antworten \emph{Duplicator}};
        \end{scope}
      \end{tikzpicture}%
    \end{center}
    \par
    Wieder definiert \emph{kein} Pfad einen partiellen Isomorphismus.
\end{itemize}

%\pagebreak
% ===================================================================
\section*{T3.13~ Beispiele für das EF-Theorem}

Betrachte wieder die Strukturen aus dem letzten Beispiel:
\par
\begin{center}
  \parbox{.35\textwidth}{%
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (a1)                     {$a_1$};
      \node[state] (a2) [below right=of a1] {$a_2$};
      \node[state] (a3) [below left =of a2] {$a_3$};
      \node[state] (a4) [above left =of a3] {$a_4$};

      \path[->] (a1) edge node[above right] {$E$} (a2)
                (a2) edge node[below right] {$E$} (a3)
                (a3) edge node[below left]  {$E$} (a4)
                (a4) edge node[above left]  {$E$} (a1);

      \node [above left=1mm and 3mm of a1]  {$\Amf$};
    \end{tikzpicture}%
  }
  \parbox{.55\textwidth}{%
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      every edge/.style={draw=black,thin}
    ]
      \node[state] (b1)               {$b_1$};
      \node[state] (b2) [right=of b1] {$b_2$};
      \node[state] (b3) [right=of b2] {$b_3$};
      \node[state] (b4) [right=of b3] {$b_4$};

      \path[->] (b1) edge node[above] {$E$} (b2)
                (b2) edge node[above] {$E$} (b3)
                (b3) edge node[above] {$E$} (b4);

      \node [above left=1mm and 3mm of b1]  {$\Bmf$};
    \end{tikzpicture}%
  }
\end{center}
\par\smallskip
\begin{itemize}
  \item
    Da \emph{Duplicator} eine Gewinnstrategie für $\Gmc_1(\Amf,\Bmf)$ hat,
    gilt wegen des EF-Theorems \emph{für alle} FO-Sätze $\varphi$ mit $\textsf{qr}(\varphi) = 1$:
    \[
      \Amf \models \varphi
      \quad\text{gdw.}\quad
      \Bmf \models \varphi,
    \]
    also z.\,B.\ für die Sätze
    \[
      \exists x\, E(x,x),\quad
      \forall x\, (x=x),\quad
      \dots
    \]
  \item
    Da \emph{Spoiler} eine Gewinnstrategie für $\Gmc_2(\Amf,\Bmf)$ hat,
    \emph{gibt es} wegen des EF-Theorems einen FO-Satz $\varphi$ mit $\textsf{qr}(\varphi) = 2$,
    durch den sich $\Amf$ und $\Bmf$ \emph{unterscheiden} lassen, z.\,B.:
    \[
      \varphi = \exists x\,\forall y\, \lnot E(y,x)
    \]
\end{itemize}

\goodbreak
% ===================================================================
\section*{T3.14~ Beweis des Methodologie-Theorems}

\textsfbf{Theorem~3.20.}~ %(Kompaktheitssatz).}~
% \par\noindent
Sei $P$ eine Eigenschaft. Wenn es f\"ur jedes $k \geq 0$ Strukturen $\Amf_k$, $\Bmf_k$
gibt, so dass
%
\begin{enumerate}
  \item
    $\Amf_k \in P$ ~und~ $\Bmf_k \notin P$\qquad und
  \item \emph{Duplicator} hat eine Gewinnstrategie f\"ur $\Gmc_k(\Amf_k,\Bmf_k)$,
\end{enumerate}
%
dann ist $P$ nicht FO-ausdr\"uckbar.
%
\begin{beweis}
  Wir beweisen das Kontrapositiv.
  Sei also $P$ FO-ausdrückbar mittels eines Satzes $\varphi$.
  Wir müssen zeigen: es \emph{gibt ein} $k \geq 0$, so dass für \emph{alle} Strukturen $\Amf,\Bmf$ gilt:
  Punkt~1 und~2 aus dem Methodologietheorem sind nicht beide erfüllt.

  Wähle dafür $k = \textsf{qr}(\varphi)$.
  Seien $\Amf,\Bmf$ beliebige Strukturen.
  Wenn Punkt~1 für $\Amf$ und $\Bmf$ \emph{nicht} erfüllt ist, dann folgt die Behauptung.
  Wenn jedoch Punkt~1 erfüllt ist, dann gilt
  $\Amf \in P$ und $\Bmf \notin P$.
  Das Ehrenfeucht-Fraïssé-Theorem (Thm.~3.19)
  liefert dann, dass \emph{Duplicator} \emph{keine} Gewinnstrategie 
  für $\Gmc_k(\Amf,\Bmf)$ hat -- also ist Punkt~2 nicht erfüllt.
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T3.15~ Beweis der Nicht-Ausdrückbarkeit von EVEN und ODD}

\textsfbf{Theorem~3.21.}~
% \par\noindent
\textsf{EVEN} und \textsf{ODD} sind nicht FO-ausdr\"uckbar --
weder in der Klasse aller Strukturen noch in der Klasse der endlichen Strukturen
(jeweils \"uber einer beliebigen Signatur $\tau$).
%
%
\begin{beweis}
  Wir zeigen die Behauptung für \textsf{EVEN} mittels des Methodologietheorems (Thm~3.20).
  Für \textsf{ODD} ist die Argumentation analog.

  Sei $k \geq 0$ beliebig.
  Wähle Strukturen $\Amf_k$ und $\Bmf_k$ wie folgt:
  %
  \begin{itemize}
    \item
      $\Amf_k$ hat $2k$ Elemente und $R^{\Amf_k} = \emptyset$ für alle $R \in \tau$.
    \item
      $\Bmf_k$ hat $2k+1$ Elemente und $R^{\Bmf_k} = \emptyset$ für alle $R \in \tau$.
  \end{itemize}
  %
  Siehe Abbildung~\ref{fig:EVEN}.
  %
  \begin{figure}[ht]
     \centering
     \begin{tikzpicture}[%
       draw=black,thin%
     ]
       \coordinate (M1) at (0,0);
       \coordinate (M2) at (5,0);
 
       \draw (M1) ellipse [x radius=.9, y radius=1];
       \draw (M2) ellipse [x radius=.9, y radius=1];

       \coordinate (P1) at (-.3,.5);
       \coordinate (P2) at ( .2,.5);
       \coordinate (P3) at (-.1,.1);
       \coordinate (P4) at ( .4,.1);
       \coordinate (P5) at (-.3,-.3);
       \coordinate (P6) at ( .2,-.3);

       \coordinate (P7) at ($ (M2) + (-.1,-.7) $);
       
       \coordinate (Alab) at ($ (M1) + (320:1.4) $);
       \coordinate (Blab) at ($ (M2) + (320:1.4) $);
       
       \foreach \point in {P1,P2,P3,P4,P5,P6}
       \draw[fill=black]
       let
         \p1 = ($ (M1) + (\point) $),
         \p2 = ($ (M2) + (\point) $)
       in
         (\p1) circle [radius=.5mm]
         (\p2) circle [radius=.5mm];
         
       \draw[fill=black] (P7) circle [radius=.5mm];
       
       \node [at=(Alab)] () {$\Amf_3$};
       \node [at=(Blab)] () {$\Bmf_3$};
     \end{tikzpicture}
     \caption{Strukturen $\Amf_k$ und $\Bmf_k$ für $k=3$}
     \label{fig:EVEN}
  \end{figure}

  Offenbar ist Punkt~1 des Methodologietheorems (Thm~3.20) erfüllt,
  denn $\Amf_k \in \textsf{EVEN}$ und $\Bmf_k \notin \textsf{EVEN}$.

  Für Punkt~2 ist zu zeigen, dass \emph{Duplicator} eine Gewinnstrategie
  für $\Gmc_k(\Amf_k,\Bmf_k)$ hat.
  Diese ist wie folgt:
  %
  \begin{itemize}
    \item
      Nach dem ersten Zug von \emph{Spoiler} in einer der beiden Strukturen
      wählt \emph{Duplicator} ein beliebiges Element aus der jeweils anderen Struktur.
    \item
      In jeder weiteren Runde verfährt \emph{Duplicator} so:
      Wählt \emph{Spoiler} ein in einer früheren Runde gespieltes Element,
      dann antwortet \emph{Duplicator} mit dem in derselben Runde gespielten
      Element in der anderen Struktur.
      Wählt jedoch \emph{Spoiler} ein noch nicht gespieltes Element einer Struktur,
      dann antwortet \emph{Duplicator} wieder mit einem beliebigen Element
      der anderen Struktur.
      Da $|A| \geq k$ und $|B| \geq k$, ist das stets möglich.
  \end{itemize}
  %
  Offensichtlich entsteht auf diese Weise ein partieller Isomorphismus.
  \qedhere
\end{beweis}%

%\pagebreak
% ===================================================================
\section*{T3.16~ Skizze der Gewinnstrategie für Zusammenhang}

Sei $k \geq 0$.
Wir w\"ahlen ungerichtete Graphen $\Amf_k,\Bmf_k$ wie folgt:
%
\begin{itemize}
  \item
    $\Amf_k$ ist ein Kreis $K_1$ der L\"ange $2^k$ (also zusammenh\"angend).
  \item
    $\Bmf_k$ besteht aus zwei disjunkten Kreisen $K_2,K_3$ der L\"ange $2^k$
    (also nicht zusammenh\"angend).
\end{itemize}
%
Siehe Abbildung~\ref{fig:ZH}.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[%
    draw=black,thin,>=Latex,
    every edge/.style={draw=black,thin}%
  ]
    \foreach \i in {0,1,2,3,4,5,6,7}{
%      \ang = 45*\i;
      \coordinate (C\i) at ($ (45*\i+22.5:13mm) $);
      \coordinate (D\i) at ($ (C\i) + (55mm,0) $);
      \coordinate (E\i) at ($ (D\i) + (28mm,0) $);
      \node[circle, minimum size=1mm, inner sep=0mm, fill=black, at=(C\i)] (P\i) {};
      \node[circle, minimum size=1mm, inner sep=0mm, fill=black, at=(D\i)] (Q\i) {};
      \node[circle, minimum size=1mm, inner sep=0mm, fill=black, at=(E\i)] (R\i) {};
    }

    \foreach \from/\to in {0/1,1/2,2/3,3/4,4/5,5/6,6/7,7/0}
    \foreach \X in {P,Q,R}
    \draw[<->] (\X\from)--(\X\to);
    
    \node[rounded corners, fill=none, draw=black, thin, minimum height=30mm, minimum width=32mm, at=($ (P0)!.5!(P4) $)] (Amf) {};

    \node[rounded corners, fill=none, draw=black, thin, minimum height=30mm, minimum width=60mm, at=($ (Q0)!.5!(R4) $)] (Bmf) {};

    \node [below right=-5mm and  2mm of Amf] () {$\Amf_3$};
    \node [below right=-5mm and  2mm of Bmf] () {$\Bmf_3$};
    
    \node [below right=3mm and -5mm of P7] () {$K_1$};
    \node [below right=3mm and -5mm of Q7] () {$K_2$};
    \node [below right=3mm and -5mm of R7] () {$K_3$};
  
  \end{tikzpicture}
  \caption{Strukturen $\Amf_k$ und $\Bmf_k$ für $k=3$. Alle Kanten sind mit $E$ beschriftet.}
  \label{fig:ZH}
\end{figure}

\textsfbf{Behauptung:}~
% Wir m\"ussen zeigen:~ 
\emph{Duplicator} hat Gewinnstrategie f\"ur $\Gmc_k(\Amf_k,\Bmf_k)$.

\textsfbf{Beste Spielweise von \emph{Spoiler} und \emph{Duplicator}:}~
%
\begin{itemize}
  \item
    In den ersten beiden Runden wählt \emph{Spoiler}
    ein Element in $K_2$ und eins in $K_3$.
  \item
    \emph{Duplicator} muss in diesen Runden dann jeweils ein Element in $K_1$ wählen.
    Diese sind verbunden, im Gegensatz zu den von Spoiler gewählten Elementen;
    darum kann \emph{Spoiler} im Prinzip gewinnen.
    \emph{Duplicator} kann jedoch den Sieg von \emph{Spoiler} so weit hinauszuzögern,
    dass dieser nicht in den ersten $k$ Runden eintritt.
    Dazu wählt sie zwei \emph{gegenüberliegende} Elemente in $K_1$,
    denn die beiden Pfade zwischen zwei solchen Elementen haben die Länge $2^{k-1}$,
    wohingegen es zwischen zwei nicht gegenüberliegenden Elementen immer einen kürzeren Pfad gibt.
  \item
    Die beste Strategie für \emph{Spoiler} besteht nun in "`binärer Suche"':
    Wähle ein Element genau in der Mitte zwischen den von \emph{Duplicator} gewählten,
    was die Strecke genau halbiert.
    Auch in den folgenden Runden muss \emph{Spoiler} die Strecke zwischen zwei
    am wenigsten voneinander entfernten gewählten Elementen halbieren.
  \item
    Auf jeden dieser Züge von \emph{Spoiler} antwortet \emph{Duplicator}
    mit einem Element in $K_2$ oder $K_3$,
    wobei sie dieselben Abstände einhält wie \emph{Spoiler}.
    Dies kann sie $k$ Runden lang durchhalten.
\end{itemize}
%
Dies ist noch kein Beweis für die obige Behauptung,
denn die beschriebene Strategie von \emph{Duplicator}
basiert auf der Annahme, dass \emph{Spoiler} optimal spielt.
Sie muss aber auch funktionieren, wenn 
\emph{Spoiler} nicht optimal spielt.
Deshalb ist es wesentlich komplizierter, die Gewinnstrategie für \emph{Duplicator} zu beschreiben;
siehe den folgenden Beweis von Lemma 3.22.

Man beachte auch, dass man hier nicht einfach einen Spielbaum zeichnen kann,
denn dessen Verzweigungsgrad ist durch die Anzahl der Elemente in den Strukturen bestimmt,
welche wiederum von $k$ abhängt, und dessen Wert ist beliebig.

%\pagebreak
% ===================================================================
\section*{(fakultativ)~ Gewinnstrategie für Zusammenhang}

\textsfbf{Lemma~3.22.}~
% \par\noindent
\emph{Duplicator} kann $\Gmc_k(\Amf_k,\Bmf_k)$ so spielen, dass nach $i$ Runden ein Spielstand
$\{ (a_1,b_1),\dots,(a_i,b_i) \}$ erreicht ist, so dass f\"ur $1 \leq j < \ell \leq i$\,:
%
\[
  \tag{$*$}
  \quad d(a_j,a_\ell) ~=~ d(b_j,b_\ell)
  \quad\text{oder}\quad
  d(a_j,a_\ell),~d(b_j,b_\ell) ~>~ 2^{k-i}
\]
%
\textsfbf{Anmerkung.}~
Intuitiv gesprochen sagt die Bedingung $(*)$,
dass zwei Elemente in einer Struktur (z.\,B.\ $a_i,a_\ell$)
denselben Abstand haben wie die zugehörigen Elemente in der anderen Struktur ($b_i,b_\ell$)
\emph{oder} dass beide Abstände einen gewissen Schwellwert überschreiten ($2^{k-i}$).
Dieser Schwellwert wird kleiner, je mehr Runden bereits gespielt wurden:
mit wachsendem $i$ fällt der Wert $2^{k-i}$.
Dies verdeutlicht, dass die "`Unterscheidungskraft"' von \emph{Spoiler} sinkt,
je weiter das Spiel fortgeschritten ist.

Aus der Bedingung $(*)$ des Lemmas lässt sich bereits eine konkrete Strategie für \emph{Duplicator} ablesen.
Wir müssen dann nur noch zeigen, dass diese eine Gewinnstrategie ist.
Die Gewinnstrategie lässt sich so formulieren: 
%
\begin{quote}
  Wenn Spoiler $a_\ell$ wählt, dann gibt es zwei Möglichkeiten:
  \begin{itemize}
    \item
      Alle schon gewählten Elemente $a_j$ sind "`weit genug weg"' (2.\ Teil "`oder"').
      Dann kann \emph{Duplicator} $b_\ell$ so wählen, dass alle schon gewählten Elemente $b_j$ ebenfalls "`weit weg"' sind;
    \item
      Mindestens ein gewähltes Element ist "`nah"' bei $a_\ell$ (1.\ Teil "`oder"').
      Dann kann \emph{Duplicator} $b_\ell$ so wählen, dass alle "`nahen"' Elemente denselben Abstand zu $a_\ell$ haben wie ihre Bilder zu $b_\ell$\,.
  \end{itemize}
  Was "`nah"' bzw.\ "`weit"' ist, verändert sich mit der Spieldauer (Schwellwert $2^{k-1}$).
  Die konkrete Wahl von $b_\ell$ ist dann ungefähr wie bereits beschrieben.
\end{quote}
%
\begin{beweis}
  Beweis per Induktion \"uber $i$.
  %
  \begin{description}
    \item[Induktionsanfang.]~
      F\"ur $i=0$ ist ($*$) trivialerweise erf\"ullt.
      \goodbreak
    \item[Induktionsschritt.]~
      \par
      Wir nehmen an, dass Spoiler im $(i+1)$-ten Zug ein Element $a=a_{i+1} \in A$
      w\"ahlt. Die Wahl eines $b=b_{i+1} \in B$ kann symmetrisch behandelt werden.

      \par\smallskip\noindent
      Unterscheide zwei F\"alle:
      %
      \begin{enumerate}
        \item
          Es gibt $a_h \in \{a_1,\dots,a_i\}$ mit $d(a_h,a) \leq 2^{k-(i+1)}$. (($*$)-Schwelle f\"ur $i+1$)

          Betrachte die Nachbarschaften $N_{2^{k-i}}(a_h)$ und
          $N_{2^{k-i}}(b_h)$. 
          IV liefert 
          % ``Isomorphie''\footnote{informell
          %     gemeint.} von $N_{2^{k-(i+1)}}(a_h)$ und $N_{2^{k-(i+1)}}(b_h)$, insb.\
          f\"ur alle $a_j,a_\ell \in \{ a_1,\dots,a_i \}$:
          %
          \begin{enumerate}
            \item[(I)]
              $a_j \in N_{2^{k-i}}(a_h)$ gdw.  $b_j \in N_{2^{k-i}}(b_h)$
            \item[(II)]
              Wenn $a_j,a_\ell \in N_{2^{k-i}}(a_h)$, dann $d(a_j,a_\ell)=d(b_j,b_\ell)$.
              % \footnote{Insgesamt ist das Ding doppelt so gross wie die Schwelle, aber man immer ``\"uber $a_h$ gehen''.}
          \end{enumerate}
          %
          Also gibt es Bijektion von $N_{2^{k-i}}(a_h)$ auf
          $N_{2^{k-i}}(b_h)$, die jedes $a_j \in N_{2^{k-i}}(a_h)$, $j \in
          \{1,\dots,i\}$, auf das entsprechende $b_j$ abbildet. Es gilt $a \in
          N_{2^{k-i}}(a_h)$.  Sei $b$ das Bild von $a$ unter der
          Bijektion. Dann gilt f\"ur alle $a_j \in \{a_1,\dots,a_i\}$:
          %
          \begin{enumerate}
            \item[(III)]
              Wenn $a_j \in N_{2^{k-i}}(a_h)$, dann $d(a_j,a)=d(b_j,b)$.
          \end{enumerate}
          %
          Duplikator w\"ahlt dieses $b$ als $b_{i+1}$. Zu zeigen: f\"ur alle $a_j \in \{a_1,\dots, a_i\}$ gilt: 
          %
          \[
            d(a_j,a)=d(b_j,b)
            \quad\text{oder}\quad
            d(a_j,a),d(b_j,b) > 2^{k-(i+1)}
          \]
          %
          Unterscheide 2 F\"alle:
          %
          \begin{enumerate}
            \item
              $a_j \in N_{2^{k-i}}(a_h)$. Folgt direkt aus (III).
          \item
            $a_j \notin N_{2^{k-i}}(a_h)$.

            %    Wir zeigen $d(a_j,a),d(b_j,b) >2^{k-(i+1)}$.

            Offensichtlich gilt $d(a_j,a_h) \leq d(a_j,a) + d(a,a_h)$.
            % \footnote{Unabh\"angig von der Wahl
            % von $a_j$, $a_h$, $a$: Dreiecksungleichung}
            Also auch 
            \[
              \begin{array}{r@{~}c@{~}ll}
                d(a_j,a) & \geq & d(a_j,a_h) - d(a,a_h) \\[1mm]
                         & >    & 2^{k-i} - 2^{k-(i+1)} & \text{(denn $d(a_j,a_h) > 2^{k-i}$} \\[1mm]
                         &      &                       & \text{~und $d(a,a_h) \leq 2^{k-(i+1)}$)} \\[1mm]
                         & =    & 2^{k-(i+1)}
              \end{array}
            \]
            %
            Nach
            % \footnote{Bei der zweiten Ungleichung in der Klammer ist ``$\leq$'' ok, da der entsprechende Wert ja \emph{abgezogen} wird; beachte: insgesamt sagen die drei Ungleichungen: echt groesser
            % als Schwellwert} 
            (I) gilt $b_j \notin N_{2^{k-i}}(b_h)$. Mit (III) auch $d(b,b_h) \leq 2^{k-(i+1)}$.
            Wir k\"onnen also ganz analog zeigen, dass $d(b_j,b) > 2^{k-(i+1)}$.
        \end{enumerate}

      \item
        Es gibt kein $a_h \in \{a_1,\dots,a_i\}$ mit $d(a_h,a) \leq 2^{k-(i+1)}$. 

        Wir zeigen: es gibt ein $b \in B$ so dass $d(b_j,b) >
        2^{k-(i+1)}$ f\"ur alle $j \in \{1,\dots,i\}$. W\"ahlt Duplikator dieses $b$ als $b_{i+1}$,
        so ist ($*$) offensichtlich erf\"ullt.

        Seien $b_{r_1},\dots,b_{r_i}$ die Elemente von $\{b_1,\dots,b_i\}$,
        die auf dem ersten Kreis in $B$ liegen, geordnet in der Reihenfolge
        auf dem Kreis.  Angenommen, es gibt kein $b$ wie beschrieben. Dann gilt
        %
        \[
          d(b_{r_\ell},b_{r_{\ell+1}}) \leq 2^{k-i} \text{ f\"ur } 1 \leq \ell \leq i, \text{ wobei }
          b_{r_{i+1}}=b_{r_1}.
        \]
        %
        Also hat der Kreis h\"ochstens
        %
        \[
          %    s \cdot 2^{k-i} \leq 
          i \cdot  2^{k-i} = 2^{k-i+\log(i)} < 2^k
        \]
        %
        Knoten. Widerspruch.
        \qedhere
      \end{enumerate}
  \end{description}
\end{beweis}%

\pagebreak
% ===================================================================
\section*{T3.17~ Korrektheit der Gewinnstrategie}

\textsfbf{Korollar~3.23.}~
% \par\noindent
\emph{Duplicator} hat eine Gewinnstrategie für $\Gmc_k(\Amf_k,\Bmf_k)$.
%
\begin{beweis}
  Sei also $k \geq 0$ und
  seien $\Gmc_k(\Amf_k,\Bmf_k)$ die in T3.16 beschriebenen Strukturen.
  Wenn Duplicator spielt wie im vorangehenden Beweis von Lemma~3.22 beschrieben,
  dann ergibt das einen abschließenden Spielstand
  $\delta = \{(a_1,b_1),\dots,(a_k,b_k)\}$,
  für den wegen Lemma~3.22 für $1 \leq j < \ell \leq k$ gilt:
  %
  \[
    \tag{$*$}
    \quad d(a_j,a_\ell) ~=~ d(b_j,b_\ell)
    \quad\text{oder}\quad
    d(a_j,a_\ell),~d(b_j,b_\ell) ~>~ 1
  \]
  %
  Wir müssen noch zeigen, dass $\delta$ ein partieller Isomorphismus ist.
  %
  \begin{itemize}
    \item
      $\delta$ ist eine Funktion:
      \par
      Wenn $a_i = a_j$ für $i \neq j$,
      dann ist $d(a_i,a_j) = 0$,
      also mit $(*)$ auch $d (b_i,b_j) = 0$,
      also $b_i = b_j$.
      \par\smallskip
    \item
      $\delta$ ist eine Bijektion:
      \par
      Nach Definition ist $\delta$ surjektiv.
      Für die Injektivität betrachte $a_i,a_j$ mit $a_i \neq a_j$.
      Dann ist $d(a_i,a_j) \neq 0$,
      also muss wegen $(*)$ auch $d (b_i,b_j) > 0$ sein,
      also $b_i \neq b_j$.
      \par\smallskip
    \item
      $\delta$ ist ein Isomorphismus:
      %
      \begin{alignat*}{2}
        (a_i,a_j) \in E^\Amf & \text{~~~gdw.~~~} d(a_i,a_j) = 1 \\
                             & \text{~~~gdw.~~~} d(b_i,b_j) = 1 & & \quad\text{wegen $(*)$} \\
                             & \text{~~~gdw.~~~} (b_i,b_j) \in E^\Amf
      \end{alignat*}
      \qedhere
  \end{itemize}
\end{beweis}%

% ===================================================================
% ===================================================================
% ===================================================================
\part{Prädikatenlogik 2.\ Stufe}

% ===================================================================
\section*{T4.1~ Korrektheit der Formel für Erreichbarkeit}

Sei
$
  \varphi(x,y) = 
  \forall X\,\Big(
    X(x) \land
    \underbrace{\forall z\,\forall z'\,\big(X(z) \land E(z,z') \to X(z')\big)}_{\psi(X)}
    \to X(y)
  \Big)
$
und $\tau = \{E\}$, also die Signatur gerichteter Graphen.
Intuitiv besagt
\begin{itemize}
  \item
    $\psi(X)$, dass die Knotenmenge $X$ unter $E$-Nachfolgern abgeschlossen ist;
  \item
    $\varphi(x,y)$, dass jede Knotenmenge, die $x$ enthält und unter $E$-Nachfolgern abgeschlossen ist,
    auch $y$ enthält.
\end{itemize}

\par\medskip
\textsfbf{Behauptung:}~
Für alle $\tau$-Strukturen $\Amf$ und Elemente $a,b \in A$ gilt
\[
  \Amf \models \varphi[a,b]
  \quad\text{gdw.}\quad
  \text{es einen Pfad in $\Amf$ von $a$ zu $b$ gibt.}
\]

\begin{beweis}
  \begin{description}
    \item[{\boldmath "`$\Rightarrow$"'}]
      Gelte $\Amf \models \varphi[a,b]$.
      Definiere folgende Menge $R \subseteq A$:
      \[
        R = \{\hat a \mid \text{es gibt einen Pfad in $\Amf$ von $a$ zu $\hat a$}\}
      \]
      Da die Menge $R$ abgeschlossen unter $E$-Nachfolgern ist,
      gilt $\Amf \models \psi[R]$.
      Außerdem gilt $a \in R$.
      Wegen $\Amf \models \varphi[a,b]$ (Voraussetzung) gilt dann $b \in R$.
      Nach Definition von $R$ gibt es demnach einen Pfad in $\Amf$ von $a$ zu $b$.
    \item[{\boldmath "`$\Leftarrow$"'}]
      Gebe es einen Pfad in $\Amf$ von $a$ zu $b$.
      Sei $R \subseteq A$ beliebig mit (i) $a \in R$
      und (ii) $\Amf \models \psi[R]$.
      Wegen (ii) ist $R$ abgeschlossen unter Nachfolgern.
      Da es einen Pfad von $a$ zu $b$ gibt, muss auch $b \in R$ sein.
      Also gilt $\Amf \models \varphi[a,b]$.
      \qedhere
  \end{description}
\end{beweis}

% ===================================================================
\section*{T4.2~ Platzkomplexität des Auswertungsalgorithmus}

\textsfbf{Lemma. 4.5}~
Der Algorithmus \texttt{ausw} benötigt
\begin{enumerate}
  \item
    polynomiell viel Platz, wenn die Eingabe eine MSO-Formel ist;
  \item
    exponentiell viel Platz im Allgemeinen.
\end{enumerate}

\begin{beweis}
  Die Eingabe sei eine Struktur $\Amf$ der Größe $n$
  und eine Formel $\varphi$ der Größe $k$.
  \begin{enumerate}
    \item
      \emph{(MSO)}
      \par
      In jedem Schritt ist eine Teilmenge von $A$ zu speichern,
      z.\,B.\ über einen Bitstring der Länge $|A| \leq n$.
      Zudem ist die Rekursionstiefe nach wie vor durch die Verschachtelungstiefe der Formel,
      also letztlich durch $k$ beschränkt.
      Dies liefert einen gesamten Platzbedarf von $\Omc(n\cdot k)$.
    \item
      \emph{(SO)}
      \par
      In jedem Schritt ist eine Menge von $\ell$-Tupeln von Elementen aus $A$ zu speichern.
      Es gibt maximal $n^\ell$ solche Tupel; zudem ist $\ell < k$
      (die Stelligkeit von in der Formel vorkommenden Relationsvariablen
      kann natürlich nicht größer sein als die Länge der Formel).
      Bei Rekursionstiefe $k$ ist der Platzbedarf also $\Omc(n^k \cdot k)$.
      \qedhere
  \end{enumerate}
\end{beweis}

% ===================================================================
\section*{T4.3~ Zeitkomplexität des Auswertungsalgorithmus}

\textsfbf{Lemma 4.6.}~
\noindent
Bei Eingabe einer Struktur \Amf der Gr\"o{\ss}e $n$ und einer Formel $\vp$
der Gr{\"o}{\ss}e $k$ ben\"otigt der Algorithmus \texttt{ausw}
%
\begin{enumerate}
  \item
    Zeit $\mathcal{O}(n^k)$, wenn $\vp$ eine FO-Formel ist;
  \item
    Zeit $2^{\mathcal{O}(nk)}$, wenn $\vp$ eine MSO-Formel ist;
  \item
    Zeit $2^{\mathcal{O}(n^{2k})}$ im Allgemeinen.
\end{enumerate}

\begin{beweis}
  Der Zeitbedarf entspricht im Wesentlichen
  der Größe des Rekursionsbaums, also der Anzahl dessen Knoten.
  Wir müssen also jeweils die maximale Tiefe und den maximalen
  Verzweigungsgrad bestimmen.
  In allen drei Fällen ist die Tiefe nach wie vor durch $k$ beschränkt
  (wie oben).
  \begin{enumerate}
    \item
      \emph{(FO)}
      \par
      Hier ist der Verzweigungsgrad durch $n$ beschränkt,
      denn im Fall $\exists x\,\psi$ bzw.\ $\forall x\,\psi$
      muss für jedes Element $a \in A$ ein Unteraufruf ausgeführt werden,
      und $|A| \leq n$.
      Damit hat der Baum maximal $n^k$ Knoten.
    \item
      \emph{(MSO)}
      \par
      Hier ist der Verzweigungsgrad durch $2^n$ beschränkt,
      denn im Fall $\exists X\,\psi$ bzw.\ $\forall X\,\psi$
      muss für jede \emph{Teilmenge} $B \subseteq A$ ein Unteraufruf ausgeführt werden,
      und es gibt $2^n$ solche Teilmengen, da $|A| \leq n$.
      Damit hat der Baum maximal $(2^n)^k = 2^{nk}$ Knoten.
    \item
      \emph{(SO)}
      \par
      Hier ist der Verzweigungsgrad durch $2^{n^\ell}$ beschränkt,
      wenn $\ell$ die maximale Stelligkeit einer in $\varphi$ vorkommenden Relationsvariable ist,
      denn im Fall $\exists X\,\psi$ bzw.\ $\forall X\,\psi$
      muss nun für jede Teilmenge $B \subseteq A^\ell$ ein Unteraufruf ausgeführt werden.
      Da $\ell$ auch durch die Formelgröße $k$ beschränkt ist,
      hat der Baum maximal $(2^{n^k})^k = 2^{n^kk} \leq 2^{n^{2k}}$ Knoten.
      \qedhere
  \end{enumerate}
\end{beweis}%

% \pagebreak
% ===================================================================
\section*{T4.4~ SO-Tautologien sind nicht rekursiv aufzählbar}

\textsfbf{Theorem 4.8.}~
\noindent
Die Menge der Tautologien in SO ist nicht rekursiv aufzählbar.
%
\begin{beweis}
  Wir nehmen an, die Tautologien in SO seien rekursiv aufzählbar.
  Wir wollen zeigen, dass dann auch die \emph{erfüllbaren} Formeln in $\textsf{FO}(\tau)$ rekursiv aufzählbar wären,
  wobei $\tau$ die Signatur ist, die aus einem einzigen zweistelligen Relationssymbol $R$ 
  besteht. Da dies ein Widerspruch zu Korollar~3.8 ist, muss unsere Annahme falsch sein, und die Behauptung gilt.

  Sei $\varphi \in \textsf{FO}(\{R\})$.
  Es gilt:
  %
  \begin{itemize}
    \item
      $\varphi$ hat ein Modell der Größe $n \in \mathbb{N}$ gdw.
      %
      \begin{align*}
        & \varphi_n \to \exists R\, \varphi \quad \text{gültig,\qquad wobei} \\
%         \intertext{wobei}
        & \varphi_n = \exists x_1\,\cdots\exists x_n\,
        \Big(
          \bigwedge_{1 \leq i < j \leq n} \!\!\! x_i \neq x_j
          ~\land~
          \forall y \!\! \bigvee_{1 \leq i \leq n} \!\! y = x_i
        \Big).
      \end{align*}
%       Man beachte, die SO-Formel $\varphi_n \to \exists R\, \varphi$
%       keine Funktions- oder Relationssymbole verwendet --
%       $R$ ist hier eine Relations\emph{variable} (und die einzige).
    \item
      $\varphi$ hat ein unendliches Modell gdw.
      %
      \[
        \varphi_\infty \to \exists R\, \varphi \quad \text{gültig,}
      \]
      wobei $\varphi_\infty$ die SO-Formel ist, die ausdrückt, dass ein Modell unendlich groß ist
      (siehe Beispiel auf Folie~9).
      Nach den Sätzen von Löwenheim-Skolem für FO braucht man hier nicht zwischen
      unendlichen Modellen verschiedener Größe zu unterscheiden.
  \end{itemize}
  %
  Unter der Annahme, dass die SO-Tautologien rekursiv aufzählbar seien,
  kann man nun die erfüllbaren FO-Formeln wie folgt aufzählen:
  %
  \begin{itemize}
    \item
      Zähle alle gültigen SO-Formeln auf.
    \item
      Für Formel der Form $\varphi_n \to \exists R\,\varphi$
      oder $\varphi_\infty \to \exists R\,\varphi$
      mit $\varphi \in \textsf{FO}(\{R\})$
      gib $\varphi$ aus.
  \end{itemize}
  %
  Damit ist der gewünschte Widerspruch hergestellt und die Annahme widerlegt.
  \qedhere
\end{beweis}%

% \pagebreak
% ===================================================================
\section*{T4.5~ Beispiel einer S1S-Struktur und -Formel}

Betrachte folgende S1S-Struktur $\Amf$:
\begin{center}
  \begin{tikzpicture}[%
    node distance=24mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
    every edge/.style={draw=black,thin}
  ]
    \linstruc{4}
    \linstruclab{1mm}{0}{l}{$P_1$\\~}
    \linstruclab{1mm}{2}{l}{$P_1$\\$P_2$}
    \linstruclab{1mm}{4}{l}{$P_2$}

    \path[->]
      (elem0) edge[bend right=31] node [above] {$<$} (elem1)
      (elem1) edge[bend right=31] node [above] {$<$} (elem2)
      (elem2) edge[bend right=31] node [above] {$<$} (elem3)
      (elem3) edge[bend right=31] node [above] {$<$} (elem4)

      (elem0) edge[bend right=49] node [above] {$<$} (elem2)
      (elem1) edge[bend right=49] node [above] {$<$} (elem3)
      (elem2) edge[bend right=49] node [above] {$<$} (elem4)

      (elem0) edge[bend right=67] node [above] {$<$} (elem3)
      (elem1) edge[bend right=67] node [above] {$<$} (elem4)

      (elem0) edge[bend right=85] node [above] {$<$} (elem4);

    \node [above left=1mm and 1mm of elem0] {0};
  \end{tikzpicture}%
\end{center}

Von nun an werden wir nur noch die Nachfolgerfunktion $s$ einzeichnen,
nicht mehr die Konstante 0 oder die Relation $<$. Die obige Struktur \Amf
stellen wir also abgekürzt so dar:
\begin{center}
  \begin{tikzpicture}[%
    node distance=24mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
    every edge/.style={draw=black,thin}
  ]
    \linstruc{4}
    \linstruclab{1mm}{0}{l}{$P_1$\\~}
    \linstruclab{1mm}{2}{l}{$P_1$\\$P_2$}
    \linstruclab{1mm}{4}{l}{$P_2$}
  \end{tikzpicture}%
\end{center}

Es gilt $\Amf \models \forall x\,\Big(P_1(x) \lor P_2(x)\Big)$
(d.\,h.: jedes Element ist entweder mit $P_1$ markiert oder sein Nachfolger mit $P_2$).

% ===================================================================
\section*{T4.6~ Beispiel für Strukturen vs.\ Wörter, Alphabetgröße {\boldmath $n=1$}}

Sei $n=1$, also $\Sigma_1 = \{0,1\}$. Dann gibt es nur ein einziges $P_i$, nämlich $P_1$, und
%
\begin{itemize}
  \item
    wenn ein Element $i$ mit $P_1$ markiert ist (also $i \in P_1^\Amf$),
    dann entspricht das dem Buchstaben 1 an Position $i$ im Wort;
  \item
    wenn ein Element $i$ \emph{nicht} mit $P_1$ markiert ist (also $i \notin P_1^\Amf$),
    dann entspricht das dem Buchstaben 0 an Position $i$ im Wort.
\end{itemize}
%
Die Struktur
\begin{center}
  \begin{tikzpicture}[%
    node distance=12mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
    every edge/.style={draw=black,thin}
  ]
    \linstruc{4}
    \linstruclab{1mm}{0}{l}{$P_1$}
    \linstruclab{1mm}{1}{l}{$P_1$}
    \linstruclab{1mm}{2}{l}{$P_1$}
    \linstruclab{1mm}{4}{l}{$P_1$}
  \end{tikzpicture}%
\end{center}
repräsentiert also das Wort 11101.

% ===================================================================
\section*{T4.7~ Anmerkung zu "`krummen"' Alphabetgrößen}

Die Alphabete $\Sigma_n = {0,1}^n$ haben natürlich $2^n$ Elemente.
Man kann aber trotzdem auch Alphabete betrachten mit einer Anzahl von Buchstaben, die keine Zweierpotenz ist:
Wenn man z.\,B.\ an $\Sigma = \{a,b,c\}$ interessiert ist,
dann trifft man zunächst die Zuordnung
\[
  \binom00 \mapsto a,\qquad
  \binom01 \mapsto b,\qquad
  \binom10 \mapsto c.
\]
Dann muss man noch ausschließen, dass der nicht benötigte Buchstabe $\binom11$ nirgends vorkommt.
Dazu fügt man jeder S1S-Formel das folgende Konjunkt hinzu:
\[
  \lnot \exists x\, \Big(P_0(x) \land P_1(x)\Big)
\]
Jede so erweiterte Formel hat nur Modelle, in denen $\binom11$ nicht als Markierung vorkommt.

% ===================================================================
\section*{T4.8~ Beispiele MSO-definierter Sprachen}

Im Folgenden wählen wir der Einfachheit halber $n=1$, also $\Sigma_1 = \{0,1\}$.
Wir verwenden $\textsf{last}(x)$ als Abkürzung für $s(x)=x$,
also eine Formel mit einer freien Variablen, die besagt,
dass das entsprechende Element (Position im Wort) das Wortende ist.

\par\medskip\noindent
\textsfbf{Beispiel 1}
%
\begin{align*}
  \varphi_1    & ~=~ P_1(0) ~\land~ \forall x\,\bigg(
                                    \Big(\big(P_1(x) \land \lnot \textsf{last}(x)\big) \to \lnot P_1\big(s(x)\big)\Big) ~~\land \\
               &     \hspace*{31mm} \Big(\big(\lnot P_1(x) \land \lnot \textsf{last}(x)\big) \to P_1\big(s(x)\big)\Big) ~~\land \\
               &     \hspace*{31mm} \textsf{last}(x) \to \lnot P_1(x)~\bigg) \\
  L(\varphi_1) & ~=~ (10)^*
\end{align*}
%
Beachte: die Objektvariablen stehen für Elemente des Universums,
also quantifiziert $\forall x$ über die \emph{Positionen des Wortes}.

\goodbreak
\par\medskip\noindent
\textsfbf{Beispiel 2}
%
\begin{align*}
  \varphi_2    & ~=~ \forall X\,\Bigg( X(0) ~~\land \\
               &     \hspace*{20mm} \forall y\, \bigg( \Big( \big(X(y) \land \lnot \textsf{last}(y)\big) \to \lnot X\big(s(y)\big) \Big)~~\land \\
               &     \hspace*{27mm}                    \Big( \big(\lnot X(y) \land \lnot \textsf{last}(y)\big) \to X\big(s(y)\big) \Big) \bigg) \\
               &     \hspace*{19mm} \to \forall y\, \Big(\textsf{last}(y) \to \lnot X(y) \Big) \Bigg) \\
  L(\varphi_2) & ~=~ \{w \in \Sigma^* \,\mid\, |w| \text{~ist geradzahlig}\}
\end{align*}
%

\par\medskip\noindent
\textsfbf{Beispiel 3}
%
\begin{align*}
  \varphi_3    & ~=~ \hspace*{3mm}      \lnot \exists x\,\Big( P_1(x) \land \lnot P_1\big(s(x)\big) \Big) \\
               &     \hspace*{6mm} \lor \lnot \exists x\,\Big( \lnot P_1(x) \land P_1\big(s(x)\big) \Big) \\[3mm]
  L(\varphi_3) & ~=~ 0^*1^* \,\cup\, 1^*0^*
\end{align*}

% ===================================================================
\section*{T4.9~ Beweis Satz von Büchi-Elgot-Trakhtenbrot, {\boldmath "`1 $\Rightarrow$ 2"'}}

\textsfbf{Behauptung:}~ Wenn $L$ regulär ist, dann $L=L(\varphi)$ für einen S1S-Satz $\varphi$.

\begin{beweis}
  Wir wollen zeigen, dass man jeden nichtdeterministischen endlichen Automaten (NEA) $\Amc$
  in einen S1S-Satz $\varphi$ umwandeln kann mit $L(\varphi) = L(\Amc)$.
  Sei also $\Amc = (Q,\Sigma,q_0,\Delta,F)$ ein NEA.
  Eine akzeptierende Berechnung von $\Amc$ auf einer Eingabe $w$
  kann man auf"|fassen als Beschriftung von $w$ mit Zuständen aus $Q$,
  die die Übergangsrelation einhält.%
  \footnote{%
    Dies ist eine Variante der üblichen Definition von Akzeptanz 
    % TODO: Skript-Referenz aktualisieren auf WiSe 16/17, SoSe 17;
    %       hier passenden Literaturverweis einfügen
    über Pfade, siehe auch "`Theoretische Informatik 1"' \cite{SkriptThI}.)%
  }
  Betrachten wir also z.\,B.\ den NEA
  \begin{center}
    \begin{tikzpicture}[%
      node distance=12mm,>=Latex,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial]   (0)              {0};
      \node[state]           (1) [right=of 0] {1};
      \node[state,accepting] (2) [right=of 1] {2};

      \path[->] (0) edge             node[below] {$b$}   (1)
                (1) edge             node[below] {$a$}   (2)
                (0) edge[loop above] node[right] {~$a,b$} ();

      \node [above left=1mm and 5mm of 0]  {$\Amc$};
    \end{tikzpicture}%
  \end{center}
  und das Eingabewort $w = aabaaba$,
  so gibt es folgende Berechnung von $\Amc$ auf $w$:
  \begin{center}
    \begin{tabular}{@{}c@{~\,}c@{~\,}*8{c@{\,}}}
      $w$ & $=$ & $a$ & $a$ & $b$ & $a$ & $a$ & $b$ & $a$ &   \\
          &     & 0   & 0   & 0   & 0   & 0   & 0   & 1   & 2 \\
    \end{tabular}
  \end{center}
  Diese Beschriftung stellt tatsächlich eine akzeptierende Berechnung von $\Amc$ auf $w$ dar,
  denn
  \begin{itemize}
    \item
      $0$ (1. Markierung) ist der Anfangszustand von \Amc;
    \item
      $(0,a,0) \in \Delta$ (1.\ Markierung, 1.\ Buchstabe von $w$, 2.\ Markierung);
    \item
      $(0,a,0) \in \Delta$ (2.\ Markierung, 2.\ Buchstabe von $w$, 3.\ Markierung);
    \item[]
      $\vdots$
    \item
      $(1,a,2) \in \Delta$ (vorletzte Markierung, letzter Buchstabe von $w$, letzte Markierung);
    \item
      $2 \in F$ (letzte Markierung ist ein akzeptierender Zustand).
  \end{itemize}

  \par\medskip\noindent
  Wir definieren nun einen S1S-Formel $\varphi_\Amc$, die ausdrückt,
  dass eine beliebige Beschriftung eine akzeptierende Berechnung 
  im Sinne der eben aufgelisteten Eigenschaften
  darstellt. Dazu nehmen wir o.\,B.\,d.\,A.\ an, die Zustandsmenge von \Amc
  sei $Q = \{q_0,\dots,q_m\}$ und das Alphabet sei $\Sigma_n$.
  Für jedes Zeichen $a = (b_1,\dots b_n) \in \Sigma_n$
  verwenden wir eine Abkürzung, die besagt, dass sich an einer Position $x$
  im Wort das Zeichen $a$ befindet:
  \[
    S_a(x) = \bigwedge_{\substack{1 \leq i \leq n\\[1pt] b_i = 0}}\!\! \lnot P_i(x)  ~\land
             \bigwedge_{\substack{1 \leq i \leq n\\[1pt] b_i = 1}}\!\! P_i(x)
  \]
  Außerdem verwenden wie die Abkürzung $\textsf{last}(x)$ aus dem vorigen Beispiel.

  Wir definieren $\varphi_\Amc$ wie folgt.
  \begin{align*}
    \varphi_\Amc & ~=~ \exists Q_0\, \cdots \exists Q_m\,\Bigg( \\
                 & \hspace*{10mm} Q_0(0) ~~\land \\
                 & \hspace*{10mm} \forall x\,\bigg(\lnot \textsf{last}(x) \to \bigvee_{(q_i,a,q_j) \in \Delta} \Big(Q_i(x) \land S_a(x) \land Q_j\big(s(x)\big)\Big)\bigg) ~~\land \\
                 & \hspace*{10mm} \forall x\,\bigg(\textsf{last}(x) \to \bigvee_{\substack{(q_i,a,q_j) \in \Delta\\q_j \in F}} \Big(Q_i(x) \land S_a(x))\Big)\bigg) ~~\land \\
                 & \hspace*{10mm} \forall x\,\bigwedge_{0 \leq i < j \leq m} \lnot\Big(Q_i(x) \land Q_j(x))\Big)
  \end{align*}
  Die Intuition hinter $\varphi_\Amc$ ist folgende.
  Die einstelligen Relationsvariablen $Q_i$ repräsentieren alle diejenigen Positionen im Wort,
  die mit $q_i$ beschriftet sind. Dabei läuft $i$ von 0 bis einschließlich $m$,
  denn das Wort hat $m$ Buchstaben an Positionen $0,\dots,m-1$, und die Beschriftung hat eine Position mehr (siehe Beispiel).
  Die einzelnen Konjunkte in $\varphi_\Amc$ besagen nun, dass
  \begin{enumerate}
    \item
      die Berechung von $\Amc$ in einem Startzustand beginnt,
    \item
      die Übergangsrelation eingehalten wird,
    \item
      die Berechnung in einem akzeptierenden Zustand endet\\
      (dieser kann \emph{keiner} Position im Wort zugeordnet werden),
    \item
      die Beschriftung nicht "`entartet"' ist, also jede Position mit höchstens einem Zustand beschriftet ist
      ("`mit \emph{mindestens} einem"' folgt aus den vorhergehenden Konjunkten -- überzeuge Dich selbst!).
  \end{enumerate}
  Man zeigt nun leicht:
  \[
    w \in L(\Amc)
    \quad\text{gdw.}\quad
    w \in L(\varphi_\Amc) \text{~für alle~} w \in \Sigma^*
  \]
  Dazu muss man aus einer akzeptierenden Berechnung von $\Amc$ (Beschriftung von $w$)
  ein S1S-Modell für $\varphi_\Amc$ konstruieren und umgekehrt.
  Das Beschreiben dieser Konstruktionen ist eine gute Übung für Euch. :)
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T4.10~ Beispiel S1S-Normalform}

Wir betrachten wieder $\Sigma_1 = \{0,1\}$.
Die folgende S1S-Formel ist in Normalform:
\begin{align*}
  \varphi    & ~=~ \hspace*{3mm}      \lnot \exists X\, \exists Y\,\Big(X \subseteq P_1 ~\land~ \lnot\big(Y \subseteq P_1\big) ~\land~ \textsf{succ}(X)=Y \Big) \\
             &     \hspace*{6mm} \lor \lnot \exists X\, \exists Y\,\Big(\lnot\big(X \subseteq P_1\big) ~\land~ Y \subseteq P_1 ~\land~ \textsf{succ}(X)=Y \Big)
\end{align*}
Man beachte dabei: die Konjunkte $\textsf{succ}(X)=Y$ beinhalten, dass $X$ und $Y$ Einermengen sind;
deshalb bedeutet z.\,B. $\lnot\big(Y \subseteq P_1\big)$, dass
an der Position, die durch $Y$ repräsentiert wird, \emph{nicht} $P_1$ steht.

Diese Formel entspricht der aus Beispiel~3 in T4.8:
die beiden Disjunkte besagen, dass es kein Infix 10 bzw. 01 gibt.
Damit ist wieder $L(\varphi) = 0^*1^* \cup 1^*0^*$.

% ===================================================================
\section*{T4.11~ Beweis des Lemmas zur S1S-Normalform}

\textsfbf{Lemma 4.12.}
Jeder S1S-Satz kann effektiv in einen äquivalenten Satz in Normalform gewandelt werden.

\begin{beweis}
  \textsfbf{(Skizze)}~
  Im Folgenden werden die notwendigen Schritte zur Herstellung der Normalform
  an konkreten Beispielen verdeutlicht.
  Es ist vergleichsweise leicht, diese Schritte allgemeingültig zu formulieren
  und zu zeigen, dass nach jedem Schritt die umgewandelte Teilformel
  äquivalent zur ursprünglichen ist.

  \par\medskip\noindent
  \textsfbf{Schritt 1:~ Eliminieren der Symbole 0 und {\boldmath $<$}}

  Zum Beispiel:
  \begin{align*}
    P_i(0) & ~\equiv~ \exists x\,\Big(\forall y\,\lnot \big(s(y) \!\!\:=\!\!\: x\big) ~\land~ P_i(x)\Big) \\
    x > 0 & ~\equiv~ \exists y\,\Big(s(y)=x\Big) \\
    t < t' & ~\equiv~ \exists X\,\bigg(X(t') ~\land~ \forall z\,\Big(X(z) \to X\big(s(z)\big)\Big) ~\land~ \lnot X(t) \bigg)
  \end{align*}
  In der ersten und zweiten Zeile wird die Anfangsposition des Wortes ähnlich umschrieben
  wie in den vorigen Beispielen die Endposition mittels $\textsf{last}(x)$.
  In der dritten Zeile stehen $t$ und $t'$ für beliebige Terme
  (die aus Objektvariablen, dem Konstantensymbol 0 und der Nachfolgerfunktion $s$
  gebildet werden können). Die rechte Formel besagt, dass es eine Menge
  von Positionen gibt ($X$), die $t'$ enthält, abgeschlossen unter Nachfolgern ist
  (also "`induktiv"' alle Positionen hinter $t'$ enthält) und nicht $t$ enthält.
  Das ist natürlich genau dann der Fall, wenn Position $t$ vor $t'$ liegt.

  \par\medskip\noindent
  \textsfbf{Schritt 2:~ Schachtelung von $s$ eliminieren}

  Zum Beispiel:
  \begin{align*}
    x = s(s(s(y))) & ~\equiv~ \exists z_1\, \exists z_2\, \Big(z_1 = s(y) ~\land~ z_2 = s(z_1) ~\land~ x = s(z_2)\Big)
  \end{align*}
  Mit anderen geschachtelten Vorkommen von $s$, z.\,B. in $P_i(s(s(s(y))))$,
  wird ganz analog umgegangen.

  \par\medskip\noindent
  \textsfbf{Schritt 3:~ Umschreiben atomarer Formeln,} so dass nur noch Atome der folgenden Formen vorkommen
  \[
    x=y,\quad s(x)=y,\quad P_i(x),\quad X(x)
  \]
  Zum Beispiel:
  \begin{align*}
    P_i(s(x)) & ~\equiv~ \exists y\,\Big(y \!\!\:=\!\!\: s(x) ~\land~ P_i(y)\Big)
  \end{align*}

  \par\medskip\noindent
  \textsfbf{Schritt 4:~ Eliminieren von Objektvariablen {\boldmath ($x,\dots$)}} in Quantoren und Atomen.

  Dazu definieren wir eine Formel $\textsf{Einer}(X)$ mit einer freien einstelligen Relationsvariablen $X$,
  die ausdrückt, dass die entsprechende Menge eine Einermenge ist -- dass erreicht man, indem man fordert,
  dass diese Menge genau eine echte Teilmenge hat:
  \begin{align*}
    \textsf{Einer}(X) & ~:=~ \exists Y\,\Big(Y \!\!\:\subseteq\!\!\: X ~\land~ \lnot\big(Y \!\!\:=\!\!\: X) ~\land~ 
                                            \forall Z\,\big(Z \!\!\:\subseteq\!\!\: X \,\to\, Z \!\!\:=\!\!\: X \,\lor\, Z \!\!\:=\!\!\: Y)\Big), \text{~~wobei}\\
    X=Y               & ~:=~ X \!\!\:\subseteq\!\!\: Y \,\land\, Y \!\!\:\subseteq\!\!\: X
  \end{align*}
  Beispiele für Schritt 4 sind nun:
  \begin{align*}
    \exists x\,P_i(x) & \,\equiv\, \exists X\Big(\textsf{Einer}(X) ~\land~ X \subseteq P_i\Big) \\
    \forall x\:\!\exists y \Big(s(x) \!\!\:=\!\!\: y \,\land\, Z(y)\Big)
                      & \,\equiv\, \forall X\bigg(\textsf{Einer}(X) \,\to\, \exists Y\Big(\textsf{Einer}(Y) \,\land\, \textsf{succ}(X) \!\!\:=\!\!\: Y \,\land\, Y \!\!\:\subseteq\!\!\: Z\Big)\bigg)
  \end{align*}
  \quasiqedhere
\end{beweis}%
\goodbreak

% ===================================================================
\section*{T4.12~Beweis Satz von Büchi-Elgot-Trakhtenbrot, {\boldmath "`2 $\Rightarrow$ 1"'}}

\textsfbf{Behauptung:}~ Für jeden S1S-Satz $\varphi$ ist $L(\varphi)$ regulär.

\begin{beweis}
  Sei $\varphi$ ein S1S-Satz.
  Wegen des vorangehenden Lemmas können wir o.\,B.\,d.\,A.\ annehmen,
  dass $\varphi$ in Normalform vorliegt.
  Wir wollen nun induktiv über den Aufbau von $\varphi$ einen NEA $\Amc_\varphi$ konstruieren,
  der $L(\varphi)$ erkennt, also mit $L(\Amc_\varphi) = L(\varphi)$.
  Dazu müssen wir auch Teilformeln von $\varphi$ betrachten, die in der Regel
  freie Relationsvariablen haben. Diese werden genauso behandelt wie die $P_i$:
  beispielsweise hat die Formel $\exists Y\,\big(X \!\!\:\subseteq\!\!\: Y \land P_1 \!\!\:\subseteq\!\!\: Y\big)$
  eine freie Relationsvariable ($X$) und ein Relationssymbol ($P_1$)
  und definiert damit eine Sprache über $\Sigma_2 = \{0,1\}^2$,
  wenn man sich auf eine Reihenfolge der Relationssymbole und Variablen festlegt
  (z.\,B. "`das erste Bit entspricht $P_1$ und das zweite $X$"').

  Wir konstruieren nun $\Amc_\varphi$ induktiv wie folgt.
  \begin{description}
    \item[Induktionsanfang.]~
      \par
      Laut Definition der Normalform gibt es zwei mögliche Formen von atomaren Formeln:
      \begin{itemize}
        \item
          $\varphi = X \subseteq Y$
          ~\par
          Dann ist das Alphabet $\Sigma_2 = \{0,1\}^2$ und es gilt
          \[
            L(\varphi) \,=\, \Bigg\{ w \,=\,\binom{b_1}{b_1'}\cdots\binom{b_n}{b_n'} \,~\Bigg|~\, \text{wenn~} b_i=1, \text{~dann~} b_i'=1\Bigg\},
          \]
          also ist $\Amc_\varphi$ wie folgt:
          \begin{center}
            \begin{tikzpicture}[%
              node distance=12mm,>=Latex,
              initial text="", initial where=below left,
              every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
              accepting/.style={double distance=1.5pt, double=white},
              every edge/.style={draw=black,thin}
            ]
              \node[state,initial,accepting] (0) {};

              \path[->] (0) edge[loop right] node[right] {$\binom00,\binom01,\binom11$} ();

              \node [above left=1mm and 5mm of 0]  {$\Amc_\varphi$};
            \end{tikzpicture}%
          \end{center}
        \item
          $\varphi = \textsf{succ}(X) = Y$
          ~\par
          Dann ist das Alphabet wieder $\Sigma_2 = \{0,1\}^2$ und es gilt
          \[
            L(\varphi) \,=\, \Bigg\{ w \,=\,\binom{b_1}{b_1'}\cdots\binom{b_n}{b_n'} \,~\Bigg|~\, \text{es gibt $k$ mit~}~
            \begin{array}[t]{@{}l@{}}
              b_k=1,~ b'_{k+1}=1, \\
              b_j=0 \text{~für alle~} j \neq k, \\
              b_j'=0 \text{~für alle~} j \neq k+1
            \end{array}
            \raisebox{-28pt}{\Bigg\},}
          \]
          also ist $\Amc_\varphi$ wie folgt:
          \begin{center}
            \begin{tikzpicture}[%
              node distance=12mm,>=Latex,
              initial text="", initial where=below left,
              every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
              accepting/.style={double distance=1.5pt, double=white},
              every edge/.style={draw=black,thin}
            ]
              \node[state,initial]   (0)              {};
              \node[state]           (1) [right=of 0] {};
              \node[state,accepting] (2) [right=of 1] {};

              \path[->] (0) edge[loop above] node[right] {\,$\binom00$} ()
                        (0) edge             node[below] {$\binom10$} (1)
                        (1) edge             node[below] {$\binom01$} (2)
                        (2) edge[loop above] node[right] {\,$\binom00$} ();

              \node [above left=1mm and 5mm of 0]  {$\Amc_\varphi$};
            \end{tikzpicture}%
          \end{center}
      \end{itemize}

    \item[Induktionsschritt.]~
      \par
      Wir nehmen die reduzierte Form an, d.\,h.\
      wir brauchen nur die Operatoren $\lnot,\land,\exists X$ zu betrachten
      und können auf $\lor,\forall X$ verzichten (siehe Teil 2, Grundlagen FOL).
      \begin{itemize}
        \item
          $\varphi = \lnot \psi$
          ~\par
          Nach Induktionsvoraussetzung gibt es einen NEA $\Amc_\psi$
          mit $L(\Amc_\psi) = L(\psi)$.
          Da $L(\varphi) = \overline{L(\psi)}$ (Semantik der Negation),
          suchen wir einen NEA $\Amc_\varphi$ mit $L(\Amc_\varphi) = \overline{L(\Amc_\psi)}$.
          Diesen können wir konstruieren, indem wir $\Amc_\psi$
          mittels Potenzmengenkonstruktion in einen DEA umwandeln 
          und dann dessen akzeptierende und nicht-akzeptierende Zustände vertauschen
          (Theoretische Informatik 1, \cite{SkriptThI}).
        \item
          $\varphi = \psi_1 \land \psi_2$
          ~\par
          Nach Induktionsvoraussetzung gibt es einen NEAs $\Amc_{\psi_i}$
          mit $L(\Amc_{\psi_i}) = L(\psi_i)$ für $i=1,2$.
          Die Semantik der Konjunktion legt nahe, dass
          $(*)$ $L(\varphi) = L(\psi_1) \cap L(\psi_2)$ ist
          und wir deshalb einen NEA $\Amc_\varphi$ suchen sollten
          mit $L(\Amc_\varphi) = L(\Amc_{\psi_1}) \cap L(\Amc_{\psi_2})$.
          Dazu könnten wir den Produktautomaten konstruieren (Theoretische Informatik 1, \cite{SkriptThI}).

          Allerdings ist $(*)$ nicht ganz korrekt,
          denn die freien Variablen in $\psi_1$ und $\psi_2$ müssen nicht übereinstimmen.
          Hat also z.\,B.\ $\psi_1$ die freien Variablen $X_1,X_2$
          und $\psi_2$ die freien Variablen $X_2,X_3$,
          so hat $\varphi$ die freien Variablen $X_1,X_2,X_3$.
          Damit ist $L(\varphi)$ über einem anderen Alphabet ($\{0,1\}^3$)
          definiert als die $L(\psi_i)$ (Alphabet $\{0,1\}^2$).

          Um die Produktkonstruktion anwenden zu können,
          müssen wir also zunächst die NEAs $\Amc_{\psi_i}$
          so erweitern, dass ihre Alphabete gleich sind und alle
          freien Variablen in $\varphi$ berücksichtigen.
          Im obigen Beispiel mit 2 bzw.\ 3 freien Variablen muss man also
          jeden Übergang
          \begin{center}
            \begin{tikzpicture}[%
              node distance=20mm,>=Latex,
              initial text="", initial where=below left,
              every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
              accepting/.style={double distance=1.5pt, double=white},
              every edge/.style={draw=black,thin}
            ]
              \node[state] (0)              {$q$};
              \node[state] (1) [right=of 0] {$q'$};

              \path[->] (0) edge             node[above] {$\binom{b_1}{b_2}$} (1);
            \end{tikzpicture}%
          \end{center}
          in $\Amc_{\psi_1}$
          ersetzen durch die Übergänge:
          \begin{center}
            \begin{tikzpicture}[%
              node distance=20mm,>=Latex,
              initial text="", initial where=below left,
              every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
              accepting/.style={double distance=1.5pt, double=white},
              every edge/.style={draw=black,thin}
            ]
              \node[state] (0)              {$q$};
              \node[state] (1) [right=of 0] {$q'$};

              \path[->] (0) edge node[above] {$\bigg(\begin{array}{@{}c@{}}\scriptstyle b_1\\[-4pt]\scriptstyle b_2\\[-4pt]\scriptstyle 0\end{array}\bigg)$,
                                              $\bigg(\begin{array}{@{}c@{}}\scriptstyle b_1\\[-4pt]\scriptstyle b_2\\[-4pt]\scriptstyle 1\end{array}\bigg)$} (1);
            \end{tikzpicture}%
          \end{center}
          Der gesuchte NEA $\Amc_\varphi$ ergibt sich dann mittels
          Produktkonstruktion aus den modifizierten NEAs
          $\Amc_{\psi_i}$, und man kann leicht zeigen, dass $L(\Amc_\varphi) = L(\varphi)$.
        \item
          $\varphi = \exists Y\,\psi(Y,X_1,\dots,X_n)$\quad (hier sind die freien Variablen relevant)
          ~\par
          Nach Induktionsvoraussetzung gibt es einen NEA $\Amc_\psi$
          über dem Alphabet $\Sigma_{n+1}$ mit $L(\Amc_\psi) = L(\psi)$.
          Daraus erhält man den gewünschten Automaten $\Amc_\varphi$ über dem Alphabet $\Sigma_n$
          durch folgende Modifikation:
          Ersetze jeden Übergang
          \begin{center}
            \begin{tikzpicture}[%
              node distance=20mm,>=Latex,
              initial text="", initial where=below left,
              every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
              accepting/.style={double distance=1.5pt, double=white},
              every edge/.style={draw=black,thin}
            ]
              \node[state] (0)              {$q$};
              \node[state] (1) [right=of 0] {$q'$};

              \path[->] (0) edge node[above] {$\Bigg(\begin{array}{@{}c@{}}\scriptstyle b_0\\[-4pt]\scriptstyle b_1\\[-5pt]\scriptstyle \vdots\\[-5pt]\scriptstyle b_n\end{array}\Bigg)$} (1);
            \end{tikzpicture}%
          \end{center}
          in $\Amc_\psi$ durch:
          \begin{center}
            \begin{tikzpicture}[%
              node distance=20mm,>=Latex,
              initial text="", initial where=below left,
              every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
              accepting/.style={double distance=1.5pt, double=white},
              every edge/.style={draw=black,thin}
            ]
              \node[state] (0)              {$q$};
              \node[state] (1) [right=of 0] {$q'$};

              \path[->] (0) edge node[above] {$\Bigg(\begin{array}{@{}c@{}}\scriptstyle b_1\\[-5pt]\scriptstyle \vdots\\[-5pt]\scriptstyle b_n\end{array}\Bigg)$} (1);
            \end{tikzpicture}%
          \end{center}
          Das Weglassen der Komponente $b_0$ ist korrekt,
          denn die Interpretation von $Y$ ist für $\varphi$ irrelevant.
          \qedhere
      \end{itemize}
  \end{description}
\end{beweis}%

\goodbreak
Man beachte, dass die Konstruktion im letzten Fall ($\exists$)
unter Umständen aus einem DEA einen NEA macht,
denn es kann vor dem Löschen von $b_0$ zwei Übergänge zu zwei verschiedenen Zuständen gegeben haben
mit zwei Zeichen, die sich nur durch den Wert von $b_0$ unterscheiden,
z.\,B.:
\begin{center}
  \begin{tikzpicture}[%
    node distance=20mm,>=Latex,baseline=-2pt,
    initial text="", initial where=below left,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
    accepting/.style={double distance=1.5pt, double=white},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (0)                                 {$q$};
    \node[state] (1) [above right=2mm and 20mm of 0] {$q'$};
    \node[state] (2) [below right=2mm and 20mm of 0] {$q''$};

    \path[->] (0) edge node[auto]       {$\binom00$} (1);
    \path[->] (0) edge node[auto, swap] {$\binom10$} (2);
  \end{tikzpicture}%
  \qquad\qquad wird zu\qquad\qquad
  \begin{tikzpicture}[%
    node distance=20mm,>=Latex,baseline=-2pt,
    initial text="", initial where=below left,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
    accepting/.style={double distance=1.5pt, double=white},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (0)                                 {$q$};
    \node[state] (1) [above right=2mm and 20mm of 0] {$q'$};
    \node[state] (2) [below right=2mm and 20mm of 0] {$q''$};

    \path[->] (0) edge node[auto]      {$0$} (1)
              (0) edge node[auto,swap] {$0$} (2);
  \end{tikzpicture}%
\end{center}
Dadurch muss man im schlimmsten Fall für jede Negation erneut die Potenz\-mengen\-konstruktion anwenden,
welche jedes Mal den Automaten exponentiell vergrößern kann.
Im schlimmsten Fall wird der Automat also \emph{nicht-elementar} größer:
für eine Formel $\varphi$ der Länge $n$ kann die Anzahl der Zustände im Automaten $\Amc_\varphi$
so groß werden:
\[
  \raisebox{-8pt}{$2^{2^{\iddots^{2^n}}}$} \bigg\} \text{~Höhe~} n
\]

% ===================================================================
\section*{T4.13~ Beispiel für die Konstruktion im vorangehenden Beweis}

Sei
$
  \varphi = \exists X\,\exists Y\,\Big(
    \underbrace{%
      X\!\!\:\subseteq\!\!\:P_1 \,\land\, Y\!\!\:\subseteq\!\!\:P_2 \,\land\, \textsf{succ}(X)\!\!\:=\!\!\:Y%
    }_{%
      \psi
    }
  \Big)
$.
Die Sprache $L(\varphi) \subseteq \Sigma_2$ ist:
\[
  \Sigma_2^* ~\cdot~ \Bigg(\binom10 \cup \binom11\Bigg) ~\cdot~ \Bigg(\binom01 \cup \binom11\Bigg) ~\cdot~ \Sigma_2^*
\]
Zur Erinnerung: jedes Relationssymbol $P_i$
und jede \emph{freie} Relationsvariable $X,Y$
wird durch ein "`Bit"' repräsentiert.
Die Reihenfolge legen wir dabei fest als $X,Y,P_1,P_2$.

Wir beginnen mit den Automaten für die atomaren Teilformeln
$X\subseteq P_1$, $Y\subseteq P_2$, $\textsf{succ}(X)=Y$,
welche jeweils zwei freie Variablen bzw.\ Relationssymbole haben; also ist das Alphabet
ebenfalls $\Sigma_2$. Wir schreiben ab jetzt die Bitstrings horizontal,
also z.\,B.\ $(0,1)$ statt $\binom01$.
\begin{center}
  \parbox[t]{.25\linewidth}{%
    \begin{tikzpicture}[%
      node distance=20mm,>=Latex,baseline=0pt,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial,accepting] (0) {};

      \path[->] (0) edge[loop right] node[right] {\begin{tabular}{@{}l@{}}(0,0)\\(0,1)\\(1,1)\end{tabular}} ();

      \node [above=1mm of 0] {$\Amc_{X\:\!\subseteq\:\!P_1}$};
    \end{tikzpicture}%
  }%
  \hspace*{\fill}
  \parbox[t]{.25\linewidth}{%
    \begin{tikzpicture}[%
      node distance=20mm,>=Latex,baseline=0pt,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial,accepting] (0) {};

      \path[->] (0) edge[loop right] node[right] {\begin{tabular}{@{}l@{}}(0,0)\\(0,1)\\(1,1)\end{tabular}} ();

      \node [above=1mm of 0] {$\Amc_{Y\:\!\subseteq\:\!P_2}$};
    \end{tikzpicture}%
  }%
  \hspace*{\fill}
  \parbox[t]{.48\linewidth}{%
    \begin{tikzpicture}[%
      node distance=25mm,>=Latex,baseline=0pt,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial]   (0)              {};
      \node[state]           (1) [right of=0] {};
      \node[state,accepting] (2) [right of=1] {};

      \path[->] (0) edge             node[below] {(1,0)} (1)
                (1) edge             node[below] {(0,1)} (2)
                (0) edge[loop below] node[below] {(0,0)} ()
                (2) edge[loop below] node[below] {(0,0)} ();

      \node [above=1mm of 0] {$\Amc_{\textsf{succ}(X)\:\!=\:\!Y}$};
    \end{tikzpicture}%
  }%
\end{center}
Um den Automaten für die Konjunktion $\psi$ zu bilden,
müssen wir zuerst für die bisherigen Automaten das Alphabet
auf $\Sigma_4$ erweitern, denn in $\psi$
kommen alle 4 Relationsvariablen und -symbole $X,Y,P_1,P_2$
vor. Da die hinzugekommenen Bits beliebige Werte annehmen können,
schreiben wir an diesen Stellen der Einfachheit halber "`$*$"'.
Beispielsweise steht "`$(0,*,0,*)$"' für
"`$(0,0,0,0),\,(0,0,0,1),\,(0,1,0,0),\,(0,1,0,1)$"'.
Man beachte, dass diese Positionen von der jeweils hinzugenommenen Variable abhängen
(also $Y,P_2$ und damit Position 2,4 bei $\Amc'_{X\:\!\subseteq\:\!P_1}$,
$X,P_1$ und damit Position 1,3 bei $\Amc'_{Y\:\!\subseteq\:\!P_2}$ usw.).
\begin{center}
  \parbox[t]{.25\linewidth}{%
    \begin{tikzpicture}[%
      node distance=20mm,>=Latex,baseline=0pt,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial,accepting] (0) {};

      \path[->] (0) edge[loop right] node[right] {\begin{tabular}{@{}l@{}}(0,*,0,*)\\(0,*,1,*)\\(1,*,1,*)\end{tabular}} ();

      \node [above=1mm of 0] {$\Amc'_{X\:\!\subseteq\:\!P_1}$};
    \end{tikzpicture}%
  }%
  \hspace*{\fill}
  \parbox[t]{.25\linewidth}{%
    \begin{tikzpicture}[%
      node distance=20mm,>=Latex,baseline=0pt,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial,accepting] (0) {};

      \path[->] (0) edge[loop right] node[right] {\begin{tabular}{@{}l@{}}(*,0,*,0)\\(*,0,*,1)\\(*,1,*,1)\end{tabular}} ();

      \node [above=1mm of 0] {$\Amc'_{Y\:\!\subseteq\:\!P_2}$};
    \end{tikzpicture}%
  }%
  \hspace*{\fill}
  \parbox[t]{.48\linewidth}{%
    \begin{tikzpicture}[%
      node distance=25mm,>=Latex,baseline=0pt,
      initial text="", initial where=below left,
      every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
      accepting/.style={double distance=1.5pt, double=white},
      every edge/.style={draw=black,thin}
    ]
      \node[state,initial]   (0)              {};
      \node[state]           (1) [right of=0] {};
      \node[state,accepting] (2) [right of=1] {};

      \path[->] (0) edge             node[below] {(1,0,*,*)} (1)
                (1) edge             node[below] {(0,1,*,*)} (2)
                (0) edge[loop below] node[below] {(0,0,*,*)} ()
                (2) edge[loop below] node[below] {(0,0,*,*)} ();

      \node [above=1mm of 0] {$\Amc'_{\textsf{succ}(X)\:\!=\:\!Y}$};
    \end{tikzpicture}%
  }%
\end{center}
Nun können wir den Produktautomaten der drei obigen Automaten bilden
(die Produktkonstruktion lässt sich bequem auf mehr als 2 Automaten übertragen):
\begin{center}
  \begin{tikzpicture}[%
    node distance=25mm,>=Latex,baseline=0pt,
    initial text="", initial where=below left,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
    accepting/.style={double distance=1.5pt, double=white},
    every edge/.style={draw=black,thin}
  ]
    \node[state,initial]   (0)              {};
    \node[state]           (1) [right of=0] {};
    \node[state,accepting] (2) [right of=1] {};

    \path[->] (0) edge             node[below] {(1,0,1,*)} (1)
              (1) edge             node[below] {(0,1,*,1)} (2)
              (0) edge[loop below] node[below] {(0,0,*,*)} ()
              (2) edge[loop below] node[below] {(0,0,*,*)} ();

    \node [above=1mm of 0] {$\Amc_\psi$};
  \end{tikzpicture}%
\end{center}
Im letzten Schritt "`verarbeiten"' wir die beiden Existenzquantoren gleichzeitig
und bilden den Automaten für $\varphi$ durch Projektion auf die zwei in $\varphi$
vorkommenden Relationssymbole $P_1,P_2$ (also auf Positionen~3 und~4 in den Bitstrings):
\begin{center}
  \begin{tikzpicture}[%
    node distance=25mm,>=Latex,baseline=0pt,
    initial text="", initial where=below left,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=7.5mm},
    accepting/.style={double distance=1.5pt, double=white},
    every edge/.style={draw=black,thin}
  ]
    \node[state,initial]   (0)              {};
    \node[state]           (1) [right of=0] {};
    \node[state,accepting] (2) [right of=1] {};

    \path[->] (0) edge             node[below] {(1,*)} (1)
              (1) edge             node[below] {(*,1)} (2)
              (0) edge[loop below] node[below] {(*,*)} ()
              (2) edge[loop below] node[below] {(*,*)} ();

    \node [above=1mm of 0] {$\Amc_\varphi$};
  \end{tikzpicture}%
\end{center}
Offensichtlich erkennt dieser NEA die Sprache $L(\varphi)$.

\pagebreak
% ===================================================================
\section*{T4.14~ Beispiele sternfreier Sprachen}

\begin{xalignat*}{2}
  \Sigma^*        & = \overline\emptyset &
  1^*0^*          & = \overline{\Sigma^*01\Sigma^*} \\[4pt]
  \{\varepsilon\} & = \overline{\bigcup_{a \in \Sigma} \{a\} \cdot \Sigma^*} &
  (10)^*          & = \Big(\overline{\Sigma^*00\Sigma^*} \cap \overline{\Sigma^*11\Sigma^*} \cap 1\Sigma^*0\Big) \cup \{\varepsilon\}
\end{xalignat*}
Dabei bedeuten
\begin{center}
  \begin{tabular}{@{}ll@{}}
    $\overline{\Sigma^*01\Sigma^*}$ & Infix 01 ist verboten \\
    $\overline{\Sigma^*00\Sigma^*}$ & Infix 00 ist verboten, d.\,h.\ auf jede 0 folgt eine 1 \\
    $\overline{\Sigma^*11\Sigma^*}$ & Infix 11 ist verboten, d.\,h.\ auf jede 1 folgt eine 0 \\
    $1\Sigma^*0$                    & das Wort beginnt mit 1 und endet mit 0
  \end{tabular}
\end{center}

% ===================================================================
\section*{T4.15~ Beispiele für LTL-Formeln im Verifikations-Szenario}

\begin{itemize}
  \item
    "`Der Wartezustand wird nur durch Ausführen des kritischen Bereichs beendet"':
    \[
      \bigwedge_{i\in\{1,2\}} \Box\Big( W_i \,\to\, \bigcirc\big(W_i \lor A_i\big) \Big)
    \]
  \item
    "` Wenn Prozess $i$ im kritischen Abschnitt ist und Prozess $\overline i = 3-i$ darauf wartet,
    dann betritt Prozess $\overline i$ den kritischen Bereich,
    sobald Prozess $i$ ihn verlässt"':
    \[
      \bigwedge_{i\in\{1,2\}} \Box\Big( \big(A_i \land W_{\overline i}\big) \,\to\, A_i \mathrel{\Umc} A_{\overline i} \Big)
    \]
\end{itemize}

% ===================================================================
\section*{T4.16~ Beispiele zur LTL-Semantik; Äquivalenzen}

Zeichnet das Folgende zur Veranschaulichung selbst in lineare Strukturen ein:
\begin{itemize}
  \item
    Wenn $\Amf,2 \models p$ und $\Amf,n \not\models p$ für alle $n \neq 2$,
    dann $\Amf,1 \models \bigcirc p$ und $\Amf,n \not\models \bigcirc p$ für alle $n \neq 1$.
  \item
    Wenn $\Amf,4 \models p$ und $\Amf,n \not\models p$ für alle $n \neq 4$,
    dann $\Amf,n \models \Diamond p$ für alle $n \leq 4$
    und $\Amf,n \not\models \Diamond p$ für alle $n > 4$.
  \item
    Wenn $\Amf,n \models p$ für alle $n \geq 3$ und $\Amf,n \not\models p$ für alle $n < 3$,
    dann $\Amf,n \models \Box p$ für alle $n \geq 3$
    und $\Amf,n \not\models \Diamond p$ für alle $n < 3$.
  \item
    Wenn $\Amf,n \models p$ für alle $1 \leq n \leq 3$ und $\Amf,4 \models q$,
    dann $\Amf,n \models p \mathrel{\Umc} q$ für alle $1 \leq n \leq 4$.
\end{itemize}
\par\medskip
Es gelten folgende Äquivalenzen:
\begin{align*}
  \Diamond\varphi & \equiv \texttt{true}\mathrel{\Umc}\varphi\qquad \text{mit \texttt{true}} = p \lor \lnot p \\
  \Box\varphi     & \equiv \lnot\Diamond\lnot\varphi
\end{align*}
Es genügen also eigentlich $\bigcirc$ und \Umc als einzige temporale Operatoren.

% ===================================================================
\section*{T4.17~ Beispiel für initiale Äquivalenz}

Die LTL-Formel
%
\[
  \varphi = \Box \big(p \to p \mathrel{\Umc} q\big)
\]
besagt, dass für jeden ($\Box$) Zeitpunkt $n$ gilt:
wenn $\Amf,n \models p$,
dann gibt es einen Zeitpunkt $m \geq n$ mit
$\Amf,m \models q$ und für alle Zeitpunkte $k$ "`dazwischen"'
(\Umc) gilt $\Amf,k \models p$.
Sie ist initial äquivalent zur F1S-Formel
(mit einer freien Variablen, wie üblich unterstrichen)
\[
  \psi(\underline x) = 
  \forall y\,\bigg(
    \big(y \geq \underline x \land P(y)\big) \to
    \exists z\,\Big(
      z \geq y \land Q(z) \land \forall u\,\big(
        y \leq u < z \to P(u)
      \big)
    \Big)
  \bigg),
\]
wobei "`$y \geq x$"' für "`$x < y \lor x = y$"' steht;
analog für "`$z \geq y$"' und "`$y \leq u < z$"'.

% ===================================================================
\section*{T4.18~ Beweis des Lemmas {\boldmath $\text{LTL} \to \text{F1S}$}}

\textsfbf{Lemma 4.19.}~
Zu jeder LTL-Formel $\varphi$ existiert eine initial äquivalente
F1S-Formel $\psi(x)$.

\newcommand{\myhat}[1]{\widehat{\rule{0pt}{7pt}#1}}
\begin{beweis}
  Wir geben eine Übersetzung an, die jeder LTL-Formel $\varphi$
  eine S1S-Formel $\widehat{\varphi}(x)$ mit einer freien Variable
  zuordnet. Dabei gehen wir induktiv über die Struktur von $\varphi$ vor.
  %
  \begin{align*}
    \myhat{p_i}(x)                          & ~= P_i(x)                                       \\[2pt]
    \myhat{\lnot\varphi}(x)                 & ~=~ \lnot\myhat{\varphi}(x)                     \\[2pt]
    \myhat{\varphi\!\!\:\land\!\!\:\psi}(x) & ~=~ \myhat{\varphi}(x) \land \myhat{\psi}(x)    \\[2pt]
    \myhat{\varphi\!\!\:\lor \!\!\:\psi}(x) & ~=~ \myhat{\varphi}(x) \lor  \myhat{\psi}(x)    \\[2pt]
    \myhat{\bigcirc\varphi}(x)              & ~=~ \exists y\,\big(y \!\!\;=\!\!\; s(x) \land \myhat{\varphi}(y)\big) \\[2pt]
    \myhat{\Diamond\varphi}(x)              & ~=~ \exists y\,\big(x \!\!\;\leq\!\!\; y \land \myhat{\varphi}(y)\big) \\[2pt]
    \myhat{\Box\varphi}(x)                  & ~=~ \forall y\,\big(x \!\!\;\leq\!\!\; y \to   \myhat{\varphi}(y)\big) \\[2pt]
    \myhat{\varphi\;\!\Umc\;\!\psi}(x)      & ~=~ \exists y\,\Big(x \!\!\;\leq\!\!\; y \land \myhat{\psi}(y)
                                                  \land \forall z\,\big(x \!\!\;\leq\!\!\; z \!\!\;<\!\!\; y \to \myhat{\varphi}(z)\big)\Big)
  \end{align*}
  %
  In den letzten 4 Fällen ist dabei $y$ jeweils eine neue Variable,
  und die Atome mit "`$\leq$"' sind dabei wieder Abkürzungen wie im vorangehenden Beispiel.

  Man kann nun leicht per Induktion zeigen, dass für alle LTL-Formeln $\varphi$ gilt:
  $\varphi$ ist initial äquivalent zu $\myhat{\varphi}(x)$.
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T4.19~ Zur ESO-Definierbarkeit von "`Hamiltonkreis"'}

Die folgende Formel definiert die Klasse HK aller ungerichteten Graphen, die einen Hamiltonkreis haben.
%
\begin{align*}
  \varphi_{\textsf{HK}} & = \exists L\,\exists S\,\Big(\text{$L$ ist strikte lineare Ordnung~} ~\land \\
                        & \hspace*{20mm} \text{alle Elemente des Universums kommen in $L$ vor~} ~\land \\
                        & \hspace*{20mm} \text{$S$ ist die \emph{direkte} Nachfolgerrelation von $L$ und} \\
                        & \hspace*{24mm} \text{verbindet zusätzlich das größte $L$-Element mit dem kleinsten~} ~\land \\
                        & \hspace*{20mm} \forall x\,\forall y\,\big(S(x,y) \to E(x,y)\big)\Big)
\end{align*}
%
Dabei sind $L$ und $S$ binäre Relationsvariablen;
alle Konjunkte sind offensichtlich durch FO-Formeln definierbar,
die $L$ und $S$ wie Relationsvariablen behandeln.

Um dies an einem Beispiel zu illustrieren, betrachte den ungerichteten Graphen $G$ im linken Teil des unteren Bildes
(den man äquivalent als Struktur $\Amf$ mit symmetrischer binärer Relation $E$ auf"|fassen kann).
Dieser Graph hat einen Hamiltonkreis:
im mittleren Teil des Bildes ist die strikte lineare Ordnung $L$ eingezeichnet, allerdings der Übersichtlichkeit halber ohne transitive Hülle.
Im rechten Teil ist die Relation $S$ eingezeichnet, die gleichzeitig den Hamiltonkreis repräsentiert.
%
\begin{center}
  \newcommand{\hamkreisbsp}{%
    \node[state] (l0)                     {};
    \node[state] (l1) [right=of l0]       {};
    \node[state] (b1) [below right=of l1] {};
    \node[state] (r1) [above right=of b1] {};
    \node[state] (t1) [above left =of r1] {};
    \node[state] (b0) [below=of b1]       {};
    \node[state] (r0) [right=of r1]       {};
    \node[state] (t0) [above=of t1]       {};

    \path[-] (l0) edge (l1)
             (b0) edge (b1)
             (r0) edge (r1)
             (t0) edge (t1)
             (l0) edge (b0)
             (b0) edge (r0)
             (r0) edge (t0)
             (t0) edge (l0)
             (l1) edge (b1)
             (b1) edge (r1)
             (r1) edge (t1)
             (t1) edge (l1);
  }%
  \newcommand{\Lpath}{%
    (l1) edge (b1)
    (b1) edge (r1)
    (r1) edge (t1)
    (t1) edge (t0)
    (t0) edge (r0)
    (r0) edge (b0)
    (b0) edge (l0)
  }%
  \hspace*{\fill}%
  \begin{tikzpicture}[%
    node distance=6mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=.5mm,minimum size=1mm},
    every edge/.style={draw=black,thin}
  ]
    \hamkreisbsp
  \end{tikzpicture}%
  \hspace*{\fill}%
  \hspace*{\fill}%
  \begin{tikzpicture}[%
    node distance=6mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=.5mm,minimum size=1mm},
    every edge/.style={draw=black,thin}
  ]
    \hamkreisbsp

    \begin{scope}[every edge/.style={draw=black,line width=2mm,draw opacity=.4}]
      \path[-]
        \Lpath;
    \end{scope}
  \end{tikzpicture}%
  \hspace*{\fill}%
  \hspace*{\fill}%
  \begin{tikzpicture}[%
    node distance=6mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=.5mm,minimum size=1mm},
    every edge/.style={draw=black,thin}
  ]
    \hamkreisbsp
    \begin{scope}[every edge/.style={draw=black,line width=2mm,draw opacity=.4}]
      \path[-]
        \Lpath
        (l0) edge (l1);
    \end{scope}
  \end{tikzpicture}%
  \hspace*{\fill}
\end{center}
%
Wir wollen nun beweisen, dass HK durch $\varphi_{\textsf{HK}}$ definiert wird,
also dass gilt:
\[
  \Amf = (A,E^\Amf) \in \textsf{HK}
  \quad\text{gdw.}\quad
  \Amf \models \varphi_{\textsf{HK}}
\]
\begin{beweis}
  \begin{description}
    \item[{\boldmath"`$\Rightarrow$"'}]
      Angenommen, der ungerichtete Graph $\Amf = (A,E^\Amf)$ enthält einen Hamiltonkreis
      \[
        H = \big\{\{a_0,a_1\},~\dots,~\{a_{n-1},a_n\},~\{a_n,a_0\}\big\}.
      \]
      Erweitere nun $\Amf$ durch die binären Relationen
      \begin{align*}
        S^\Amf & := \big\{(a_0,a_1),~\dots,~(a_{n-1},a_n),~(a_n,a_0)\big\}\quad\text{(wie $H$, aber gerichtet)} \\
        L^\Amf & := \text{transitive Hülle von~} S^\Amf \setminus \{(a_n,a_0)\}.
      \end{align*}
      Man prüft nun leicht, dass alle FO-Konjunkte von $\varphi_{\textsf{HK}}$ in \Amf erfüllt sind.
      Deshalb wird durch $S^\Amf$ und $L^\Amf$ eine Zuweisung $\beta$ bestimmt,
      unter der die gesamte Konjunktion, als SO-Formel aufgefasst, erfüllt ist.
      Folglich gilt $\Amf \models \varphi_{\textsf{HK}}$.
    \item[{\boldmath"`$\Leftarrow$"'}]
      Angenommen $\Amf \models \varphi_{\textsf{HK}}$.
      Seien $S^\Amf$ und $L^\Amf$ Relationen, so dass alle FO-Formeln in $\varphi_{\textsf{HK}}$
      erfüllt sind. Dann ist $S^\Amf$ ein Hamiltonkreis in $\Amf = (A,E^\Amf)$:
      \begin{itemize}
        \item
          $S^\Amf$ ist ein Kreis, da $S^\Amf$ die direkte Nachfolgerrelation der strikten
          linearen Ordnung $L^\Amf$ ist und zusätzlich deren größtes Element mit dem kleinsten verbindet.
        \item
          $S^\Amf$ enthält nur Kanten aus $E$.
        \item
          $S^\Amf$ enthält \emph{alle} Knoten aus $A$, weil $L^\Amf$ alle Knoten enthält.
        \item
          $S^\Amf$ enthält jeden Knoten höchstens einmal, weil anderenfalls $L^\Amf$ keine \emph{strikte} lineare Ordnung wäre.
      \end{itemize}
      \qedhere
  \end{description}
\end{beweis}%

\goodbreak
% ===================================================================
\section*{T4.20~ Beispiel für die Kodierung einer Struktur als Wort}

Sei $\Amf = (A,R^\Amf)$ eine Struktur mit einem zweistelligen
Relationssymbol $R$ wie folgt.
%
\begin{center}
  \begin{tikzpicture}[%
    node distance=18mm,>=Latex,
    every state/.style={draw=black,thin,fill=black!10,inner sep=1mm,minimum size=6mm},
    every edge/.style={draw=black,thin}
  ]
    \node[state] (a1)                    {$a_1$};
    \node[state] (a2) [right=of a1]      {$a_2$};
    \node[state] (a3) [below=10mm of a1] {$a_3$};
    \node[state] (a4) [right=of a3]      {$a_4$};

    \path[->] (a1) edge node[auto] {$R$}                (a2)
              (a1) edge node[auto] {$R$}                (a3)
              (a3) edge node[auto] {$R$}                (a4)
              (a2) edge[bend right=10] node[auto,swap] {$R$} (a4)
              (a4) edge[bend right=10] node[auto,swap] {$R$} (a2)
              (a1) edge[loop left]     node       {$R$} ()
              (a4) edge[loop right]    node       {$R$} ();
  \end{tikzpicture}%
\end{center}
%
Dann wird die Relation $R^\Amf$ durch folgendes Wort kodiert:
\[
  w_R = 1\,1\,1\,0\,0\,0\,0\,1\,0\,0\,0\,1\,0\,1\,0\,1
\]
Dabei stehen die 16 Bits in dieser Reihenfolge für die Paare
\[
  (a_1,a_1) \in R^\Amf,~~
  (a_1,a_2) \in R^\Amf,~~
  (a_1,a_3) \in R^\Amf,~~
  \dots,~~
  (a_4,a_3) \notin R^\Amf,~~
  (a_4,a_4) \in R^\Amf.
\]
Die gesamte Struktur wird dann so kodiert:
\[
  \underbrace{0\,0\,0\,0\,1}_{|A|=4}\!
  \underbrace{0\,0\,1}_{R \text{~binär}}\!\!
  w_R
\]

\pagebreak
% ===================================================================
\section*{T4.21~ Datenkomplexität von ESO}

\textsfbf{Lemma 4.27.}~
Jedes ESO-definierbare Problem $K$ ist in NP.

\begin{beweis}
  Sei $K$ definierbar durch einen ESO-Satz $\varphi_K$.
  Das Entscheidungsproblem $K$ ist dann äquivalent zu folgendem Problem:
  \begin{quote}
    \begin{tabular}{ll}
      Gegeben: & Struktur $\Amf$ \\
      Frage  : & Gilt $\Amf \models \varphi_K$\,?
    \end{tabular}
  \end{quote}
  Dies ist nichts anderes als das Auswertungsproblem, wobei $\varphi_K$
  fest ist, also unabhängig von der Eingabe,
  Es genügt also zu zeigen, dass ESO-Auswertung bezüglich Datenkomplexität in NP ist
  (deshalb der Zusatz "`mit anderen Worten"' auf der Folie).

  \par\smallskip
  Sei $\varphi = \exists R_1\,\cdots\exists R_n\,\varphi$
  der fixierte auszuwertende ESO-Satz mit $\varphi \in \textsf{FO}$.
  Wir verwenden den folgenden Algorithmus,
  der eine Struktur $\Amf$ als Eingabe verwendet:
  %
  \begin{enumerate}
    \item
      Bestimme nichtdeterministisch Relationen $R_1^\Amf,\dots,R_n^\Amf$
      passender Stelligkeit.
    \item
      Überprüfe mit dem Auswertungsalgorithmus \texttt{ausw}
      aus Teil~2 (Prädikatenlogik 1.~Stufe),
      ob die um diese Relationen erweiterte Struktur $\Amf$
      den FO-Satz $\varphi$ wahr macht.
      Wenn ja, gib "`erfüllt"' aus, sonst "`nicht erfüllt"'.
  \end{enumerate}
  Der zweite Schritt ist deterministisch;
  da $\varphi$ fixiert ist, kann er in Polynomialzeit ausgeführt werden
  (siehe Datenkomplexität von FO).
  \qedhere
\end{beweis}%

% ===================================================================
\section*{T4.22~ Repräsentation der Schrittzähler und Bandpositionen}

Wenn die Eingabestruktur \Amf durch ein Wort $w_\Amf$ repräsentiert wird,
kann Polyzeit-Turingmaschine $M$ maximal $|w_\Amf|^k$ viele Berechnungsschritte durchführen.
Für jeden Schritt muss die aktuelle Konfiguration festgehalten werden,
die neben dem aktuellen Zustand auch aus dem Schrittzähler (Werte $0,\dots,|w_\Amf|^k-1$)
und dem Inhalt des Bandes an den maximal $|w_\Amf|^k$ Bandpositionen besteht.
Da es in $\Amf$ nur $|A|$ viele Elemente gibt,
müssen wir Schrittzähler und und Bandpositionen durch \emph{Tupel} $\overline{a}$ von Elementen
von $\Amf$ ausdrücken. Dafür wählen wir $k'$ so, dass $|A|^{k'} \leq |w_\Amf|^k$,
also dass es mindestens so viele Tupel gibt wie benötigt.

Um in der Struktur festzuhalten, welches Tupel welcher Zahl aus $\{0,\dots,|w_\Amf|^k-1\}$
entspricht,
verwenden wir zusätzlich eine strikte lineare Ordnung über $A^{k'}$.
Diese repräsentieren wir mittels einer $2k'$-stelligen Relationsvariable $L$ wie folgt.
%
\begin{align*}
  \varphi_{\textsf{lin}} & \,:=\, \exists L\,\bigg(L \text{~ist irreflexiv, antisymmetrisch, transitiv} \\[-.7\baselineskip]
                         & \hspace*{16mm} \land~~ \forall\:\!\overline{x}\,\forall\:\!\overline{y}\,
                                          \Big(\overline{x} \neq \overline{y} \to \big(L(\overline{x},\overline{y}) \lor L(\overline{y},\overline{x})\big)\Big)\bigg),
\end{align*}
%
wobei $\overline{x},\overline{y}$ jeweils $k'$-Tupel von Variablen sind
und die fehlenden FO-Formeln wieder leicht einzusetzen sind.
Um nun mittels $L$ die Zahlen $0,\dots,|w_\Amf|^k-1$ zu repräsentieren,
benötigt man noch die Nachfolgerrelation auf $L$, die man wie folgt definieren kann:
%
\[
  \varphi_{\textsf{NF}} \,:=\, L(\overline{x},\overline{y}) \land \lnot \exists\:\!\overline{z}\,\big(L(\overline{x},\overline{z}) \land L(\overline{z},\overline{y})\big)
\]
%
Nun können wir mittels eines Tupels $\overline{x}$ Schrittzähler und Bandposition repräsentieren.

\goodbreak
% ===================================================================
\section*{T4.23~ Bestandteile der Formel {\boldmath $\psi$} im Beweis Satz von Fagin}

\begin{itemize}
  \item
    {\boldmath $\psi_{\textsf{ok}}$}
    \par
    Dieses Konjunkt soll sicherstellen,
    dass Bandsymbole und Zustände eindeutig sind, d.\,h.,
    an jeder Bandposition (repräsentiert durch ein $k'$-Tupel $\overline{p}$)
    steht zu jedem Zeitpunkt der Berechnung
    (Schrittzähler, repräsentiert durch ein $k'$-Tupel~$\overline{t}$)
    höchstens ein Zeichen $a_i$ des Arbeitsalphabets
    (repräsentiert durch eine $k'$-stellige Relationsvariable $T_{a_i}$),
    und wenn dort der Schreib-Lese-Kopf steht,
    dann in höchstens einem Zustand
    (repräsentiert durch eine $k'$-stellige Relationsvariable $H_{q_i}$);
    außerdem kann der Schreib-Lese-Kopf dann an keiner weiteren Position $\overline{p}'$ stehen.
    Dies kann wie folgt ausgedrückt werden:
    %
    \begin{align*}
      \psi_{\textsf{ok}} & ~=~
      \forall\:\! \overline{p}~\forall\:\! \overline{t}~
      \Bigg(
        \bigvee_{1 \leq i \leq \ell} \bigg(
          T_{a_i}(\overline{p},\overline{t}) \land
          \bigwedge_{\substack{1 \leq j \leq \ell\\j \neq i}} \lnot T_{a_j}(\overline{p},\overline{t})
        \bigg)
      \Bigg)
      ~~\land \\
      & \hspace*{8mm}
      \forall\:\! \overline{t}~\exists\:\! \overline{p}~
      \Bigg(
        \bigvee_{1 \leq i \leq m} \bigg(
          H_{q_i}(\overline{p},\overline{t}) \land
          \bigwedge_{\substack{1 \leq j \leq m\\j \neq i}} \lnot H_{q_j}(\overline{p},\overline{t})
        \bigg)
      \\
      & \hspace*{22mm}
      \land~~ \forall\:\! \overline{p}'~
      \bigg(
        \overline{p} \neq \overline{p}' \to
        \bigwedge_{1 \leq i \leq m} \lnot H_{q_i}(\overline{p}',\overline{t})
      \bigg)\Bigg)
    \end{align*}
  \item
    {\boldmath $\psi_{\textsf{move}}$}
    \par
    Dieses Konjunkt drückt aus, dass zwei aufeinander folgende Konfigurationen
    entweder der Übergangsrelation $\Delta$ der Maschine entsprechen
    oder in einem akzeptierenden oder verwerfenden Zustand verbleiben
    (falls vor Erreichen der $n^k$ Schritte ein solcher Zustand erreicht wird,
    wird er aus technischen Gründen in den folgenden Zeitpunkten einfach beibehalten):
    \begin{align*}
      \psi_{\textsf{move}} & ~=~
      \forall\:\! \overline{t}~
      \forall\:\! \overline{t}' \Bigg(
        \varphi_{\textsf{nf}}(\overline{t},\overline{t}') ~\to
        \bigvee_{(q,a,q',b,M) \in \Delta} \alpha_{q,a,q',b,M} (\overline{t},\overline{t}') ~\lor~
        \psi_{\textsf{term}} (\overline{t},\overline{t}')
      \Bigg),
      \intertext{wobei}
      \alpha_{q,a,q',b,\text{{\boldmath $R$}}} (\overline{t},\overline{t}') & ~=~
      \exists\:\! \overline{p}~
      \exists\:\! \overline{p}' \Bigg(
        H_q (\overline{p},\overline{t}) \land T_a (\overline{p},\overline{t}) \land
        H_{q'} (\overline{p}',\overline{t}') \land T_b (\overline{p}',\overline{t}') \land
        \text{{\boldmath $\varphi_{\textsf{nf}} (\overline{t},\overline{t}')$}}
      \Bigg), \\
      \alpha_{q,a,q',b,\text{{\boldmath $L$}}} (\overline{t},\overline{t}') & ~=~
      \exists\:\! \overline{p}~
      \exists\:\! \overline{p}' \Bigg(
        H_q (\overline{p},\overline{t}) \land T_a (\overline{p},\overline{t}) \land
        H_{q'} (\overline{p}',\overline{t}') \land T_b (\overline{p}',\overline{t}') \land
        \text{{\boldmath $\varphi_{\textsf{nf}} (\overline{t}',\overline{t})$}}
      \Bigg)
      \intertext{und}
      \psi_{\textsf{term}} (\overline{t},\overline{t}') & ~=~
      \exists\:\! \overline{p}
      \bigvee_{q \in Q_A \cup Q_R}\Bigg(
        H_q (\overline{p},\overline{t}) \land
        H_q (\overline{p},\overline{t}')
      \Bigg).
    \end{align*}
  \item
    {\boldmath $\psi_{\textsf{acc}}$}
    \par
    Für dieses Konjunkt genügt wegen der obigen Beobachtung über akzeptierende (und verwerfende) Zustände:
    \[
      \psi_{\textsf{acc}}  ~=~
      \exists\:\! \overline{p}~
      \exists\:\! \overline{t}
      \bigvee_{q \in Q_A}\Bigg(
        H_q (\overline{p},\overline{t})
      \Bigg)
    \]
  \item
    {\boldmath $\psi_{\textsf{const}}$}
    \par
    Dieses Konjunkt lässt sich leicht analog konstruieren;
    probiert es selbst aus.
  \item
    {\boldmath $\psi_{\textsf{ini}}$}
    \par
    Dies ist das technisch aufwändigste Konjunkt,
    denn dazu müssen Addition und Multiplikation von natürlichen Zahlen
    ESO-definiert werden.
    Weitere Details kann man z.\,B.\ in \cite{EF99,Imm99} nachlesen.
\end{itemize}

% ===================================================================
% ===================================================================
% ===================================================================
\part*{Anhang}
\addcontentsline{toc}{part}{Anhang}

% ===================================================================
\section*{Griechische Buchstaben}

\paragraph*{Kleinbuchstaben}
~\par%\vspace*{-.2\baselineskip}
$\alpha$ \dotfill alpha \\
$\beta$ \dotfill beta \\
$\gamma$ \dotfill gamma \\
$\delta$ \dotfill delta \\
$\epsilon$ \dotfill epsilon \\
$\zeta$ \dotfill zeta \\
$\eta$ \dotfill eta \\
$\vartheta,\theta$ \dotfill theta \\
$\iota$ \dotfill iota \\
$\kappa$ \dotfill kappa \\
$\lambda$ \dotfill lambda\\
$\mu$ \dotfill my\\
$\nu$ \dotfill ny \\
$\xi$ \dotfill xi\\
$o$ \dotfill omikron\\
$\pi$ \dotfill pi\\
$\rho$ \dotfill rho\\
$\sigma,\varsigma$ \dotfill sigma\\
$\tau$ \dotfill tau\\
$\upsilon$ \dotfill ypsilon\\
$\varphi,\phi$ \dotfill phi\\
$\chi$ \dotfill chi\\
$\psi$ \dotfill psi\\
$\omega$ \dotfill omega

% \newpage

\paragraph*{Großbuchstaben}
~\par%\vspace*{-.2\baselineskip}
$\Gamma$ \dotfill Gamma \\
$\Delta$ \dotfill Delta \\
$\Theta$ \dotfill Theta \\
$\Lambda$ \dotfill Lambda \\
$\Pi$ \dotfill Pi \\
$\Xi$ \dotfill Xi \\
$\Sigma$ \dotfill Sigma \\
$\Upsilon$ \dotfill Ypsilon \\
$\Phi$ \dotfill Phi \\
$\Psi$ \dotfill Psi \\
$\Omega$ \dotfill Omega

Die übrigen griechischen Großbuchstaben werden genauso geschrieben wie die entsprechenden lateinischen.

\pagebreak
\addcontentsline{toc}{part}{Literaturverzeichnis}
\bibliographystyle{babalpha}
\bibliography{biblio.bib}
\end{document}
